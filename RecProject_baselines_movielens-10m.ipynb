{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53b7b19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVoK_7xHdaa9",
    "outputId": "5068028f-6526-41db-ab84-9989d1f39bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polara\n",
      "  Cloning https://github.com/evfro/polara.git (to revision develop) to /tmp/pip-install-2y70x9ba/polara_606a3c3a2230448b9393ef034c0f5194\n",
      "  Running command git clone -q https://github.com/evfro/polara.git /tmp/pip-install-2y70x9ba/polara_606a3c3a2230448b9393ef034c0f5194\n",
      "  Running command git checkout -b develop --track origin/develop\n",
      "  Switched to a new branch 'develop'\n",
      "  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
      "  Resolved https://github.com/evfro/polara.git to commit 4de4ca7d6f901e32f1e045f190bcb09587162397\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52051f5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:21.335881Z",
     "start_time": "2022-04-30T17:28:20.194309Z"
    },
    "id": "o_HJgdQFdSaf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import polara\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, downvote_seen_items\n",
    "\n",
    "from polara.lib.tensor import hooi\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "from sa_hooi import sa_hooi, form_attention_matrix, get_scaling_weights, generate_position_projector\n",
    "\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from scipy.sparse.linalg import norm, svds\n",
    "from scipy.linalg import solve_triangular, sqrtm\n",
    "\n",
    "from IPython.utils import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbbfc5e",
   "metadata": {
    "id": "4NbP1tmBdSas"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406f94e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:26.800639Z",
     "start_time": "2022-04-30T17:28:26.787622Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def full_preproccessing(data = None):\n",
    "    if (data is None):\n",
    "        data = get_movielens_data(\"ml-10m.zip\", include_time=True)\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.8, interpolation='nearest'\n",
    "    )\n",
    "    \n",
    "    labels, levels = pd.factorize(data.movieid)\n",
    "    data.movieid = labels\n",
    "\n",
    "    labels, levels = pd.factorize(data.userid)\n",
    "    data.userid = labels\n",
    "    \n",
    "    if (data[\"rating\"].nunique() > 5):\n",
    "        data[\"rating\"] = data[\"rating\"] * 2\n",
    "        \n",
    "    data[\"rating\"] = data[\"rating\"].astype(int)\n",
    "\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "    train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    "    )\n",
    "    \n",
    "    training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "    test_data = reindex(test_data_, data_index['items'])\n",
    "\n",
    "    testset_, holdout_ = leave_one_out(\n",
    "    test_data, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "    testset_valid_, holdout_valid_ = leave_one_out(\n",
    "        testset_, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "\n",
    "    test_users_val = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset_valid = testset_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "    holdout_valid = holdout_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "\n",
    "    test_users = np.intersect1d(testset_.userid.unique(), holdout_.userid.unique())\n",
    "    testset = testset_.query('userid in @test_users').sort_values('userid')\n",
    "    holdout = holdout_.query('userid in @test_users').sort_values('userid')\n",
    "    \n",
    "    assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
    "        testset_valid\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "\n",
    "    data_description = dict(\n",
    "        users = data_index['users'].name,\n",
    "        items = data_index['items'].name,\n",
    "        feedback = 'rating',\n",
    "        n_users = len(data_index['users']),\n",
    "        n_items = len(data_index['items']),\n",
    "        n_ratings = training['rating'].nunique(),\n",
    "        min_rating = training['rating'].min(),\n",
    "        test_users = holdout_valid[data_index['users'].name].drop_duplicates().values, # NEW\n",
    "        n_test_users = holdout_valid[data_index['users'].name].nunique() # NEW\n",
    "    )\n",
    "\n",
    "    return training, testset_valid, holdout_valid, testset, holdout, data_description, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee53de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:37.767718Z",
     "start_time": "2022-04-30T17:28:28.865924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 242627 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce3b18",
   "metadata": {
    "id": "YJOfzHI5dSaz"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9672a97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:39.873545Z",
     "start_time": "2022-04-30T17:28:39.859396Z"
    },
    "code_folding": [
     0,
     52,
     70
    ],
    "id": "nXnDXyWrdSbM"
   },
   "outputs": [],
   "source": [
    "def model_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10, dcg=False):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    alpha = 3 if holdout_description[\"n_ratings\"] == 5 else 6\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    holdout_items = holdout[itemid].values\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    \n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    \n",
    "    # HR calculation\n",
    "    #hr = np.sum(hits_mask.any(axis=1)) / n_test_users\n",
    "    hr_pos = np.sum(hits_mask[pos_mask].any(axis=1)) / n_test_users\n",
    "    hr_neg = np.sum(hits_mask[neg_mask].any(axis=1)) / n_test_users\n",
    "    hr = hr_pos + hr_neg\n",
    "    \n",
    "    # MRR calculation\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    mrr_pos = np.sum(1 / pos_hit_rank) / n_test_users\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    mrr_neg = np.sum(1 / neg_hit_rank) / n_test_users\n",
    "    \n",
    "    # Matthews correlation\n",
    "    TP = np.sum(hits_mask[pos_mask]) # + \n",
    "    FP = np.sum(hits_mask[neg_mask]) # +\n",
    "    cond = (hits_mask.sum(axis = 1) == 0)\n",
    "    FN = np.sum(cond[pos_mask])\n",
    "    TN = np.sum(cond[neg_mask])\n",
    "    N = TP+FP+TN+FN\n",
    "    S = (TP+FN)/N\n",
    "    P = (TP+FP)/N\n",
    "    C = (TP/N - S*P) / np.sqrt(P*S*(1-P)*(1-S))\n",
    "    \n",
    "    # DCG calculation\n",
    "    if dcg:\n",
    "        pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "        neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "        ndcg = np.mean(1 / np.log2(pos_hit_rank+1))\n",
    "        ndcl = np.mean(1 / np.log2(neg_hit_rank+1))\n",
    "    \n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    if dcg:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C, ndcg, ndcl\n",
    "    else:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C\n",
    "\n",
    "def make_prediction(tf_scores, holdout, data_description, mode, context=\"\", print_mode=True):\n",
    "    if (mode and print_mode):\n",
    "        print(f\"for context {context} evaluation ({mode}): \\n\")\n",
    "    for n in [5, 10, 20]:\n",
    "        tf_recs = topn_recommendations(tf_scores, n)\n",
    "        hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout, data_description, topn=n)\n",
    "        if (print_mode):\n",
    "            print(f\"HR@{n} = {hr:.4f}, MRR@{n} = {mrr:.4f}, Coverage@{n} = {cov:.4f}\")\n",
    "            print(f\"HR_pos@{n} = {hr_pos:.4f}, HR_neg@{n} = {hr_neg:.4f}\")\n",
    "            print(f\"MRR_pos@{n} = {mrr_pos:.4f}, MRR_neg@{n} = {mrr_neg:.4f}\")\n",
    "            print(f\"Matthews@{n} = {C:.4f}\")\n",
    "            print(\"-------------------------------------\")\n",
    "        if (n == 10):\n",
    "            mrr10 = mrr\n",
    "            hr10 = hr\n",
    "            c10 = C\n",
    "    return mrr10, hr10, c10\n",
    "\n",
    "def valid_mlrank(mlrank):\n",
    "    '''\n",
    "    Only allow ranks that are suitable for truncated SVD computations\n",
    "    on unfolded compressed tensor (the result of ttm product in HOOI).\n",
    "    '''\n",
    "    #s, r1, r2, r3 = mlrank\n",
    "    s, r1, r3 = mlrank\n",
    "    r2 = r1\n",
    "    #print(s, r1, r2, r3)\n",
    "    return r1*r2 > r3 and r1*r3 > r2 and r2*r3 > r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfbb23",
   "metadata": {},
   "source": [
    "# CoFFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400f0e84",
   "metadata": {
    "code_folding": [
     3,
     55,
     66
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "from scipy.special import softmax\n",
    "\n",
    "def tf_model_build(config, data, data_description, testset, holdout, attention_matrix=np.array([])):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    if (attention_matrix.shape[0] == 0):\n",
    "        attention_matrix = form_attention_matrix(\n",
    "            data_description['n_ratings'],\n",
    "            **config['params'],\n",
    "            format = 'csr'\n",
    "        )\n",
    "        \n",
    "    attention_matrix = np.array(attention_matrix)\n",
    "\n",
    "    item_popularity = (\n",
    "        data[itemid]\n",
    "        .value_counts(sort=False)\n",
    "        .reindex(range(n_items))\n",
    "        .fillna(1)\n",
    "        .values\n",
    "    )\n",
    "    scaling_weights = get_scaling_weights(item_popularity, scaling=config[\"scaling\"])\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        u0, u1, u2 = sa_hooi(\n",
    "            idx, val, shape, config[\"mlrank\"],\n",
    "            attention_matrix = attention_matrix,\n",
    "            scaling_weights = scaling_weights,\n",
    "            testset = testset,\n",
    "            holdout = holdout,\n",
    "            data_description = data_description,\n",
    "            max_iters = config[\"num_iters\"],\n",
    "            parallel_ttm = True,\n",
    "            randomized = config[\"randomized\"],\n",
    "            growth_tol = config[\"growth_tol\"],\n",
    "            seed = config[\"seed\"],\n",
    "            iter_callback = None,\n",
    "        )\n",
    "    \n",
    "    return u0, u1, u2, attention_matrix    \n",
    "    \n",
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"mlrank\": (30, 30, data_description['n_ratings']),\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 4,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "def tf_scoring(params, data, data_description, context=[\"3+4+5\"]):\n",
    "    user_factors, item_factors, feedback_factors, attention_matrix = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid) \n",
    "    data_new = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    ) # NEW\n",
    "    useridx = data_new[userid]\n",
    "    itemidx = data_new[itemid].values\n",
    "    ratings = data_new[feedback].values\n",
    "    ratings = ratings - data_description['min_rating'] # NEW\n",
    "    \n",
    "    n_users = useridx.nunique()\n",
    "    n_items = data_description['n_items']\n",
    "    n_ratings = data_description['n_ratings']\n",
    "    \n",
    "    inv_attention = solve_triangular(attention_matrix, np.eye(n_ratings), lower=True)\n",
    "    \n",
    "    tensor_outer = tensor_outer_at('cpu')\n",
    "    #matrix_softmax = softmax(inv_attention.T @ feedback_factors)\n",
    "    matrix_softmax = inv_attention.T @ feedback_factors\n",
    "    #\n",
    "    if (n_ratings == 10):\n",
    "        coef = 2\n",
    "    else:\n",
    "        coef = 1\n",
    "        \n",
    "    if (context == \"5\"): # make softmax \n",
    "        inv_aT_feedback = matrix_softmax[(-1 * coef) , :]\n",
    "    elif (context == \"4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[(-2 * coef):, :], axis=0)\n",
    "    elif (context == \"3+4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[(-3 * coef):, :], axis=0)\n",
    "    #elif (context == \"2+3+4+5\"):\n",
    "    #    inv_aT_feedback = np.sum(matrix_softmax[-4:, :], axis=0)\n",
    "    elif (context == \"3+4+5-2-1\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[(-3 * coef):, :], axis=0) - np.sum(matrix_softmax[:(2 * coef), :], axis=0)\n",
    "        \n",
    "    scores = tensor_outer(\n",
    "        1.0,\n",
    "        item_factors,\n",
    "        attention_matrix @ feedback_factors,\n",
    "        itemidx,\n",
    "        ratings\n",
    "    )\n",
    "    scores = np.add.reduceat(scores, np.r_[0, np.where(np.diff(useridx))[0]+1]) # sort by users\n",
    "    scores = np.tensordot(\n",
    "        scores,\n",
    "        inv_aT_feedback,\n",
    "        axes=(2, 0)\n",
    "    ).dot(item_factors.T)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c81dc8b",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "def full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix):\n",
    "\n",
    "    config[\"mlrank\"] = (64, 64, data_description[\"n_ratings\"])\n",
    "    print(\"Starting pipeline...\")\n",
    "    print(\"Training with different context in progress...\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"3+4+5-2-1\"]:\n",
    "        tf_params = tf_model_build(config, training, data_description, testset_valid, holdout_valid, attention_matrix=attention_matrix)\n",
    "        seen_data = testset_valid\n",
    "        tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "        downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "        cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout_valid, data_description, \"Validation\", context)\n",
    "        print(\"------------------------------------------------------\")\n",
    "\n",
    "    print(f\"Tuning model for all contexts...\\n\")\n",
    "\n",
    "    rank_grid = []\n",
    "    for i in range(5, 9):\n",
    "        rank_grid.append(2 * 2 ** i)\n",
    "        rank_grid.append(3 * 2 ** i)\n",
    "    \n",
    "    rank_grid = np.array(rank_grid)\n",
    "    tf_hyper = {\n",
    "    'scaling': [0.3], #np.linspace(0, 2, 21),\n",
    "    'r1': rank_grid, #np.arange(100, 220, 25),\n",
    "    #'r2': np.arange(50, 801, 25),\n",
    "    'r3': range(1, 6, 1)#range(2, 11, 2), # change\n",
    "    }\n",
    "\n",
    "    grid, param_names = random_grid(tf_hyper, n=0)\n",
    "    tf_grid = [tuple(mlrank) for mlrank in grid if valid_mlrank(mlrank)]\n",
    "\n",
    "    hr_tf = {}\n",
    "    hr_pos_tf = {}\n",
    "    hr_neg_tf = {}\n",
    "    mrr_tf = {}\n",
    "    mrr_pos_tf = {}\n",
    "    mrr_neg_tf = {}\n",
    "    cov_tf = {}\n",
    "    C_tf = {}\n",
    "    \n",
    "    seen_data = testset_valid\n",
    "    \n",
    "    for mlrank in tqdm(tf_grid):\n",
    "        with io.capture_output() as captured:\n",
    "            r1, r3 = mlrank[1:]\n",
    "            cur_mlrank = tuple((r1, r1, r3))\n",
    "            config['mlrank'] = cur_mlrank\n",
    "            config['scaling'] = mlrank[0]\n",
    "            tf_params = tf_model_build(config, training, data_description, testset_valid, holdout_valid, attention_matrix=attention_matrix)\n",
    "            for context in [\"5\", \"4+5\", \"3+4+5\", \"3+4+5-2-1\"]:\n",
    "                tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "                downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "                tf_recs = topn_recommendations(tf_scores, topn=10)\n",
    "                \n",
    "                hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout_valid, data_description, topn=10)\n",
    "                hr_tf[(context, cur_mlrank, mlrank[0])] = hr\n",
    "                hr_pos_tf[(context, cur_mlrank, mlrank[0])] = hr_pos\n",
    "                hr_neg_tf[(context, cur_mlrank, mlrank[0])] = hr_neg\n",
    "                mrr_tf[(context, cur_mlrank, mlrank[0])] = mrr\n",
    "                mrr_pos_tf[(context, cur_mlrank, mlrank[0])] = mrr_pos\n",
    "                mrr_neg_tf[(context, cur_mlrank, mlrank[0])] = mrr_neg\n",
    "                cov_tf[(context, cur_mlrank, mlrank[0])] = cov\n",
    "                C_tf[(context, cur_mlrank, mlrank[0])] = C\n",
    "\n",
    "    print(f'Best HR={pd.Series(hr_tf).max():.4f} achieved with context {pd.Series(hr_tf).idxmax()[0]} and mlrank = {pd.Series(hr_tf).idxmax()[1]} and scale factor = {pd.Series(hr_tf).idxmax()[2]}')\n",
    "    print(f'Best HR_pos={pd.Series(hr_pos_tf).max():.4f} achieved with context {pd.Series(hr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(hr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(hr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best HR_neg={pd.Series(hr_neg_tf).min():.4f} achieved with context {pd.Series(hr_neg_tf).idxmin()[0]} and mlrank = {pd.Series(hr_neg_tf).idxmin()[1]} and scale factor = {pd.Series(hr_neg_tf).idxmin()[2]}')\n",
    "    \n",
    "    print(f'Best MRR={pd.Series(mrr_tf).max():.4f} achieved with context {pd.Series(mrr_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR_pos={pd.Series(mrr_pos_tf).max():.4f} achieved with context {pd.Series(mrr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR_neg={pd.Series(mrr_neg_tf).min():.4f} achieved with context {pd.Series(mrr_neg_tf).idxmin()[0]} and mlrank = {pd.Series(mrr_neg_tf).idxmin()[1]} and scale factor = {pd.Series(mrr_neg_tf).idxmin()[2]}')\n",
    "    \n",
    "    print(f'Best Matthews={pd.Series(C_tf).max():.4f} achieved with context {pd.Series(C_tf).idxmax()[0]} and mlrank = {pd.Series(C_tf).idxmax()[1]} and scale factor = {pd.Series(C_tf).idxmax()[2]}')\n",
    "                          \n",
    "    print(f'COV={pd.Series(cov_tf)[pd.Series(C_tf).idxmax()]:.4f} (based on best Matthews value)')\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"Evaluation of the best model on test holdout in progress...\\n\")\n",
    "    \n",
    "    print(\"Best by MRR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(mrr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by HR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(hr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by Matthews@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(C_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(C_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(C_tf).idxmax()[0])\n",
    "    print(\"Pipeline ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22a6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attention_matrix = np.eye(5)\n",
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce206499",
   "metadata": {
    "id": "EW7SFRIqqle7"
   },
   "source": [
    "# Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "629408b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:11:44.551668Z",
     "start_time": "2022-03-24T12:11:44.536651Z"
    },
    "id": "KMEOnT4sqoTq"
   },
   "outputs": [],
   "source": [
    "def build_random_model(trainset, trainset_description):\n",
    "    itemid = trainset_description['items']\n",
    "    n_items = trainset[itemid].max() + 1\n",
    "    random_state = np.random.RandomState(42)\n",
    "    return n_items, random_state\n",
    "\n",
    "def random_model_scoring(params, testset, testset_description):\n",
    "    n_items, random_state = params\n",
    "    n_users = testset_description['n_test_users']\n",
    "    scores = random_state.rand(n_users, n_items)\n",
    "    return scores\n",
    "\n",
    "def simple_model_recom_func(scores, topn=20):\n",
    "    recommendations = np.apply_along_axis(topidx, 1, scores, topn)\n",
    "    return recommendations\n",
    "\n",
    "def topidx(a, topn):\n",
    "    parted = np.argpartition(a, -topn)[-topn:]\n",
    "    return parted[np.argsort(-a[parted])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb85fe62",
   "metadata": {
    "id": "LQaaMX1erOcc"
   },
   "source": [
    "# Popularity-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "11412e0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:11:45.116079Z",
     "start_time": "2022-03-24T12:11:45.108082Z"
    },
    "id": "oI3UZ4KMrR4i"
   },
   "outputs": [],
   "source": [
    "def build_popularity_model(trainset, trainset_description):\n",
    "    itemid = trainset_description['items']\n",
    "    item_popularity = trainset[itemid].value_counts()\n",
    "    return item_popularity\n",
    "\n",
    "def popularity_model_scoring(params, testset, testset_description):\n",
    "    item_popularity = params\n",
    "    n_items = item_popularity.index.max() + 1\n",
    "    n_users = testset_description['n_test_users']\n",
    "    # fill in popularity scores for each item with indices from 0 to n_items-1\n",
    "    popularity_scores = np.zeros(n_items,)\n",
    "    popularity_scores[item_popularity.index] = item_popularity.values\n",
    "    # same scores for each test user\n",
    "    scores = np.tile(popularity_scores, n_users).reshape(n_users, n_items)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0973652c",
   "metadata": {
    "id": "-c7NJyjoxbVF"
   },
   "source": [
    "# PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "254e24ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:11:46.267532Z",
     "start_time": "2022-03-24T12:11:46.254529Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHfx8WVYvJsQ",
    "outputId": "8791e807-11c9-41a1-c3a9-7b68cf85822d"
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), shape=(useridx.values.max() + 1, data_description[\"n_items\"]), dtype='f8')\n",
    "\n",
    "def build_svd_model(config, data, data_description):\n",
    "    source_matrix = matrix_from_observations(data, data_description)\n",
    "    #print(source_matrix.shape)\n",
    "    D = norm(source_matrix, axis=0)\n",
    "    A = source_matrix.dot(diags(D**(config['f']-1)))\n",
    "    _, _, vt = svds(A, k=config['rank'], return_singular_vectors='vh')\n",
    "#     singular_values = s[::-1]\n",
    "    item_factors = np.ascontiguousarray(vt[::-1, :].T)\n",
    "    return item_factors\n",
    "\n",
    "def svd_model_scoring(params, data, data_description):\n",
    "    item_factors = params\n",
    "    test_data = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    )\n",
    "    test_matrix = matrix_from_observations(test_data, data_description)\n",
    "    #print(test_matrix.shape, item_factors.shape)\n",
    "    scores = test_matrix.dot(item_factors) @ item_factors.T\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c793d6d2",
   "metadata": {
    "id": "RkKi34mwyWUo"
   },
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0390bf47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T10:15:25.329453Z",
     "start_time": "2022-03-24T10:15:25.314464Z"
    }
   },
   "outputs": [],
   "source": [
    "rank_grid = []\n",
    "for i in range(5, 9):\n",
    "    rank_grid.append(2 * 2 ** i)\n",
    "    rank_grid.append(3 * 2 ** i)\n",
    "    \n",
    "rank_grid = np.array(rank_grid)\n",
    "\n",
    "f_grid = np.linspace(0, 2, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9c32b98f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T10:38:55.267179Z",
     "start_time": "2022-03-24T10:18:22.838941Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [2:32:51<00:00, 54.59s/it]  \n"
     ]
    }
   ],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "C_tf = {}\n",
    "grid = list(zip(np.meshgrid(rank_grid, f_grid)[0].flatten(), np.meshgrid(rank_grid, f_grid)[1].flatten()))\n",
    "for params in tqdm(grid):\n",
    "    r, f = params\n",
    "    svd_config = {'rank': int(r), 'f': f}\n",
    "    svd_params = build_svd_model(svd_config, training, data_description)\n",
    "    svd_scores = svd_model_scoring(svd_params, testset_valid, data_description)\n",
    "    downvote_seen_items(svd_scores, testset_valid, data_description)\n",
    "    svd_recs = topn_recommendations(svd_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(svd_recs, holdout_valid, data_description, alpha=3, topn=10, dcg=False)\n",
    "    hr_tf[f'r={r}, f={f:.2f}'] = hr\n",
    "    mrr_tf[f'r={r}, f={f:.2f}'] = mrr\n",
    "    C_tf[f'r={r}, f={f:.2f}'] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "35eb31ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T10:40:21.195015Z",
     "start_time": "2022-03-24T10:40:21.183996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=768, f=0.20 0.09536384976525822\n",
      "r=512, f=0.20 0.09008215962441316\n",
      "r=512, f=0.30 0.08841940532081377\n",
      "r=384, f=0.30 0.08303990610328639\n",
      "r=256, f=0.30 0.08274647887323944\n",
      "r=192, f=0.30 0.0825508607198748\n",
      "r=768, f=0.30 0.0818661971830986\n",
      "r=384, f=0.40 0.07932316118935837\n",
      "r=512, f=0.40 0.07678012519561815\n",
      "r=384, f=0.20 0.07423708920187794\n"
     ]
    }
   ],
   "source": [
    "hr_sorted = sorted(hr_tf, key=hr_tf.get, reverse=True)\n",
    "for i in range(10):\n",
    "    print(hr_sorted[i], hr_tf[hr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8c3816c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T10:43:48.278788Z",
     "start_time": "2022-03-24T10:43:48.266777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=768, f=0.20 0.03897121152842984\n",
      "r=512, f=0.20 0.0366707963832377\n",
      "r=768, f=0.30 0.03602172448269866\n",
      "r=384, f=0.30 0.03497745733661226\n",
      "r=256, f=0.30 0.03472975196860174\n"
     ]
    }
   ],
   "source": [
    "mrr_sorted = sorted(mrr_tf, key=mrr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(mrr_sorted[i], mrr_tf[mrr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9280890b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T10:40:42.540415Z",
     "start_time": "2022-03-24T10:40:42.522418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=64, f=0.30 0.03387107526309943\n",
      "r=512, f=0.20 0.031697660905411346\n",
      "r=192, f=0.20 0.030905404823089885\n",
      "r=384, f=0.30 0.030312510030069694\n",
      "r=192, f=0.40 0.028456848830230315\n"
     ]
    }
   ],
   "source": [
    "C_sorted = sorted(C_tf, key=C_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(C_sorted[i], C_tf[C_sorted[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a0f03",
   "metadata": {},
   "source": [
    "# EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc4c4f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:42.931375Z",
     "start_time": "2022-04-30T17:28:42.912362Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), dtype='f8')\n",
    "\n",
    "\n",
    "def easer(data, data_description, lmbda=500):\n",
    "    X = matrix_from_observations(data, data_description)\n",
    "    G = X.T.dot(X)\n",
    "    diag_indices = np.diag_indices(G.shape[0])\n",
    "    G[diag_indices] += lmbda\n",
    "    P = np.linalg.inv(G.A)\n",
    "    B = P / (-np.diag(P))\n",
    "    B[diag_indices] = 0\n",
    "    \n",
    "    return B\n",
    "\n",
    "def easer_scoring(params, data, data_description):\n",
    "    item_factors = params\n",
    "    test_data = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    )\n",
    "    test_matrix = matrix_from_observations(test_data, data_description)\n",
    "    scores = test_matrix.dot(item_factors)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caeacd8",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78158d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:29:05.703035Z",
     "start_time": "2022-04-30T17:29:05.687790Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "lambda_grid = np.arange(50, 1000, 50)\n",
    "# lambda_grid = np.arange(5, 55, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7431e38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:33.869516Z",
     "start_time": "2022-04-30T17:29:07.413532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9f15fd1d9e4121a07337c589750c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "C_tf = {}\n",
    "for lmbda in tqdm(lambda_grid):\n",
    "    easer_params = easer(training, data_description, lmbda=lmbda)\n",
    "    easer_scores = easer_scoring(easer_params, testset_valid, data_description)\n",
    "    downvote_seen_items(easer_scores, testset_valid, data_description)\n",
    "    easer_recs = topn_recommendations(easer_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(easer_recs, holdout_valid, data_description, alpha=3, topn=10, dcg=False)\n",
    "    hr_tf[lmbda] = hr\n",
    "    mrr_tf[lmbda] = mrr\n",
    "    C_tf[lmbda] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68637351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:37.446640Z",
     "start_time": "2022-04-30T17:40:37.426657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 0.09956417192666066\n",
      "900 0.09941388638412985\n",
      "850 0.09926360084159903\n",
      "800 0.09918845807033363\n",
      "650 0.09888788698527202\n"
     ]
    }
   ],
   "source": [
    "hr_sorted = sorted(hr_tf, key=hr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(hr_sorted[i], hr_tf[hr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "825b9a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:38.445147Z",
     "start_time": "2022-04-30T17:40:38.426128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 0.04058896427020863\n",
      "900 0.040551422703135956\n",
      "850 0.0405415825783274\n",
      "800 0.040271247513132095\n",
      "700 0.04020275428075248\n"
     ]
    }
   ],
   "source": [
    "mrr_sorted = sorted(mrr_tf, key=mrr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(mrr_sorted[i], mrr_tf[mrr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "681085b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:39.287900Z",
     "start_time": "2022-04-30T17:40:39.277900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 0.09030209278823384\n",
      "950 0.08981499435721321\n",
      "500 0.08976855243668021\n",
      "600 0.08952405447091506\n",
      "650 0.08912827025284913\n"
     ]
    }
   ],
   "source": [
    "C_sorted = sorted(C_tf, key=C_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(C_sorted[i], C_tf[C_sorted[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb268de",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d58a16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:44.645953Z",
     "start_time": "2022-04-30T17:28:44.578485Z"
    }
   },
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    n_ratings = training['rating'].nunique(),\n",
    "    min_rating = training['rating'].min(),\n",
    "    test_users = holdout[data_index['users'].name].drop_duplicates().values,\n",
    "    n_test_users = holdout[data_index['users'].name].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d00e1",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "11dbb22e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:28:25.027454Z",
     "start_time": "2022-03-24T12:28:24.845212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0001, MRR@5 = 0.0000, Coverage@5 = 0.9608\n",
      "HR_pos@5 = 0.0001, HR_neg@5 = 0.0000\n",
      "MRR_pos@5 = 0.0000, MRR_neg@5 = 0.0000\n",
      "Matthews@5 = 0.0031\n",
      "-------------------------------------\n",
      "HR@10 = 0.0001, MRR@10 = 0.0000, Coverage@10 = 0.9984\n",
      "HR_pos@10 = 0.0001, HR_neg@10 = 0.0000\n",
      "MRR_pos@10 = 0.0000, MRR_neg@10 = 0.0000\n",
      "Matthews@10 = 0.0043\n",
      "-------------------------------------\n",
      "HR@20 = 0.0002, MRR@20 = 0.0000, Coverage@20 = 1.0000\n",
      "HR_pos@20 = 0.0002, HR_neg@20 = 0.0000\n",
      "MRR_pos@20 = 0.0000, MRR_neg@20 = 0.0000\n",
      "Matthews@20 = 0.0048\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rnd_params = build_random_model(training, data_description)\n",
    "rnd_scores = random_model_scoring(rnd_params, None, data_description)\n",
    "downvote_seen_items(rnd_scores, testset, data_description)\n",
    "\n",
    "_ = make_prediction(rnd_scores, holdout, data_description, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f23b25",
   "metadata": {},
   "source": [
    "## MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "35cc1a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:28:33.944233Z",
     "start_time": "2022-03-24T12:28:33.910186Z"
    }
   },
   "outputs": [],
   "source": [
    "pop_params = build_popularity_model(training, data_description)\n",
    "pop_scores = popularity_model_scoring(pop_params, None, data_description)\n",
    "downvote_seen_items(pop_scores, testset, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "602da32c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:28:34.431536Z",
     "start_time": "2022-03-24T12:28:34.320513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0269, MRR@5 = 0.0105, Coverage@5 = 0.0002\n",
      "HR_pos@5 = 0.0248, HR_neg@5 = 0.0021\n",
      "MRR_pos@5 = 0.0096, MRR_neg@5 = 0.0009\n",
      "Matthews@5 = 0.0203\n",
      "-------------------------------------\n",
      "HR@10 = 0.0380, MRR@10 = 0.0118, Coverage@10 = 0.0003\n",
      "HR_pos@10 = 0.0350, HR_neg@10 = 0.0030\n",
      "MRR_pos@10 = 0.0108, MRR_neg@10 = 0.0010\n",
      "Matthews@10 = 0.0239\n",
      "-------------------------------------\n",
      "HR@20 = 0.0448, MRR@20 = 0.0123, Coverage@20 = 0.0005\n",
      "HR_pos@20 = 0.0413, HR_neg@20 = 0.0035\n",
      "MRR_pos@20 = 0.0112, MRR_neg@20 = 0.0011\n",
      "Matthews@20 = 0.0261\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "_ = make_prediction(pop_scores, holdout, data_description, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791a7027",
   "metadata": {},
   "source": [
    "## PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fdf67972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T12:28:39.191316Z",
     "start_time": "2022-03-24T12:28:36.704692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'rank': 768, 'f': 0.2}, 'HR')\n",
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0600, MRR@5 = 0.0353, Coverage@5 = 0.1250\n",
      "HR_pos@5 = 0.0554, HR_neg@5 = 0.0046\n",
      "MRR_pos@5 = 0.0328, MRR_neg@5 = 0.0026\n",
      "Matthews@5 = 0.0317\n",
      "-------------------------------------\n",
      "HR@10 = 0.0906, MRR@10 = 0.0393, Coverage@10 = 0.1965\n",
      "HR_pos@10 = 0.0827, HR_neg@10 = 0.0079\n",
      "MRR_pos@10 = 0.0363, MRR_neg@10 = 0.0030\n",
      "Matthews@10 = 0.0293\n",
      "-------------------------------------\n",
      "HR@20 = 0.1247, MRR@20 = 0.0417, Coverage@20 = 0.2790\n",
      "HR_pos@20 = 0.1134, HR_neg@20 = 0.0113\n",
      "MRR_pos@20 = 0.0385, MRR_neg@20 = 0.0032\n",
      "Matthews@20 = 0.0305\n",
      "-------------------------------------\n",
      "({'rank': 768, 'f': 0.2}, 'MRR')\n",
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0600, MRR@5 = 0.0353, Coverage@5 = 0.1250\n",
      "HR_pos@5 = 0.0554, HR_neg@5 = 0.0046\n",
      "MRR_pos@5 = 0.0328, MRR_neg@5 = 0.0026\n",
      "Matthews@5 = 0.0317\n",
      "-------------------------------------\n",
      "HR@10 = 0.0907, MRR@10 = 0.0393, Coverage@10 = 0.1965\n",
      "HR_pos@10 = 0.0828, HR_neg@10 = 0.0079\n",
      "MRR_pos@10 = 0.0363, MRR_neg@10 = 0.0030\n",
      "Matthews@10 = 0.0295\n",
      "-------------------------------------\n",
      "HR@20 = 0.1249, MRR@20 = 0.0417, Coverage@20 = 0.2785\n",
      "HR_pos@20 = 0.1135, HR_neg@20 = 0.0113\n",
      "MRR_pos@20 = 0.0385, MRR_neg@20 = 0.0032\n",
      "Matthews@20 = 0.0306\n",
      "-------------------------------------\n",
      "({'rank': 64, 'f': 0.3}, 'MC')\n",
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0381, MRR@5 = 0.0273, Coverage@5 = 0.0147\n",
      "HR_pos@5 = 0.0357, HR_neg@5 = 0.0024\n",
      "MRR_pos@5 = 0.0256, MRR_neg@5 = 0.0017\n",
      "Matthews@5 = 0.0328\n",
      "-------------------------------------\n",
      "HR@10 = 0.0484, MRR@10 = 0.0287, Coverage@10 = 0.0266\n",
      "HR_pos@10 = 0.0450, HR_neg@10 = 0.0035\n",
      "MRR_pos@10 = 0.0268, MRR_neg@10 = 0.0018\n",
      "Matthews@10 = 0.0318\n",
      "-------------------------------------\n",
      "HR@20 = 0.0625, MRR@20 = 0.0296, Coverage@20 = 0.0454\n",
      "HR_pos@20 = 0.0582, HR_neg@20 = 0.0043\n",
      "MRR_pos@20 = 0.0277, MRR_neg@20 = 0.0019\n",
      "Matthews@20 = 0.0385\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for_hr = sorted(hr_tf, key=hr_tf.get, reverse=True)[0]\n",
    "for_mrr = sorted(mrr_tf, key=mrr_tf.get, reverse=True)[0]\n",
    "for_mc = sorted(C_tf, key=C_tf.get, reverse=True)[0]\n",
    "\n",
    "svd_config_hr = {'rank': int(for_hr.split(\",\")[0][2:]), 'f': float(for_hr.split(\",\")[1][3:])}\n",
    "svd_config_mrr = {'rank': int(for_mrr.split(\",\")[0][2:]), 'f': float(for_mrr.split(\",\")[1][3:])}\n",
    "svd_config_mc = {'rank': int(for_mc.split(\",\")[0][2:]), 'f': float(for_mc.split(\",\")[1][3:])}\n",
    "\n",
    "svd_configs = [(svd_config_hr, \"HR\"), (svd_config_mrr, \"MRR\"), (svd_config_mc, \"MC\")]\n",
    "\n",
    "for svd_config in svd_configs:\n",
    "    print(svd_config)\n",
    "    svd_params = build_svd_model(svd_config[0], training, data_description)\n",
    "    svd_scores = svd_model_scoring(svd_params, testset, data_description)\n",
    "    downvote_seen_items(svd_scores, testset, data_description)\n",
    "\n",
    "    _ = make_prediction(svd_scores, holdout, data_description, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcdd475",
   "metadata": {},
   "source": [
    "## CoFFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f3e9d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:22:31.187429Z",
     "start_time": "2022-04-27T15:22:26.955405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : HR@5 = 0.0247, MRR@5 = 0.0137, Coverage@5 = 0.1311, Matthews@5 = 0.0324\n",
      "HR_pos@5 = 0.0247, HR_neg@5 = 0.0000\n",
      "MRR_pos@5 = 0.0137, MRR_neg@5 = 0.0000\n",
      "\n",
      "Test : HR@10 = 0.0472, MRR@10 = 0.0166, Coverage@10 = 0.1779, Matthews@10 = 0.0316\n",
      "HR_pos@10 = 0.0472, HR_neg@10 = 0.0000\n",
      "MRR_pos@10 = 0.0166, MRR_neg@10 = 0.0000\n",
      "\n",
      "Test : HR@20 = 0.0880, MRR@20 = 0.0194, Coverage@20 = 0.2356, Matthews@20 = 0.0225\n",
      "HR_pos@20 = 0.0840, HR_neg@20 = 0.0040\n",
      "MRR_pos@20 = 0.0192, MRR_neg@20 = 0.0003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'mlrank': (50, 70, 2),\n",
    "    \"num_iters\": 5,\n",
    "}\n",
    "coffee_params = coffee_model_build(config, training, data_description)\n",
    "coffee_scores = coffee_scoring(coffee_params, testset, data_description)\n",
    "downvote_seen_items(coffee_scores, testset, data_description)\n",
    "\n",
    "make_prediction(coffee_scores, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450b03e",
   "metadata": {},
   "source": [
    "## EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acff584c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:41:36.021476Z",
     "start_time": "2022-04-30T17:40:57.644055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0624, MRR@5 = 0.0341, Coverage@5 = 0.1685\n",
      "HR_pos@5 = 0.0591, HR_neg@5 = 0.0033\n",
      "MRR_pos@5 = 0.0325, MRR_neg@5 = 0.0017\n",
      "Matthews@5 = 0.0638\n",
      "-------------------------------------\n",
      "HR@10 = 0.0957, MRR@10 = 0.0385, Coverage@10 = 0.2144\n",
      "HR_pos@10 = 0.0902, HR_neg@10 = 0.0055\n",
      "MRR_pos@10 = 0.0366, MRR_neg@10 = 0.0020\n",
      "Matthews@10 = 0.0757\n",
      "-------------------------------------\n",
      "HR@20 = 0.1472, MRR@20 = 0.0420, Coverage@20 = 0.2724\n",
      "HR_pos@20 = 0.1372, HR_neg@20 = 0.0100\n",
      "MRR_pos@20 = 0.0397, MRR_neg@20 = 0.0023\n",
      "Matthews@20 = 0.0844\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03852231077395159, 0.09568914081145584, 0.07568675740331703)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easer_params = easer(training, data_description, lmbda=550)\n",
    "easer_scores = easer_scoring(easer_params, testset, data_description)\n",
    "downvote_seen_items(easer_scores, testset, data_description)\n",
    "\n",
    "make_prediction(easer_scores, holdout, data_description, mode='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be789c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
