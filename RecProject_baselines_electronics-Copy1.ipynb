{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e4bdb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVoK_7xHdaa9",
    "outputId": "5068028f-6526-41db-ab84-9989d1f39bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polara\n",
      "  Cloning https://github.com/evfro/polara.git (to revision develop) to /tmp/pip-install-2y70x9ba/polara_606a3c3a2230448b9393ef034c0f5194\n",
      "  Running command git clone -q https://github.com/evfro/polara.git /tmp/pip-install-2y70x9ba/polara_606a3c3a2230448b9393ef034c0f5194\n",
      "  Running command git checkout -b develop --track origin/develop\n",
      "  Switched to a new branch 'develop'\n",
      "  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
      "  Resolved https://github.com/evfro/polara.git to commit 4de4ca7d6f901e32f1e045f190bcb09587162397\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ec3325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T16:43:36.002209Z",
     "start_time": "2022-04-30T16:43:35.991216Z"
    },
    "id": "o_HJgdQFdSaf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import polara\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, downvote_seen_items\n",
    "\n",
    "from polara.lib.tensor import hooi\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "from sa_hooi import sa_hooi, form_attention_matrix, get_scaling_weights, generate_position_projector\n",
    "\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from scipy.sparse.linalg import norm, svds\n",
    "from scipy.linalg import solve_triangular, sqrtm\n",
    "\n",
    "from IPython.utils import io\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import tempfile\n",
    "from ast import literal_eval\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679e379",
   "metadata": {
    "id": "4NbP1tmBdSas"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8c2ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T16:51:54.350815Z",
     "start_time": "2022-04-30T16:43:39.087184Z"
    },
    "code_folding": [
     0,
     5
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
      "Temporarily saved file at: C:\\Users\\Liza\\AppData\\Local\\Temp\\tmpmmbld0k2\n"
     ]
    }
   ],
   "source": [
    "def amazon_data_reader(path):\n",
    "    with gzip.open(path, 'rt') as gz:\n",
    "        for line in gz:\n",
    "            yield literal_eval(line)\n",
    "\n",
    "def read_amazon_data(path=None, name=None):\n",
    "    '''Data is taken from https://jmcauley.ucsd.edu/data/amazon/'''\n",
    "    if path is None and name is None:\n",
    "            raise ValueError('Either the name of the dataset to download \\\n",
    "                or a path to a local file must be specified.')\n",
    "    if path is None:\n",
    "        file_url = f'http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_{name}_5.json.gz'\n",
    "        print(f'Downloading data from: {file_url}')\n",
    "        with request.urlopen(file_url) as response:\n",
    "            file = response.read()\n",
    "            with tempfile.NamedTemporaryFile(delete=False) as temp:\n",
    "                temp.write(file)\n",
    "                path = temp.name\n",
    "                print(f'Temporarily saved file at: {path}')\n",
    "    return pd.DataFrame.from_records(\n",
    "        amazon_data_reader(path),\n",
    "        columns=['reviewerID', 'asin', 'overall', 'unixReviewTime']\n",
    "    )\n",
    "\n",
    "data = read_amazon_data(name = \"Electronics\")\n",
    "data.rename(columns = {'reviewerID' : 'userid', 'asin' : 'movieid', \"overall\" : \"rating\", \"unixReviewTime\" : \"timestamp\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8422efe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T16:52:10.442999Z",
     "start_time": "2022-04-30T16:52:10.422998Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def full_preproccessing(data = None):\n",
    "    if (data is None):\n",
    "        data = get_movielens_data(\"ml-10m.zip\", include_time=True)\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.8, interpolation='nearest'\n",
    "    )\n",
    "    \n",
    "    labels, levels = pd.factorize(data.movieid)\n",
    "    data.movieid = labels\n",
    "\n",
    "    labels, levels = pd.factorize(data.userid)\n",
    "    data.userid = labels\n",
    "    \n",
    "    if (data[\"rating\"].nunique() > 5):\n",
    "        data[\"rating\"] = data[\"rating\"] * 2\n",
    "        \n",
    "    data[\"rating\"] = data[\"rating\"].astype(int)\n",
    "\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "    train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    "    )\n",
    "    \n",
    "    training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "    test_data = reindex(test_data_, data_index['items'])\n",
    "\n",
    "    testset_, holdout_ = leave_one_out(\n",
    "    test_data, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "    testset_valid_, holdout_valid_ = leave_one_out(\n",
    "        testset_, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "\n",
    "    test_users_val = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset_valid = testset_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "    holdout_valid = holdout_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "\n",
    "    test_users = np.intersect1d(testset_.userid.unique(), holdout_.userid.unique())\n",
    "    testset = testset_.query('userid in @test_users').sort_values('userid')\n",
    "    holdout = holdout_.query('userid in @test_users').sort_values('userid')\n",
    "    \n",
    "    assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
    "        testset_valid\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "\n",
    "    data_description = dict(\n",
    "        users = data_index['users'].name,\n",
    "        items = data_index['items'].name,\n",
    "        feedback = 'rating',\n",
    "        n_users = len(data_index['users']),\n",
    "        n_items = len(data_index['items']),\n",
    "        n_ratings = training['rating'].nunique(),\n",
    "        min_rating = training['rating'].min(),\n",
    "        test_users = holdout_valid[data_index['users'].name].drop_duplicates().values, # NEW\n",
    "        n_test_users = holdout_valid[data_index['users'].name].nunique() # NEW\n",
    "    )\n",
    "\n",
    "    return training, testset_valid, holdout_valid, testset, holdout, data_description, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8736a448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T16:52:20.973612Z",
     "start_time": "2022-04-30T16:52:11.443478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 34993 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fff2ff",
   "metadata": {
    "id": "YJOfzHI5dSaz"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac713e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T16:52:46.578292Z",
     "start_time": "2022-04-30T16:52:46.553297Z"
    },
    "code_folding": [
     0,
     52,
     70
    ],
    "id": "nXnDXyWrdSbM"
   },
   "outputs": [],
   "source": [
    "def model_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10, dcg=False):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    alpha = 3 if holdout_description[\"n_ratings\"] == 5 else 6\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    holdout_items = holdout[itemid].values\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    \n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    \n",
    "    # HR calculation\n",
    "    #hr = np.sum(hits_mask.any(axis=1)) / n_test_users\n",
    "    hr_pos = np.sum(hits_mask[pos_mask].any(axis=1)) / n_test_users\n",
    "    hr_neg = np.sum(hits_mask[neg_mask].any(axis=1)) / n_test_users\n",
    "    hr = hr_pos + hr_neg\n",
    "    \n",
    "    # MRR calculation\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    mrr_pos = np.sum(1 / pos_hit_rank) / n_test_users\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    mrr_neg = np.sum(1 / neg_hit_rank) / n_test_users\n",
    "    \n",
    "    # Matthews correlation\n",
    "    TP = np.sum(hits_mask[pos_mask]) # + \n",
    "    FP = np.sum(hits_mask[neg_mask]) # +\n",
    "    cond = (hits_mask.sum(axis = 1) == 0)\n",
    "    FN = np.sum(cond[pos_mask])\n",
    "    TN = np.sum(cond[neg_mask])\n",
    "    N = TP+FP+TN+FN\n",
    "    S = (TP+FN)/N\n",
    "    P = (TP+FP)/N\n",
    "    C = (TP/N - S*P) / np.sqrt(P*S*(1-P)*(1-S))\n",
    "    \n",
    "    # DCG calculation\n",
    "    if dcg:\n",
    "        pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "        neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "        ndcg = np.mean(1 / np.log2(pos_hit_rank+1))\n",
    "        ndcl = np.mean(1 / np.log2(neg_hit_rank+1))\n",
    "    \n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    if dcg:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C, ndcg, ndcl\n",
    "    else:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C\n",
    "\n",
    "def make_prediction(tf_scores, holdout, data_description, mode, context=\"\", print_mode=True):\n",
    "    if (mode and print_mode):\n",
    "        print(f\"for context {context} evaluation ({mode}): \\n\")\n",
    "    for n in [5, 10, 20]:\n",
    "        tf_recs = topn_recommendations(tf_scores, n)\n",
    "        hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout, data_description, topn=n)\n",
    "        if (print_mode):\n",
    "            print(f\"HR@{n} = {hr:.4f}, MRR@{n} = {mrr:.4f}, Coverage@{n} = {cov:.4f}\")\n",
    "            print(f\"HR_pos@{n} = {hr_pos:.4f}, HR_neg@{n} = {hr_neg:.4f}\")\n",
    "            print(f\"MRR_pos@{n} = {mrr_pos:.4f}, MRR_neg@{n} = {mrr_neg:.4f}\")\n",
    "            print(f\"Matthews@{n} = {C:.4f}\")\n",
    "            print(\"-------------------------------------\")\n",
    "        if (n == 10):\n",
    "            mrr10 = mrr\n",
    "            hr10 = hr\n",
    "            c10 = C\n",
    "    return mrr10, hr10, c10\n",
    "\n",
    "def valid_mlrank(mlrank):\n",
    "    '''\n",
    "    Only allow ranks that are suitable for truncated SVD computations\n",
    "    on unfolded compressed tensor (the result of ttm product in HOOI).\n",
    "    '''\n",
    "    #s, r1, r2, r3 = mlrank\n",
    "    s, r1, r3 = mlrank\n",
    "    r2 = r1\n",
    "    #print(s, r1, r2, r3)\n",
    "    return r1*r2 > r3 and r1*r3 > r2 and r2*r3 > r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f4fced",
   "metadata": {},
   "source": [
    "# EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbb041d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T16:55:42.797770Z",
     "start_time": "2022-04-30T16:55:42.778770Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), dtype='f8')\n",
    "\n",
    "def easer(data, data_description, lmbda=500):\n",
    "    X = matrix_from_observations(data, data_description)\n",
    "    G = X.T.dot(X)\n",
    "    diag_indices = np.diag_indices(G.shape[0])\n",
    "    G[diag_indices] += lmbda\n",
    "    P = np.linalg.inv(G.A)\n",
    "    B = P / (-np.diag(P))\n",
    "    B[diag_indices] = 0\n",
    "    \n",
    "    return B\n",
    "\n",
    "def easer_scoring(params, data, data_description):\n",
    "    item_factors = params\n",
    "    test_data = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    )\n",
    "    test_matrix = matrix_from_observations(test_data, data_description)\n",
    "    scores = test_matrix.dot(item_factors)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d731d",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a796d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:29:05.703035Z",
     "start_time": "2022-04-30T17:29:05.687790Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "lambda_grid = np.arange(50, 1000, 50)\n",
    "# lambda_grid = np.arange(5, 55, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d0ab15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:33.869516Z",
     "start_time": "2022-04-30T17:29:07.413532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9f15fd1d9e4121a07337c589750c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "C_tf = {}\n",
    "for lmbda in tqdm(lambda_grid):\n",
    "    easer_params = easer(training, data_description, lmbda=lmbda)\n",
    "    easer_scores = easer_scoring(easer_params, testset_valid, data_description)\n",
    "    downvote_seen_items(easer_scores, testset_valid, data_description)\n",
    "    easer_recs = topn_recommendations(easer_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(easer_recs, holdout_valid, data_description, alpha=3, topn=10, dcg=False)\n",
    "    hr_tf[lmbda] = hr\n",
    "    mrr_tf[lmbda] = mrr\n",
    "    C_tf[lmbda] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be6b8335",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:37.446640Z",
     "start_time": "2022-04-30T17:40:37.426657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 0.09956417192666066\n",
      "900 0.09941388638412985\n",
      "850 0.09926360084159903\n",
      "800 0.09918845807033363\n",
      "650 0.09888788698527202\n"
     ]
    }
   ],
   "source": [
    "hr_sorted = sorted(hr_tf, key=hr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(hr_sorted[i], hr_tf[hr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591954b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:38.445147Z",
     "start_time": "2022-04-30T17:40:38.426128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 0.04058896427020863\n",
      "900 0.040551422703135956\n",
      "850 0.0405415825783274\n",
      "800 0.040271247513132095\n",
      "700 0.04020275428075248\n"
     ]
    }
   ],
   "source": [
    "mrr_sorted = sorted(mrr_tf, key=mrr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(mrr_sorted[i], mrr_tf[mrr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f486694",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:40:39.287900Z",
     "start_time": "2022-04-30T17:40:39.277900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 0.09030209278823384\n",
      "950 0.08981499435721321\n",
      "500 0.08976855243668021\n",
      "600 0.08952405447091506\n",
      "650 0.08912827025284913\n"
     ]
    }
   ],
   "source": [
    "C_sorted = sorted(C_tf, key=C_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(C_sorted[i], C_tf[C_sorted[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638e269",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24b6f029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T16:59:44.064861Z",
     "start_time": "2022-04-30T16:59:44.043861Z"
    }
   },
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    n_ratings = training['rating'].nunique(),\n",
    "    min_rating = training['rating'].min(),\n",
    "    test_users = holdout[data_index['users'].name].drop_duplicates().values,\n",
    "    n_test_users = holdout[data_index['users'].name].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e986c763",
   "metadata": {},
   "source": [
    "## EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b907d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:01:06.691289Z",
     "start_time": "2022-04-30T17:01:06.100293Z"
    }
   },
   "outputs": [],
   "source": [
    "easer_params = easer(training, data_description, lmbda=C_sorted[i])\n",
    "easer_scores = easer_scoring(easer_params, testset, data_description)\n",
    "downvote_seen_items(easer_scores, testset, data_description)\n",
    "\n",
    "make_prediction(easer_scores, holdout, data_description, mode='Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.306px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
