{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6zfbrvMoy9Ed"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:00.631543Z",
     "start_time": "2022-04-27T15:27:59.591272Z"
    },
    "id": "Jd1axtgLy9Id"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import polara\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "from polara.evaluation.pipelines import random_grid\n",
    "from polara.lib.tensor import hooi\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items\n",
    "from sa_hooi import sa_hooi, form_attention_matrix, get_scaling_weights, generate_position_projector\n",
    "\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.linalg import solve_triangular\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, rbf_kernel, laplacian_kernel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:01.880683Z",
     "start_time": "2022-04-27T15:28:01.771682Z"
    },
    "code_folding": [],
    "id": "SM-pkXQx1GwO"
   },
   "outputs": [],
   "source": [
    "def model_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10, dcg=False):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    holdout_items = holdout[itemid].values\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    \n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    \n",
    "    # HR calculation\n",
    "    hr = np.sum(hits_mask.any(axis=1)) / n_test_users\n",
    "    hr_pos = np.sum(hits_mask[pos_mask].any(axis=1)) / n_test_users\n",
    "    hr_neg = np.sum(hits_mask[neg_mask].any(axis=1)) / n_test_users\n",
    "    \n",
    "    # MRR calculation\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    mrr_pos = np.sum(1 / pos_hit_rank) / n_test_users\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    mrr_neg = np.sum(1 / neg_hit_rank) / n_test_users\n",
    "    \n",
    "    # Matthews correlation\n",
    "    TP = np.sum(hits_mask[pos_mask])\n",
    "    FP = np.sum(hits_mask[neg_mask])\n",
    "    FN = np.sum(~hits_mask[pos_mask])\n",
    "    TN = np.sum(~hits_mask[neg_mask])\n",
    "    N = TP+FP+TN+FN\n",
    "    S = (TP+FN)/N\n",
    "    P = (TP+FP)/N\n",
    "    C = (TP/N - S*P) / np.sqrt(P*S*(1-P)*(1-S))\n",
    "    \n",
    "    # DCG calculation\n",
    "    if dcg:\n",
    "        pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "        neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "        ndcg = np.sum(1 / np.log2(pos_hit_rank+1)) / n_test_users\n",
    "        ndcl = np.sum(1 / np.log2(neg_hit_rank+1)) / n_test_users\n",
    "    \n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    if dcg:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C, ndcg, ndcl\n",
    "    else:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:03.007743Z",
     "start_time": "2022-04-27T15:28:02.908653Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def split_holdout(\n",
    "        data,\n",
    "        n=5,\n",
    "        key = 'userid',\n",
    "        target = None,\n",
    "        sample_top = False,\n",
    "        random_state = None\n",
    "    ):\n",
    "    '''\n",
    "    Samples 1 item per every user according to the rule `sample_top`.\n",
    "    It always shuffles the input data. The reason is that even if sampling\n",
    "    top-rated elements, there could be several items with the same top rating.\n",
    "    '''\n",
    "    if sample_top: # sample item with the highest target value (e.g., rating, time, etc.)\n",
    "        idx = (\n",
    "            data[target]\n",
    "            .sample(frac=1, random_state=random_state) # handle same feedback for different items\n",
    "            .groupby(data[key], sort=False)\n",
    "            .nlargest(n)\n",
    "            .reset_index()\n",
    "            .level_1\n",
    "        ).values\n",
    "    else: # sample random item\n",
    "        idx = (\n",
    "            data[key]\n",
    "            .sample(frac=1, random_state=random_state)\n",
    "            .groupby(data[key], sort=False)\n",
    "            .sample(n) # data is shuffled - simply take the 1st element\n",
    "            .index\n",
    "        ).values\n",
    "\n",
    "    observed = data.drop(idx)\n",
    "    holdout = data.loc[idx]\n",
    "    return observed, holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:03.723287Z",
     "start_time": "2022-04-27T15:28:03.603289Z"
    },
    "code_folding": [
     0
    ],
    "id": "BDtwh0bdy9Mk"
   },
   "outputs": [],
   "source": [
    "def full_preproccessing(n=1):\n",
    "    data = get_movielens_data('ml-1m.zip', include_time=True)\n",
    "#     data['rating'] = data['rating'].apply(lambda x: np.arctan(x-3)+3)\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.8, interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "    train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    "    )\n",
    "    \n",
    "    training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "    test_data = reindex(test_data_, data_index['items'])\n",
    "\n",
    "    testset_, holdout_ = split_holdout(\n",
    "    test_data, n=n, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "    testset_valid_, holdout_valid_ = split_holdout(\n",
    "        testset_, n=n, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "\n",
    "    test_users_val = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset_valid = testset_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "    holdout_valid = holdout_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "\n",
    "    test_users = np.intersect1d(testset_.userid.unique(), holdout_.userid.unique())\n",
    "    testset = testset_.query('userid in @test_users').sort_values('userid')\n",
    "    holdout = holdout_.query('userid in @test_users').sort_values('userid')\n",
    "\n",
    "\n",
    "    assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
    "        testset_valid\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "    \n",
    "    assert holdout.set_index('userid')['timestamp'].ge(\n",
    "        testset\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "\n",
    "    data_description = dict(\n",
    "        users = data_index['users'].name,\n",
    "        items = data_index['items'].name,\n",
    "        feedback = 'rating',\n",
    "        n_users = len(data_index['users']),\n",
    "        n_items = len(data_index['items']),\n",
    "        n_ratings = training['rating'].nunique(),\n",
    "        min_rating = training['rating'].min()\n",
    "    )\n",
    "\n",
    "    return training, testset_valid, holdout_valid, testset, holdout, data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:07.716564Z",
     "start_time": "2022-04-27T15:28:05.605902Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmYMpvcBy9QZ",
    "outputId": "bd702bab-2522-40a6-91df-ea8da2ceeede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 177 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description = full_preproccessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:08.618328Z",
     "start_time": "2022-04-27T15:28:08.508326Z"
    },
    "code_folding": [
     2
    ],
    "id": "SM-pkXQx1GwO"
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "def tf_model_build(config, data, data_description, attention_matrix=np.array([])):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    if (attention_matrix.shape[0] == 0):\n",
    "        attention_matrix = form_attention_matrix(\n",
    "            data_description['n_ratings'],\n",
    "            **config['params'],\n",
    "            format = 'csr'\n",
    "        ).A\n",
    "\n",
    "    item_popularity = (\n",
    "        data[itemid]\n",
    "        .value_counts(sort=False)\n",
    "        .reindex(range(n_items))\n",
    "        .fillna(1)\n",
    "        .values\n",
    "    )\n",
    "    scaling_weights = get_scaling_weights(item_popularity, scaling=config[\"scaling\"])\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        u0, u1, u2 = sa_hooi(\n",
    "            idx, val, shape, config[\"mlrank\"],\n",
    "            attention_matrix = attention_matrix,\n",
    "            scaling_weights = scaling_weights,\n",
    "            max_iters = config[\"num_iters\"],\n",
    "            parallel_ttm = False,\n",
    "            randomized = config[\"randomized\"],\n",
    "            growth_tol = config[\"growth_tol\"],\n",
    "            seed = config[\"seed\"],\n",
    "            iter_callback = None,\n",
    "        )\n",
    "    \n",
    "    return u0, u1, u2, attention_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:09.613111Z",
     "start_time": "2022-04-27T15:28:09.509109Z"
    },
    "id": "SM-pkXQx1GwO"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"mlrank\": (30, 30, 5),\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 3,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:10.323121Z",
     "start_time": "2022-04-27T15:28:10.219125Z"
    },
    "code_folding": [
     0
    ],
    "id": "SM-pkXQx1GwO"
   },
   "outputs": [],
   "source": [
    "def tf_scoring(params, data, data_description, context=[\"3+4+5\"]):\n",
    "    user_factors, item_factors, feedback_factors, attention_matrix = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid)\n",
    "    useridx = data[userid]\n",
    "    itemidx = data[itemid].values\n",
    "    ratings = data[feedback].values\n",
    "    ratings = ratings - data_description['min_rating']\n",
    "    \n",
    "    n_users = useridx.nunique()\n",
    "    n_items = data_description['n_items']\n",
    "    n_ratings = data_description['n_ratings']\n",
    "    \n",
    "    #inv_attention = np.linalg.inv(attention_matrix.A) # change\n",
    "    inv_attention = solve_triangular(attention_matrix, np.eye(5), lower=True)\n",
    "    #np.testing.assert_almost_equal(inv_attention, inv_attention_)\n",
    "    \n",
    "    tensor_outer = tensor_outer_at('cpu')\n",
    "    \n",
    "    if (context == \"5\"):\n",
    "        inv_aT_feedback = (inv_attention.T @ feedback_factors)[-1, :]\n",
    "    elif (context == \"4+5\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-2:, :], axis=0)\n",
    "    elif (context == \"3+4+5\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-3:, :], axis=0)\n",
    "    elif (context == \"2+3+4+5\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-4:, :], axis=0)\n",
    "    elif (context == \"3+4+5-2-1\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-3:, :], axis=0) - np.sum((inv_attention.T @ feedback_factors)[:2, :], axis=0)\n",
    "    else:\n",
    "        inv_aT_feedback = (inv_attention.T @ feedback_factors)[-1, :]\n",
    "        \n",
    "    scores = tensor_outer(\n",
    "        1.0,\n",
    "        item_factors,\n",
    "        attention_matrix @ feedback_factors,\n",
    "        itemidx,\n",
    "        ratings\n",
    "    )\n",
    "    scores = np.add.reduceat(scores, np.r_[0, np.where(np.diff(useridx))[0]+1]) # sort by users\n",
    "    scores = np.tensordot(\n",
    "        scores,\n",
    "        inv_aT_feedback,\n",
    "        axes=(2, 0)\n",
    "    ).dot(item_factors.T)\n",
    "\n",
    "#     scores = np.zeros((n_users, n_items))\n",
    "#     print(scores.shape)\n",
    "#     #inv_attention = np.linalg.inv(attention_matrix.A)\n",
    "#     for i, u in tqdm(enumerate(np.unique(useridx))):\n",
    "#         data_u = data[data.userid==u]\n",
    "#         P = csr_matrix((np.ones(data_u.shape[0]), (data_u[itemid].values, data_u[feedback].values - data_description['min_rating'])), (n_items, n_ratings))\n",
    "#         res = item_factors @ (item_factors.T @ (P @ (attention_matrix @ (feedback_factors @ (inv_attention.T @ feedback_factors).T))))\n",
    "#         if (context == \"5\"):\n",
    "#             scores[i] = np.sum(res[:, -1:], axis=1)\n",
    "#         elif (context == \"4+5\"):\n",
    "#             scores[i] = np.sum(res[:, -2:], axis=1)\n",
    "#         elif (context == \"3+4+5\"):\n",
    "#             scores[i] = np.sum(res[:, -3:], axis=1)\n",
    "#         elif (context == \"2+3+4+5\"):\n",
    "#             scores[i] = np.sum(res[:, -4:], axis=1)\n",
    "#         elif (context == \"3+4+5-2-1\"):\n",
    "#             scores[i] = np.sum(res[:, 2:], axis=1) - np.sum(res[:, :2], axis=1)\n",
    "        \n",
    "#     if (context == \"4+5\"):\n",
    "#         np.testing.assert_almost_equal(scores, scores_)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:11.005644Z",
     "start_time": "2022-04-27T15:28:10.898643Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def best_num_iter_sa_hooi(config, training, data_description, attention_matrix, testset, holdout):\n",
    "    # Calculate optimal number of iteration for each context for metrics : MRR@10, HR@10\n",
    "    # Input:\n",
    "    # config - dict of params\n",
    "    # training - training dataset\n",
    "    # data_description - dict of data_description\n",
    "    # attention_matrix - attention_matrix which will be used in sa_hooi algo\n",
    "    # testset - test or validation part of dataset\n",
    "    # holdout - holdout which corresponding to users from testset\n",
    "    \n",
    "    print(\"Starting tuning number of iteration in sa_hooi algo...\\n\")\n",
    "    init_max_iter = config[\"num_iters\"]\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"2+3+4+5\", \"3+4+5-2-1\"]:\n",
    "        best_mrr, best_hr = -1, -1\n",
    "        for max_iter in range(1, 10):\n",
    "            config[\"num_iters\"] = max_iter\n",
    "            tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "            tf_scores = tf_scoring(tf_params, testset, data_description, context)\n",
    "            downvote_seen_items(tf_scores, testset, data_description)\n",
    "            cur_mrr, cur_hr = make_prediction(tf_scores, holdout, data_description, \"Validation\", context, print_mode=False)\n",
    "            if (cur_mrr > best_mrr):\n",
    "                best_mrr = cur_mrr\n",
    "                best_iter_mrr = max_iter\n",
    "            if (cur_hr > best_hr):\n",
    "                best_hr = cur_hr\n",
    "                best_iter_hr = max_iter\n",
    "            \n",
    "        print(f\"For context '{context}' the following parameters were found:\")\n",
    "        print(f\"\\tFor HR@10 ({best_hr:.4f}) -- number of iteration is {best_iter_hr}\")\n",
    "        print(f\"\\tFor MRR@10 ({best_mrr:.4f}) -- number of iteration is {best_iter_mrr}\")\n",
    "        print(\"------------------------------------------------------\\n\")\n",
    "    config[\"num_iters\"] = init_max_iter\n",
    "    print(\"Tuning ended.\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:11.620311Z",
     "start_time": "2022-04-27T15:28:11.512315Z"
    },
    "code_folding": [
     0
    ],
    "id": "3p0AyeCf3QVU"
   },
   "outputs": [],
   "source": [
    "def full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix):\n",
    "\n",
    "    config[\"mlrank\"] = (30, 30, 5)\n",
    "    print(\"Starting pipeline...\")\n",
    "    print(\"Training with different context in progress...\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    best_mrr_context = \"3+4+5\"\n",
    "    best_mrr = 0.0\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"2+3+4+5\", \"3+4+5-2-1\"]:\n",
    "        tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "        seen_data = testset_valid\n",
    "        tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "        downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "        cur_mrr, cur_hr = make_prediction(tf_scores, holdout_valid, data_description, \"Validation\", context)\n",
    "        print(\"------------------------------------------------------\")\n",
    "        if (cur_mrr > best_mrr):\n",
    "            best_mrr = cur_mrr\n",
    "            best_mrr_context = context\n",
    "\n",
    "    best_mrr_context = \"3+4+5\" # intuitively this is better \n",
    "    #print(f\"Tuning model with context {best_mrr_context}...\")\n",
    "    print(f\"Tuning model for all contexts...\\n\")\n",
    "\n",
    "    tf_hyper = {\n",
    "    'scaling': np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]),\n",
    "    'r1': np.arange(100, 301, 25),\n",
    "    #'r2': np.arange(50, 801, 25),\n",
    "    'r3': range(2, 6, 1),\n",
    "    }\n",
    "\n",
    "    grid, param_names = random_grid(tf_hyper, n=0)\n",
    "    tf_grid = [tuple(mlrank) for mlrank in grid if valid_mlrank(mlrank)]\n",
    "\n",
    "    hr_tf = {}\n",
    "    hr_pos_tf = {}\n",
    "    hr_neg_tf = {}\n",
    "    mrr_tf = {}\n",
    "    mrr_pos_tf = {}\n",
    "    mrr_neg_tf = {}\n",
    "    cov_tf = {}\n",
    "    \n",
    "    seen_data = testset_valid\n",
    "    \n",
    "    for mlrank in tqdm(tf_grid):\n",
    "        with io.capture_output() as captured:\n",
    "            r1, r3 = mlrank[1:]\n",
    "            cur_mlrank = tuple((r1, r1, r3))\n",
    "            config['mlrank'] = cur_mlrank\n",
    "            config['scaling'] = mlrank[0]\n",
    "            tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "            for context in [\"5\", \"4+5\", \"3+4+5\", \"2+3+4+5\", \"3+4+5-2-1\"]:\n",
    "                tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "                downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "                tf_recs = topn_recommendations(tf_scores, topn=10)\n",
    "                \n",
    "                hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov = model_evaluate(tf_recs, holdout_valid, data_description, topn=10)\n",
    "                hr_tf[(context, cur_mlrank, mlrank[0])] = hr\n",
    "                hr_pos_tf[(context, cur_mlrank, mlrank[0])] = hr_pos\n",
    "                hr_neg_tf[(context, cur_mlrank, mlrank[0])] = hr_neg\n",
    "                mrr_tf[(context, cur_mlrank, mlrank[0])] = mrr\n",
    "                mrr_pos_tf[(context, cur_mlrank, mlrank[0])] = mrr_pos\n",
    "                mrr_neg_tf[(context, cur_mlrank, mlrank[0])] = mrr_neg\n",
    "                cov_tf[(context, cur_mlrank, mlrank[0])] = cov\n",
    "\n",
    "    print(f'Best HR={pd.Series(hr_tf).max():.4f} achieved with context {pd.Series(hr_tf).idxmax()[0]} and mlrank = {pd.Series(hr_tf).idxmax()[1]} and scale factor = {pd.Series(hr_tf).idxmax()[2]}')\n",
    "    print(f'Best HR_pos={pd.Series(hr_pos_tf).max():.4f} achieved with context {pd.Series(hr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(hr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(hr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best HR={pd.Series(hr_neg_tf).max():.4f} achieved with context {pd.Series(hr_neg_tf).idxmax()[0]} and mlrank = {pd.Series(hr_neg_tf).idxmax()[1]} and scale factor = {pd.Series(hr_neg_tf).idxmax()[2]}')\n",
    "    \n",
    "    print(f'Best MRR={pd.Series(mrr_tf).max():.4f} achieved with context {pd.Series(mrr_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR={pd.Series(mrr_pos_tf).max():.4f} achieved with context {pd.Series(mrr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR={pd.Series(mrr_neg_tf).max():.4f} achieved with context {pd.Series(mrr_neg_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_neg_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_neg_tf).idxmax()[2]}')\n",
    "                          \n",
    "    print(f'COV={pd.Series(cov_tf)[pd.Series(mrr_tf).idxmax()]:.4f} (based on best MRR value)')\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"Evaluation of the best model on test holdout in progress...\\n\")\n",
    "    \n",
    "    print(\"Best by MRR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(mrr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by HR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(hr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    print(\"Pipeline ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAJa3SH0_RNF"
   },
   "source": [
    "## Linear attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T16:00:20.409030Z",
     "start_time": "2022-04-24T16:00:20.313030Z"
    },
    "id": "VpdpVwzd-lwL"
   },
   "outputs": [],
   "source": [
    "linear_attentions_list = [\n",
    "    {'decay_factor': 1, 'exponential_decay': False, 'reverse': False},\n",
    "    #{'decay_factor': 1, 'exponential_decay': False, 'reverse': False},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T16:31:14.256214Z",
     "start_time": "2022-04-24T16:04:34.823282Z"
    },
    "code_folding": [
     0
    ],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkAHiLwl-lwL",
    "outputId": "1157331d-951f-44ef-befc-0caeb4e7a357",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n",
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0153, Coverage@5 = 0.1230\n",
      "HR_pos@5 = 0.0388, HR_neg@5 = 0.0070\n",
      "MRR_pos@5 = 0.0151, MRR_neg@5 = 0.0002\n",
      "Test : HR@10 = 0.0616, MRR@10 = 0.0191, Coverage@10 = 0.1754\n",
      "HR_pos@10 = 0.0719, HR_neg@10 = 0.0105\n",
      "MRR_pos@10 = 0.0188, MRR_neg@10 = 0.0003\n",
      "Test : HR@20 = 0.1044, MRR@20 = 0.0219, Coverage@20 = 0.2409\n",
      "HR_pos@20 = 0.1163, HR_neg@20 = 0.0455\n",
      "MRR_pos@20 = 0.0212, MRR_neg@20 = 0.0007\n",
      "------------------------------------------------------\n",
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0381, MRR@5 = 0.0190, Coverage@5 = 0.1255\n",
      "HR_pos@5 = 0.0444, HR_neg@5 = 0.0070\n",
      "MRR_pos@5 = 0.0181, MRR_neg@5 = 0.0009\n",
      "Test : HR@10 = 0.0622, MRR@10 = 0.0223, Coverage@10 = 0.1729\n",
      "HR_pos@10 = 0.0712, HR_neg@10 = 0.0175\n",
      "MRR_pos@10 = 0.0212, MRR_neg@10 = 0.0011\n",
      "Test : HR@20 = 0.1144, MRR@20 = 0.0258, Coverage@20 = 0.2376\n",
      "HR_pos@20 = 0.1261, HR_neg@20 = 0.0559\n",
      "MRR_pos@20 = 0.0243, MRR_neg@20 = 0.0015\n",
      "------------------------------------------------------\n",
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0393, MRR@5 = 0.0197, Coverage@5 = 0.1355\n",
      "HR_pos@5 = 0.0430, HR_neg@5 = 0.0210\n",
      "MRR_pos@5 = 0.0170, MRR_neg@5 = 0.0027\n",
      "Test : HR@10 = 0.0680, MRR@10 = 0.0234, Coverage@10 = 0.1829\n",
      "HR_pos@10 = 0.0761, HR_neg@10 = 0.0280\n",
      "MRR_pos@10 = 0.0206, MRR_neg@10 = 0.0028\n",
      "Test : HR@20 = 0.1232, MRR@20 = 0.0271, Coverage@20 = 0.2479\n",
      "HR_pos@20 = 0.1339, HR_neg@20 = 0.0699\n",
      "MRR_pos@20 = 0.0238, MRR_neg@20 = 0.0033\n",
      "------------------------------------------------------\n",
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0381, MRR@5 = 0.0192, Coverage@5 = 0.1431\n",
      "HR_pos@5 = 0.0409, HR_neg@5 = 0.0245\n",
      "MRR_pos@5 = 0.0169, MRR_neg@5 = 0.0022\n",
      "Test : HR@10 = 0.0669, MRR@10 = 0.0228, Coverage@10 = 0.1924\n",
      "HR_pos@10 = 0.0747, HR_neg@10 = 0.0280\n",
      "MRR_pos@10 = 0.0205, MRR_neg@10 = 0.0023\n",
      "Test : HR@20 = 0.1214, MRR@20 = 0.0265, Coverage@20 = 0.2526\n",
      "HR_pos@20 = 0.1304, HR_neg@20 = 0.0769\n",
      "MRR_pos@20 = 0.0237, MRR_neg@20 = 0.0029\n",
      "------------------------------------------------------\n",
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0370, MRR@5 = 0.0185, Coverage@5 = 0.1339\n",
      "HR_pos@5 = 0.0423, HR_neg@5 = 0.0105\n",
      "MRR_pos@5 = 0.0175, MRR_neg@5 = 0.0010\n",
      "Test : HR@10 = 0.0651, MRR@10 = 0.0221, Coverage@10 = 0.1813\n",
      "HR_pos@10 = 0.0754, HR_neg@10 = 0.0140\n",
      "MRR_pos@10 = 0.0210, MRR_neg@10 = 0.0011\n",
      "Test : HR@20 = 0.1132, MRR@20 = 0.0253, Coverage@20 = 0.2457\n",
      "HR_pos@20 = 0.1268, HR_neg@20 = 0.0455\n",
      "MRR_pos@20 = 0.0239, MRR_neg@20 = 0.0014\n",
      "------------------------------------------------------\n",
      "Tuning model for all contexts...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e5bb8c1237452bb28a6d9c603dc7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#best_num_iter_sa_hooi(config, training, data_description, np.array([]), testset_valid, holdout_valid)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mfull_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mfull_pipeline\u001b[1;34m(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)\u001b[0m\n\u001b[0;32m     50\u001b[0m tf_params \u001b[38;5;241m=\u001b[39m tf_model_build(config, training, data_description, attention_matrix\u001b[38;5;241m=\u001b[39mattention_matrix)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4+5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3+4+5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2+3+4+5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3+4+5-2-1\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 52\u001b[0m     tf_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtf_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseen_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     downvote_seen_items(tf_scores, seen_data, data_description)\n\u001b[0;32m     54\u001b[0m     tf_recs \u001b[38;5;241m=\u001b[39m topn_recommendations(tf_scores, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mtf_scoring\u001b[1;34m(params, data, data_description, context)\u001b[0m\n\u001b[0;32m     32\u001b[0m         inv_aT_feedback \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((inv_attention\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m feedback_factors)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum((inv_attention\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m feedback_factors)[:\u001b[38;5;241m2\u001b[39m, :], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m     scores \u001b[38;5;241m=\u001b[39m tensor_outer(\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     36\u001b[0m         item_factors,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m         ratings\n\u001b[0;32m     40\u001b[0m     )\n\u001b[1;32m---> 41\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduceat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43museridx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# sort by users\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtensordot(\n\u001b[0;32m     43\u001b[0m         scores,\n\u001b[0;32m     44\u001b[0m         inv_aT_feedback,\n\u001b[0;32m     45\u001b[0m         axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     46\u001b[0m     )\u001b[38;5;241m.\u001b[39mdot(item_factors\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#     scores = np.zeros((n_users, n_items))\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#     print(scores.shape)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#     #inv_attention = np.linalg.inv(attention_matrix.A)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#     if (context == \"4+5\"):\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#         np.testing.assert_almost_equal(scores, scores_)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for params in linear_attentions_list:\n",
    "    \n",
    "    config[\"params\"] = params\n",
    "    \n",
    "    #best_num_iter_sa_hooi(config, training, data_description, np.array([]), testset_valid, holdout_valid)\n",
    "    full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:07:51.621153Z",
     "start_time": "2022-04-24T20:07:51.506579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.85, 0.5 , 0.1 , 0.  ],\n",
       "       [0.85, 1.  , 0.65, 0.2 , 0.05],\n",
       "       [0.5 , 0.65, 1.  , 0.75, 0.2 ],\n",
       "       [0.1 , 0.2 , 0.75, 1.  , 0.85],\n",
       "       [0.  , 0.05, 0.2 , 0.85, 1.  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = np.array([[1, 0.85, 0.5, 0.1, 0], [0.85, 1, 0.65, 0.2, 0.05], [0.5, 0.65, 1, 0.75, 0.2], [0.1, 0.2, 0.75, 1, 0.85], [0, 0.05, 0.2, 0.85, 1]])\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:07:52.332051Z",
     "start_time": "2022-04-24T20:07:52.216343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86030365,  0.46408882,  0.21104287, -0.0075498 , -0.00117653],\n",
       "       [ 0.46408882,  0.8228861 ,  0.32961986,  0.02604066,  0.02409949],\n",
       "       [ 0.21104287,  0.32961986,  0.79451066,  0.48479688, -0.0301396 ],\n",
       "       [-0.0075498 ,  0.02604066,  0.48479688,  0.71597228,  0.53580926],\n",
       "       [-0.00117653,  0.02409949, -0.0301396 ,  0.53580926,  0.85263566]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "attention_matrix = scipy.linalg.sqrtm(similarity_matrix).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n",
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0161, Coverage@5 = 0.1062, nDCG@5 = 0.01947, nDCL@5 = 0.00000\n",
      "Test : HR@10 = 0.0624, MRR@10 = 0.0203, Coverage@10 = 0.1475, nDCG@10 = 0.02957, nDCL@10 = 0.00029\n",
      "Test : HR@20 = 0.0994, MRR@20 = 0.0228, Coverage@20 = 0.2039, nDCG@20 = 0.03734, nDCL@20 = 0.00183\n",
      "------------------------------------------------------\n",
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0175, Coverage@5 = 0.1078, nDCG@5 = 0.02008, nDCL@5 = 0.00044\n",
      "Test : HR@10 = 0.0668, MRR@10 = 0.0223, Coverage@10 = 0.1486, nDCG@10 = 0.03109, nDCL@10 = 0.00126\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0260, Coverage@20 = 0.1997, nDCG@20 = 0.04317, nDCL@20 = 0.00261\n",
      "------------------------------------------------------\n",
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0169, Coverage@5 = 0.1125, nDCG@5 = 0.01963, nDCL@5 = 0.00044\n",
      "Test : HR@10 = 0.0677, MRR@10 = 0.0219, Coverage@10 = 0.1549, nDCG@10 = 0.03154, nDCL@10 = 0.00073\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0255, Coverage@20 = 0.2074, nDCG@20 = 0.04259, nDCL@20 = 0.00274\n",
      "------------------------------------------------------\n",
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 = 0.0182, Coverage@5 = 0.1180, nDCG@5 = 0.02078, nDCL@5 = 0.00044\n",
      "Test : HR@10 = 0.0660, MRR@10 = 0.0227, Coverage@10 = 0.1612, nDCG@10 = 0.03144, nDCL@10 = 0.00099\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0265, Coverage@20 = 0.2171, nDCG@20 = 0.04285, nDCL@20 = 0.00320\n",
      "------------------------------------------------------\n",
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0281, MRR@5 = 0.0160, Coverage@5 = 0.1122, nDCG@5 = 0.01897, nDCL@5 = 0.00000\n",
      "Test : HR@10 = 0.0624, MRR@10 = 0.0206, Coverage@10 = 0.1530, nDCG@10 = 0.02941, nDCL@10 = 0.00061\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0245, Coverage@20 = 0.2050, nDCG@20 = 0.04208, nDCL@20 = 0.00232\n",
      "------------------------------------------------------\n",
      "Tuning model for all contexts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/324 [02:20<12:35:38, 140.37s/it]"
     ]
    }
   ],
   "source": [
    "config[\"params\"] = {}\n",
    "\n",
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHY4qoqt_aEi"
   },
   "source": [
    "## Exponential attention, decay factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX1ein75-lwN"
   },
   "outputs": [],
   "source": [
    "exponential_attentions_list = [\n",
    "    {'decay_factor': 1, 'exponential_decay': True, 'reverse': True},\n",
    "    {'decay_factor': 1, 'exponential_decay': True, 'reverse': False}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARiPOSQn-lwO",
    "outputId": "bf3c637c-55b2-4525-e81d-d8fa13ca6f9f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1346.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0162, Coverage@5 = 0.0754\n",
      "Validation : HR@10 = 0.0431, MRR@10 == 0.0180, Coverage@10 = 0.1111\n",
      "Validation : HR@20 = 0.0853, MRR@20 == 0.0207, Coverage@20 = 0.1565\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1391.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0133, Coverage@5 = 0.0779\n",
      "Validation : HR@10 = 0.0545, MRR@10 == 0.0166, Coverage@10 = 0.1092\n",
      "Validation : HR@20 = 0.0897, MRR@20 == 0.0188, Coverage@20 = 0.1538\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1387.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0264, MRR@5 == 0.0158, Coverage@5 = 0.0817\n",
      "Validation : HR@10 = 0.0519, MRR@10 == 0.0193, Coverage@10 = 0.1136\n",
      "Validation : HR@20 = 0.0959, MRR@20 == 0.0222, Coverage@20 = 0.1538\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1311.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0264, MRR@5 == 0.0165, Coverage@5 = 0.0820\n",
      "Validation : HR@10 = 0.0536, MRR@10 == 0.0201, Coverage@10 = 0.1142\n",
      "Validation : HR@20 = 0.0950, MRR@20 == 0.0228, Coverage@20 = 0.1554\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1171.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0211, MRR@5 == 0.0133, Coverage@5 = 0.0795\n",
      "Validation : HR@10 = 0.0501, MRR@10 == 0.0171, Coverage@10 = 0.1109\n",
      "Validation : HR@20 = 0.0906, MRR@20 == 0.0199, Coverage@20 = 0.1543\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:48<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0721 achieved with mlrank=(50, 55, 5)\n",
      "Best MRR=0.0259 achieved with mlrank=(55, 55, 5)\n",
      "COV=0.1334 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1035.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 == 0.0147, Coverage@5 = 0.1021\n",
      "Test : HR@10 = 0.0519, MRR@10 == 0.0173, Coverage@10 = 0.1343\n",
      "Test : HR@20 = 0.0932, MRR@20 == 0.0201, Coverage@20 = 0.1843\n",
      "Pipeline ended.\n",
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1282.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0273, MRR@5 == 0.0150, Coverage@5 = 0.1078\n",
      "Validation : HR@10 = 0.0466, MRR@10 == 0.0175, Coverage@10 = 0.1521\n",
      "Validation : HR@20 = 0.0765, MRR@20 == 0.0194, Coverage@20 = 0.2135\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1282.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0273, MRR@5 == 0.0155, Coverage@5 = 0.1040\n",
      "Validation : HR@10 = 0.0563, MRR@10 == 0.0192, Coverage@10 = 0.1450\n",
      "Validation : HR@20 = 0.0985, MRR@20 == 0.0221, Coverage@20 = 0.1981\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1218.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0162, Coverage@5 = 0.1114\n",
      "Validation : HR@10 = 0.0580, MRR@10 == 0.0197, Coverage@10 = 0.1554\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0228, Coverage@20 = 0.2085\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1191.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0162, Coverage@5 = 0.1147\n",
      "Validation : HR@10 = 0.0589, MRR@10 == 0.0200, Coverage@10 = 0.1574\n",
      "Validation : HR@20 = 0.1064, MRR@20 == 0.0234, Coverage@20 = 0.2138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1139.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0163, Coverage@5 = 0.1073\n",
      "Validation : HR@10 = 0.0519, MRR@10 == 0.0189, Coverage@10 = 0.1469\n",
      "Validation : HR@20 = 0.0932, MRR@20 == 0.0218, Coverage@20 = 0.2072\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:02<00:00,  6.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0712 achieved with mlrank=(55, 45, 5)\n",
      "Best MRR=0.0260 achieved with mlrank=(55, 45, 5)\n",
      "COV=0.1678 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1129.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0229, MRR@5 == 0.0121, Coverage@5 = 0.1241\n",
      "Test : HR@10 = 0.0493, MRR@10 == 0.0157, Coverage@10 = 0.1673\n",
      "Test : HR@20 = 0.1003, MRR@20 == 0.0191, Coverage@20 = 0.2261\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "for params in exponential_attentions_list:\n",
    "    \n",
    "    config[\"params\"] = params\n",
    "    \n",
    "    full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZJWFtvA_fMT"
   },
   "source": [
    "## Eucledian distance attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T17:01:46.653230Z",
     "start_time": "2022-04-24T17:01:46.542226Z"
    },
    "id": "SVn3hrQqAThd"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        eucl_matrix[i, j] = 1.0 / np.exp(abs(i - j)) if i != j else 1#5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "#for i in range(5):\n",
    "#    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqjrI5XWTmdv",
    "outputId": "efbdd857-1dc6-4fce-d44a-eb94243650c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 454.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0281, MRR@5 = 0.0146, Coverage@5 = 0.1062, nDCG@5 = 0.017867376002130942, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0449, MRR@10 = 0.0167, Coverage@10 = 0.1486, nDCG@10 = 0.022810376704779294, nDCL@10 = 0.00031328688400001953\n",
      "Test : HR@20 = 0.0827, MRR@20 = 0.0192, Coverage@20 = 0.2074, nDCG@20 = 0.03182850401950546, nDCL@20 = 0.0007760803573836037\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 428.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0246, MRR@5 = 0.0142, Coverage@5 = 0.1059, nDCG@5 = 0.01677526696874801, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0589, MRR@10 = 0.0186, Coverage@10 = 0.1431, nDCG@10 = 0.02712028100059107, nDCL@10 = 0.0005780450156306099\n",
      "Test : HR@20 = 0.1003, MRR@20 = 0.0215, Coverage@20 = 0.1981, nDCG@20 = 0.03698954841129931, nDCL@20 = 0.0011894372442691652\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 429.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0290, MRR@5 = 0.0153, Coverage@5 = 0.1125, nDCG@5 = 0.01865985435740027, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0563, MRR@10 = 0.0188, Coverage@10 = 0.1549, nDCG@10 = 0.026520271658344773, nDCL@10 = 0.0008196655666098846\n",
      "Test : HR@20 = 0.1064, MRR@20 = 0.0223, Coverage@20 = 0.2063, nDCG@20 = 0.03840486802109786, nDCL@20 = 0.0016456180005074892\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 422.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0159, Coverage@5 = 0.1155, nDCG@5 = 0.019391362227246023, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0607, MRR@10 = 0.0199, Coverage@10 = 0.1604, nDCG@10 = 0.028057738861461328, nDCL@10 = 0.0010970378230025263\n",
      "Test : HR@20 = 0.1073, MRR@20 = 0.0232, Coverage@20 = 0.2157, nDCG@20 = 0.03890728791062438, nDCL@20 = 0.0021498433369555206\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 406.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0154, Coverage@5 = 0.1067, nDCG@5 = 0.018939600060349285, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0545, MRR@10 = 0.0185, Coverage@10 = 0.1494, nDCG@10 = 0.026126076323414085, nDCL@10 = 0.000570622876094162\n",
      "Test : HR@20 = 0.0959, MRR@20 = 0.0213, Coverage@20 = 0.2088, nDCG@20 = 0.035744226202484616, nDCL@20 = 0.0013849021974513384\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:31<00:00, 10.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0704 achieved with mlrank=(55, 50, 5)\n",
      "Best MRR=0.0260 achieved with mlrank=(55, 45, 5)\n",
      "COV=0.1684 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:03, 377.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0229, MRR@5 = 0.0130, Coverage@5 = 0.1230, nDCG@5 = 0.013501595259558496, nDCL@5 = 0.0019002272838202505\n",
      "Test : HR@10 = 0.0510, MRR@10 = 0.0167, Coverage@10 = 0.1673, nDCG@10 = 0.021426338215084297, nDCL@10 = 0.0030055584084011963\n",
      "Test : HR@20 = 0.1003, MRR@20 = 0.0200, Coverage@20 = 0.2256, nDCG@20 = 0.03159885631636453, nDCL@20 = 0.005175396057991248\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9NOoGl7_jYO"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        eucl_matrix[i, j] = abs(i - j) / np.exp(abs(i - j)) if i != j else 1#5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "#for i in range(5):\n",
    "#    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_O5eTPe_i91",
    "outputId": "9faf46ec-56ef-4c08-ca48-7849d8fbc4ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36787944, 0.27067057, 0.14936121, 0.07326256],\n",
       "       [0.36787944, 1.        , 0.36787944, 0.27067057, 0.14936121],\n",
       "       [0.27067057, 0.36787944, 1.        , 0.36787944, 0.27067057],\n",
       "       [0.14936121, 0.27067057, 0.36787944, 1.        , 0.36787944],\n",
       "       [0.07326256, 0.14936121, 0.27067057, 0.36787944, 1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eucl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5W5oYqHs-lwS",
    "outputId": "66a59e69-ecd8-4975-abf6-62702a42341b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 449.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0325, MRR@5 = 0.0173, Coverage@5 = 0.1133, nDCG@5 = 0.02060432236528717, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0484, MRR@10 = 0.0195, Coverage@10 = 0.1615, nDCG@10 = 0.024949103516384515, nDCL@10 = 0.0013205621816481372\n",
      "Test : HR@20 = 0.0862, MRR@20 = 0.0221, Coverage@20 = 0.2184, nDCG@20 = 0.03389446271350918, nDCL@20 = 0.0019477206355299238\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 436.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0273, MRR@5 = 0.0165, Coverage@5 = 0.1067, nDCG@5 = 0.0188046987495604, nDCL@5 = 0.0003402399360022354\n",
      "Test : HR@10 = 0.0607, MRR@10 = 0.0208, Coverage@10 = 0.1464, nDCG@10 = 0.029122114892130457, nDCL@10 = 0.0006176936534918825\n",
      "Test : HR@20 = 0.1055, MRR@20 = 0.0239, Coverage@20 = 0.2014, nDCG@20 = 0.03892623484222006, nDCL@20 = 0.002164813185781927\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 435.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 = 0.0182, Coverage@5 = 0.1117, nDCG@5 = 0.02095813684883867, nDCL@5 = 0.0003402399360022354\n",
      "Test : HR@10 = 0.0651, MRR@10 = 0.0228, Coverage@10 = 0.1552, nDCG@10 = 0.031430396324063546, nDCL@10 = 0.0009309805374919021\n",
      "Test : HR@20 = 0.1117, MRR@20 = 0.0260, Coverage@20 = 0.2083, nDCG@20 = 0.041667131483007276, nDCL@20 = 0.00242245621538168\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 433.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0182, Coverage@5 = 0.1177, nDCG@5 = 0.02147860868588538, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0677, MRR@10 = 0.0227, Coverage@10 = 0.1604, nDCG@10 = 0.0318932798429734, nDCL@10 = 0.001030494339396439\n",
      "Test : HR@20 = 0.1170, MRR@20 = 0.0260, Coverage@20 = 0.2162, nDCG@20 = 0.041897268132751256, nDCL@20 = 0.003395215076820426\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 422.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 = 0.0182, Coverage@5 = 0.1087, nDCG@5 = 0.02105086337696857, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0536, MRR@10 = 0.0211, Coverage@10 = 0.1516, nDCG@10 = 0.02782691500401366, nDCL@10 = 0.0007172074553964193\n",
      "Test : HR@20 = 0.0994, MRR@20 = 0.0242, Coverage@20 = 0.2061, nDCG@20 = 0.03847711975476604, nDCL@20 = 0.0015739320900605947\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:32<00:00, 10.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0756 achieved with mlrank=(55, 45, 5)\n",
      "Best MRR=0.0261 achieved with mlrank=(55, 50, 5)\n",
      "COV=0.1714 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:03, 371.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0264, MRR@5 = 0.0140, Coverage@5 = 0.1285, nDCG@5 = 0.015803032964804557, nDCL@5 = 0.001235387306983765\n",
      "Test : HR@10 = 0.0563, MRR@10 = 0.0178, Coverage@10 = 0.1714, nDCG@10 = 0.02423695351166098, nDCL@10 = 0.002307115419365183\n",
      "Test : HR@20 = 0.0959, MRR@20 = 0.0205, Coverage@20 = 0.2325, nDCG@20 = 0.031898621460716925, nDCL@20 = 0.004529182667381669\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYMZzRsB-lwT"
   },
   "source": [
    "## Rating distribution attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T17:03:13.864067Z",
     "start_time": "2022-04-24T17:03:13.680300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOW0iu_z-lwV",
    "outputId": "f9e5e9c0-4737-4b68-ed50-079df0d9121c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05653845317719693,\n",
       " 0.1047471358488105,\n",
       " 0.26050732251682984,\n",
       " 0.3441582910021087,\n",
       " 0.23404879745505403]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dist = []\n",
    "\n",
    "total_cnt = training.shape[0]\n",
    "\n",
    "for i in range(5):\n",
    "    val = training.query(f'rating == {i + 1}').count()[0] / total_cnt\n",
    "    \n",
    "    rating_dist.append(val)\n",
    "\n",
    "rating_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T17:03:14.694191Z",
     "start_time": "2022-04-24T17:03:14.580778Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cGm3uxPQK-4",
    "outputId": "a0465ef1-27b6-48ac-bb3c-e89f10000879"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liza\\AppData\\Local\\Temp\\ipykernel_19068\\312260118.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  rat_dist_matrix[i, j] = rating_dist[i] / abs(rating_dist[i] - rating_dist[j])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[       inf, 1.17278569, 0.27719158, 0.19657355, 0.31850793],\n",
       "       [2.17278569,        inf, 0.67248979, 0.43751986, 0.81009892],\n",
       "       [1.27719158, 1.67248979,        inf, 3.11421765, 9.8458747 ],\n",
       "       [1.19657355, 1.43751986, 4.11421765,        inf, 3.12560053],\n",
       "       [1.31850793, 1.81009892, 8.8458747 , 2.12560053,        inf]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        rat_dist_matrix[i, j] = rating_dist[i] / abs(rating_dist[i] - rating_dist[j])\n",
    "        #rat_dist_matrix[i, j] = diff / np.exp(diff) if i != j else 1. + 1e-1\n",
    "\n",
    "rat_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T17:03:15.412028Z",
     "start_time": "2022-04-24T17:03:15.301241Z"
    },
    "id": "TVtjj-UD-lwW"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        diff = abs(rating_dist[i] - rating_dist[j])\n",
    "        rat_dist_matrix[i, j] = diff / np.exp(diff) if i != j else 1. + 1e-1\n",
    "        \n",
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)\n",
    "#rat_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qcbsCWe-lwZ",
    "outputId": "8f1da19a-e989-4a15-d5ae-64fc43e5683c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 445.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0237, MRR@5 = 0.0144, Coverage@5 = 0.1117, nDCG@5 = 0.016772111754940346, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0466, MRR@10 = 0.0175, Coverage@10 = 0.1546, nDCG@10 = 0.023598806239983595, nDCL@10 = 0.0005780450156306099\n",
      "Test : HR@20 = 0.0783, MRR@20 = 0.0197, Coverage@20 = 0.2036, nDCG@20 = 0.03118319086912337, nDCL@20 = 0.0010092849309640722\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 421.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0200, Coverage@5 = 0.1109, nDCG@5 = 0.02287084881401924, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0642, MRR@10 = 0.0240, Coverage@10 = 0.1499, nDCG@10 = 0.03215653999889215, nDCL@10 = 0.001030494339396439\n",
      "Test : HR@20 = 0.1091, MRR@20 = 0.0270, Coverage@20 = 0.2014, nDCG@20 = 0.042042408086102726, nDCL@20 = 0.002324415387296944\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 430.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0352, MRR@5 = 0.0200, Coverage@5 = 0.1131, nDCG@5 = 0.023292283101531776, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0774, MRR@10 = 0.0255, Coverage@10 = 0.1508, nDCG@10 = 0.035593016466947444, nDCL@10 = 0.0015958437691679919\n",
      "Test : HR@20 = 0.1223, MRR@20 = 0.0283, Coverage@20 = 0.2044, nDCG@20 = 0.04514020087027024, nDCL@20 = 0.003077443022063615\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 428.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0369, MRR@5 = 0.0199, Coverage@5 = 0.1142, nDCG@5 = 0.023307446744329403, nDCL@5 = 0.0007190231884854308\n",
      "Test : HR@10 = 0.0712, MRR@10 = 0.0242, Coverage@10 = 0.1535, nDCG@10 = 0.033375587900277, nDCL@10 = 0.0015386887550953153\n",
      "Test : HR@20 = 0.1187, MRR@20 = 0.0274, Coverage@20 = 0.2052, nDCG@20 = 0.043284447809058275, nDCL@20 = 0.0034691192822309458\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 402.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0172, Coverage@5 = 0.1144, nDCG@5 = 0.02074601094985069, nDCL@5 = 0.0003787832524831953\n",
      "Test : HR@10 = 0.0712, MRR@10 = 0.0221, Coverage@10 = 0.1552, nDCG@10 = 0.03205373289389733, nDCL@10 = 0.0012005394879658672\n",
      "Test : HR@20 = 0.1214, MRR@20 = 0.0255, Coverage@20 = 0.2028, nDCG@20 = 0.04261636016198688, nDCL@20 = 0.0031542602033563837\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:30<00:00, 10.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0844 achieved with mlrank=(50, 45, 5)\n",
      "Best MRR=0.0306 achieved with mlrank=(55, 55, 5)\n",
      "COV=0.1772 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:03, 344.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 = 0.0143, Coverage@5 = 0.1348, nDCG@5 = 0.016939382722254145, nDCL@5 = 0.0016141705594669602\n",
      "Test : HR@10 = 0.0580, MRR@10 = 0.0179, Coverage@10 = 0.1774, nDCG@10 = 0.02469648307522927, nDCL@10 = 0.0024464502508388963\n",
      "Test : HR@20 = 0.1055, MRR@20 = 0.0211, Coverage@20 = 0.2333, nDCG@20 = 0.034409123222778414, nDCL@20 = 0.004649546849046022\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU04z-n1-lwa"
   },
   "source": [
    "## Trigonometry scale attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T17:04:49.095089Z",
     "start_time": "2022-04-24T17:04:48.970065Z"
    },
    "id": "xJiHTF7_-lwb"
   },
   "outputs": [],
   "source": [
    "def rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T17:04:49.710103Z",
     "start_time": "2022-04-24T17:04:49.592449Z"
    },
    "id": "8pQN1IHU-lwc"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = rescale_score(i + 1), rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = diff / np.exp(diff) if i != j else 5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQtcfKcE-lwc",
    "outputId": "989556b9-ee77-47f7-ada3-7819ec240f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1441.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0343, MRR@5 == 0.0208, Coverage@5 = 0.1048\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1461\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0271, Coverage@20 = 0.2014\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1129.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0183, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0633, MRR@10 == 0.0228, Coverage@10 = 0.1475\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0260, Coverage@20 = 0.2003\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1357.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0730, MRR@10 == 0.0243, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1258, MRR@20 == 0.0277, Coverage@20 = 0.2047\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1302.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0369, MRR@5 == 0.0198, Coverage@5 = 0.1150\n",
      "Validation : HR@10 = 0.0704, MRR@10 == 0.0242, Coverage@10 = 0.1541\n",
      "Validation : HR@20 = 0.1249, MRR@20 == 0.0278, Coverage@20 = 0.2096\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1127.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0009, MRR@5 == 0.0003, Coverage@5 = 0.1653\n",
      "Validation : HR@10 = 0.0018, MRR@10 == 0.0004, Coverage@10 = 0.2360\n",
      "Validation : HR@20 = 0.0026, MRR@20 == 0.0005, Coverage@20 = 0.3249\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:58<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0844 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0303 achieved with mlrank=(50, 50, 5)\n",
      "COV=0.1750 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1045.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0237, MRR@5 == 0.0103, Coverage@5 = 0.1287\n",
      "Test : HR@10 = 0.0589, MRR@10 == 0.0150, Coverage@10 = 0.1744\n",
      "Test : HR@20 = 0.0994, MRR@20 == 0.0177, Coverage@20 = 0.2338\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56vIkauV-lwd"
   },
   "outputs": [],
   "source": [
    "def center_and_rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AyRMQch-lwe",
    "outputId": "549aaf3d-a9ea-4476-b139-7e64607dbf1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.75657241 0.47457495 0.34571609 0.31110998]\n",
      " [0.75657241 1.         0.56009915 0.38898453 0.34571609]\n",
      " [0.47457495 0.56009915 1.         0.56009915 0.47457495]\n",
      " [0.34571609 0.38898453 0.56009915 1.         0.75657241]\n",
      " [0.31110998 0.34571609 0.47457495 0.75657241 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = center_and_rescale_score(i + 1), center_and_rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = 1 / (diff + 1)\n",
    "\n",
    "similarity = eucl_matrix\n",
    "        \n",
    "print(similarity)\n",
    "    \n",
    "a = np.linalg.cholesky(similarity)        \n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdXGb7Wb-lwf",
    "outputId": "604d12fb-6502-4041-cc4e-5c6d163c1254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1482.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0528, MRR@10 == 0.0222, Coverage@10 = 0.1530\n",
      "Validation : HR@20 = 0.0871, MRR@20 == 0.0245, Coverage@20 = 0.2168\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1424.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0192, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0235, Coverage@10 = 0.1505\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0270, Coverage@20 = 0.2039\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1415.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0197, Coverage@5 = 0.1139\n",
      "Validation : HR@10 = 0.0686, MRR@10 == 0.0246, Coverage@10 = 0.1552\n",
      "Validation : HR@20 = 0.1161, MRR@20 == 0.0279, Coverage@20 = 0.2110\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1366.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0187, Coverage@5 = 0.1164\n",
      "Validation : HR@10 = 0.0677, MRR@10 == 0.0239, Coverage@10 = 0.1596\n",
      "Validation : HR@20 = 0.1152, MRR@20 == 0.0272, Coverage@20 = 0.2138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1312.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0180, Coverage@5 = 0.1109\n",
      "Validation : HR@10 = 0.0572, MRR@10 == 0.0217, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1099, MRR@20 == 0.0253, Coverage@20 = 0.2116\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:38<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0827 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0293 achieved with mlrank=(55, 50, 5)\n",
      "COV=0.1816 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1105.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0246, MRR@5 == 0.0129, Coverage@5 = 0.1312\n",
      "Test : HR@10 = 0.0554, MRR@10 == 0.0168, Coverage@10 = 0.1816\n",
      "Test : HR@20 = 0.0985, MRR@20 == 0.0198, Coverage@20 = 0.2454\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ5eMt1G-lwg"
   },
   "source": [
    "## Conditional prob attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T17:05:39.460591Z",
     "start_time": "2022-04-24T17:05:39.331602Z"
    },
    "id": "Q2f472Za-lwg"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count12_tot = 0\n",
    "count12_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "     count12_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count12_loc += 1\n",
    "  count12_tot += count12_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvf78Rfb-lwh"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count13_tot = 0\n",
    "count13_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count13_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count13_loc += 1\n",
    "  count13_tot += count13_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJHQliXB-lwh"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count14_tot = 0\n",
    "count14_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count14_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count14_loc += 1\n",
    "  count14_tot += count14_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uc9cn3J-lwj"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count15_tot = 0\n",
    "count15_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count15_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count15_loc += 1\n",
    "  count15_tot += count15_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLXk6x4G-lwk"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count23_tot = 0\n",
    "count23_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count23_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count23_loc += 1\n",
    "  count23_tot += count23_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FlI1HRm-lwo"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count24_tot = 0\n",
    "count24_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count24_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count24_loc += 1\n",
    "  count24_tot += count24_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tawueqnY-lwq"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count25_tot = 0\n",
    "count25_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count25_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count25_loc += 1\n",
    "  count25_tot += count25_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-A4Q24n-lwu"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count34_tot = 0\n",
    "count34_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count34_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count34_loc += 1\n",
    "  count34_tot += count34_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3YNSNjX-lwv"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count35_tot = 0\n",
    "count35_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count35_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count35_loc += 1\n",
    "  count35_tot += count35_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AisgFMpm-lww"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count45_tot = 0\n",
    "count45_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count45_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "      count45_loc += 1\n",
    "  count45_tot += count45_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJ_R_SJS-lwx"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1')\n",
    "users = train_new_part.userid.unique()\n",
    "count11_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count11_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBDskvQm-lwy"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count22_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count22_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YkuEEsn-lwy"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count33_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count33_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmfoz1Mw-lw0"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count44_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count44_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpfZSAEp-lw1"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count55_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count55_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri7dKAgV-lw2"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "rat_dist_matrix[0][0] = count11_tot\n",
    "rat_dist_matrix[0][1] = rat_dist_matrix[1][0]= count12_tot\n",
    "rat_dist_matrix[0][2] = rat_dist_matrix[2][0]= count13_tot\n",
    "rat_dist_matrix[0][3] = rat_dist_matrix[3][0]= count14_tot\n",
    "rat_dist_matrix[0][4] = rat_dist_matrix[4][0]= count15_tot\n",
    "rat_dist_matrix[1][1] = count22_tot\n",
    "rat_dist_matrix[1][2] = rat_dist_matrix[2][1] = count23_tot\n",
    "rat_dist_matrix[1][3] = rat_dist_matrix[3][1] = count24_tot\n",
    "rat_dist_matrix[1][4] = rat_dist_matrix[4][1] = count25_tot\n",
    "rat_dist_matrix[2][2] = count33_tot\n",
    "rat_dist_matrix[2][3] = rat_dist_matrix[3][2] = count34_tot\n",
    "rat_dist_matrix[2][4] = rat_dist_matrix[4][2] = count35_tot\n",
    "rat_dist_matrix[3][3] = count44_tot\n",
    "rat_dist_matrix[3][4] = rat_dist_matrix[4][3] = count45_tot\n",
    "rat_dist_matrix[4][4] = count55_tot       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9tfKojo-lw3"
   },
   "outputs": [],
   "source": [
    "summ = np.sum(rat_dist_matrix)\n",
    "rat_dist_matrix /= summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63xlkdVN-lw4"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix[0,0] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[1,1] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[2,2] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[3,3] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[4,4] += np.random.uniform(low=0.0, high=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9_koO81-lw4"
   },
   "outputs": [],
   "source": [
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOP1rnpS-lw5",
    "outputId": "722042ce-74d0-4138-aaf3-9f15b38ed67e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1542.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0164, Coverage@5 = 0.0949\n",
      "Validation : HR@10 = 0.0554, MRR@10 == 0.0195, Coverage@10 = 0.1337\n",
      "Validation : HR@20 = 0.0880, MRR@20 == 0.0217, Coverage@20 = 0.1796\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1359.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0188, Coverage@5 = 0.0988\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0226, Coverage@10 = 0.1309\n",
      "Validation : HR@20 = 0.0950, MRR@20 == 0.0250, Coverage@20 = 0.1772\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1444.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0352, MRR@5 == 0.0207, Coverage@5 = 0.0993\n",
      "Validation : HR@10 = 0.0642, MRR@10 == 0.0245, Coverage@10 = 0.1315\n",
      "Validation : HR@20 = 0.1047, MRR@20 == 0.0273, Coverage@20 = 0.1777\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1446.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0334, MRR@5 == 0.0205, Coverage@5 = 0.1007\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0245, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0273, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1284.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0203, Coverage@5 = 0.1004\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1029, MRR@20 == 0.0272, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:55<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0800 achieved with mlrank=(45, 45, 5)\n",
      "Best MRR=0.0279 achieved with mlrank=(40, 45, 5)\n",
      "COV=0.1560 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1100.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0290, MRR@5 == 0.0126, Coverage@5 = 0.1161\n",
      "Test : HR@10 = 0.0528, MRR@10 == 0.0157, Coverage@10 = 0.1549\n",
      "Test : HR@20 = 0.1038, MRR@20 == 0.0190, Coverage@20 = 0.2077\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoFFee representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:24:40.042537Z",
     "start_time": "2022-04-27T15:24:39.929535Z"
    }
   },
   "outputs": [],
   "source": [
    "def coffee_model_build(config, data, data_description):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    u0, u1, u2, g = hooi(\n",
    "        idx, val, shape, core_shape,\n",
    "        return_core=False, num_iters=num_iters,\n",
    "        parallel_ttm=False, growth_tol=0.01,\n",
    "    )\n",
    "    return u0, u1, u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:24:40.598533Z",
     "start_time": "2022-04-27T15:24:40.465535Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'mlrank': (50, 70, 2),\n",
    "    \"num_iters\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:24:43.904555Z",
     "start_time": "2022-04-27T15:24:41.050536Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_params = coffee_model_build(config, training, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:13:08.546525Z",
     "start_time": "2022-04-24T20:13:08.434727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5146774 ,  0.51470557,  0.51284014,  0.41066111, -0.19631042],\n",
       "       [ 0.51470557,  0.51473454,  0.51283089,  0.41021091, -0.19712438],\n",
       "       [ 0.51284014,  0.51283089,  0.51277113,  0.43150372, -0.15770155],\n",
       "       [ 0.41066111,  0.41021091,  0.43150372,  0.61016425,  0.32340159],\n",
       "       [-0.19631042, -0.19712438, -0.15770155,  0.32340159,  0.89058735]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix = scipy.linalg.sqrtm(cosine_similarity(tf_params[-1])).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:17:47.683656Z",
     "start_time": "2022-04-24T20:17:47.582013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 9.99999673e-01,  8.08488743e-04,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 9.99271663e-01, -3.81570952e-02,  4.24841747e-04,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 8.72479011e-01, -4.83175257e-01,  7.29523543e-02,\n",
       "         3.61130385e-05,  0.00000000e+00],\n",
       "       [ 6.63719458e-04, -8.20938136e-01,  5.71016678e-01,\n",
       "         3.00166364e-04,  7.65200381e-07]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = cosine_similarity(tf_params[-1])\n",
    "sims = cosine_similarity(tf_params[-1]) - np.min(sims)\n",
    "sims = sims / np.max(sims)\n",
    "attention_matrix = np.linalg.cholesky(sims)\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:18:12.487270Z",
     "start_time": "2022-04-24T20:18:12.376433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81729761,  0.49920592,  0.20392372,  0.16646119,  0.11629207],\n",
       "       [ 0.49920592,  0.78824066,  0.27679063,  0.21384059,  0.08443498],\n",
       "       [ 0.20392372,  0.27679063,  0.87088273,  0.34853239, -0.04348002],\n",
       "       [ 0.16646119,  0.21384059,  0.34853239,  0.89208442,  0.09629866],\n",
       "       [ 0.11629207,  0.08443498, -0.04348002,  0.09629866,  0.98396288]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = euclidean_distances(tf_params[-1])\n",
    "attention_matrix = scipy.linalg.sqrtm(1 - dists / np.max(dists)).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:19:38.519993Z",
     "start_time": "2022-04-24T20:19:38.407658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.90335366,  0.42889644,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.53539628,  0.34562348,  0.77064599,  0.        ,  0.        ],\n",
       "       [ 0.47356905,  0.27797213,  0.45906648,  0.69837083,  0.        ],\n",
       "       [ 0.25878614, -0.04086778, -0.1614597 ,  0.23747859,  0.92135457]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix = np.linalg.cholesky(1 - dists / np.max(dists))\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:20:30.650030Z",
     "start_time": "2022-04-24T20:20:30.530913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64834247, 0.57577932, 0.32642458, 0.27447916, 0.2573682 ],\n",
       "       [0.57577932, 0.59164233, 0.40717315, 0.32566357, 0.21584899],\n",
       "       [0.32642458, 0.40717315, 0.702229  , 0.47769552, 0.07961432],\n",
       "       [0.27447916, 0.32566357, 0.47769552, 0.73001925, 0.23975678],\n",
       "       [0.2573682 , 0.21584899, 0.07961432, 0.23975678, 0.90738584]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix = scipy.linalg.sqrtm(rbf_kernel(tf_params[-1])).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:21:29.266896Z",
     "start_time": "2022-04-24T20:21:29.155695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.99180947,  0.1277262 ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.82690926,  0.52764784,  0.19444492,  0.        ,  0.        ],\n",
       "       [ 0.78347925,  0.45135898,  0.20283384,  0.37589064,  0.        ],\n",
       "       [ 0.6164727 , -0.2284229 ,  0.13031051,  0.43954945,  0.59799652]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix = np.linalg.cholesky(rbf_kernel(tf_params[-1]))\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:22:06.002357Z",
     "start_time": "2022-04-24T20:22:05.884676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78488714, 0.48306455, 0.2426216 , 0.23409967, 0.1921794 ],\n",
       "       [0.48306455, 0.75609052, 0.29087935, 0.28318655, 0.17369613],\n",
       "       [0.2426216 , 0.29087935, 0.84103522, 0.34580984, 0.17204439],\n",
       "       [0.23409967, 0.28318655, 0.34580984, 0.832832  , 0.2276162 ],\n",
       "       [0.1921794 , 0.17369613, 0.17204439, 0.2276162 , 0.92276125]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix = scipy.linalg.sqrtm(laplacian_kernel(tf_params[-1])).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:22:59.862820Z",
     "start_time": "2022-04-24T20:22:59.739035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.91463999, 0.40426933, 0.        , 0.        , 0.        ],\n",
       "       [0.64901475, 0.28686343, 0.70461992, 0.        , 0.        ],\n",
       "       [0.64314899, 0.28427077, 0.36645365, 0.60931209, 0.        ],\n",
       "       [0.50710786, 0.08688763, 0.17778287, 0.22530154, 0.80803752]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_matrix = np.linalg.cholesky(laplacian_kernel(tf_params[-1]))\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:25:07.496970Z",
     "start_time": "2022-04-27T15:25:07.383973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8556113 ,  0.47079734,  0.20826378,  0.03232477, -0.04313327],\n",
       "       [ 0.47079734,  0.82116697,  0.30426251,  0.1020495 ,  0.03232477],\n",
       "       [ 0.20826378,  0.30426251,  0.85328837,  0.30426251,  0.20826378],\n",
       "       [ 0.03232477,  0.1020495 ,  0.30426251,  0.82116697,  0.47079734],\n",
       "       [-0.04313327,  0.03232477,  0.20826378,  0.47079734,  0.8556113 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = euclidean_distances(np.arctan(np.array([-2, -1, 0, 1, 2]).reshape(-1,1)))\n",
    "attention_matrix = scipy.linalg.sqrtm(1 - dists / np.max(dists)).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:25:10.487192Z",
     "start_time": "2022-04-27T15:25:10.378196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.85469407, 0.51913202, 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.41985255, 0.7574456 , 0.        , 0.        ],\n",
       "       [0.14530593, 0.32057307, 0.57833796, 0.73596487, 0.        ],\n",
       "       [0.        , 0.2799017 , 0.50496373, 0.64259239, 0.5037278 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = euclidean_distances(np.arctan(np.array([-2, -1, 0, 1, 2]).reshape(-1,1)))\n",
    "attention_matrix = np.linalg.cholesky(1 - dists / np.max(dists))\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:14.987231Z",
     "start_time": "2022-04-27T15:28:14.869216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8944101 ,  0.38848154,  0.20235236,  0.07225377, -0.0542732 ],\n",
       "       [ 0.38848154,  0.82346475,  0.35955913,  0.19100922,  0.07225377],\n",
       "       [ 0.20235236,  0.35955913,  0.81212161,  0.35955913,  0.20235236],\n",
       "       [ 0.07225377,  0.19100922,  0.35955913,  0.82346475,  0.38848154],\n",
       "       [-0.0542732 ,  0.07225377,  0.20235236,  0.38848154,  0.8944101 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = euclidean_distances(np.array([1,2,3,4,5]).reshape(-1,1))\n",
    "attention_matrix = scipy.linalg.sqrtm(1 - dists / np.max(dists)).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:25:18.364268Z",
     "start_time": "2022-04-27T15:25:18.255249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.75      , 0.66143783, 0.        , 0.        , 0.        ],\n",
       "       [0.5       , 0.56694671, 0.65465367, 0.        , 0.        ],\n",
       "       [0.25      , 0.47245559, 0.54554473, 0.64549722, 0.        ],\n",
       "       [0.        , 0.37796447, 0.43643578, 0.51639778, 0.63245553]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = euclidean_distances(np.array([1,2,3,4,5]).reshape(-1,1))\n",
    "attention_matrix = np.linalg.cholesky(1 - dists / np.max(dists))\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:13:16.667874Z",
     "start_time": "2022-04-24T20:13:16.565144Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_prediction(tf_scores, holdout_valid, data_description):\n",
    "    for n in [5, 10, 20]:\n",
    "        tf_recs = topn_recommendations(tf_scores, n)\n",
    "        hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout_valid, data_description, topn=n)\n",
    "        print(f\"Test : HR@{n} = {hr:.4f}, MRR@{n} = {mrr:.4f}, Coverage@{n} = {cov:.4f}, Matthews@{n} = {C:.4f}\")\n",
    "        print(f\"HR_pos@{n} = {hr_pos:.4f}, HR_neg@{n} = {hr_neg:.4f}\")\n",
    "        print(f\"MRR_pos@{n} = {mrr_pos:.4f}, MRR_neg@{n} = {mrr_neg:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:39:24.192565Z",
     "start_time": "2022-04-24T20:39:24.064292Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"mlrank\": (100, 100, 2),\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 3,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-24T20:13:23.052603Z",
     "start_time": "2022-04-24T20:13:18.064058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test : HR@5 = 0.0339, MRR@5 = 0.0156, Coverage@5 = 0.1687, Matthews@5 = 0.0232\n",
      "HR_pos@5 = 0.0383, HR_neg@5 = 0.0132\n",
      "MRR_pos@5 = 0.0145, MRR_neg@5 = 0.0011\n",
      "\n",
      "Test : HR@10 = 0.0644, MRR@10 = 0.0196, Coverage@10 = 0.2292, Matthews@10 = 0.0180\n",
      "HR_pos@10 = 0.0710, HR_neg@10 = 0.0330\n",
      "MRR_pos@10 = 0.0181, MRR_neg@10 = 0.0015\n",
      "\n",
      "Test : HR@20 = 0.1121, MRR@20 = 0.0228, Coverage@20 = 0.2962, Matthews@20 = 0.0132\n",
      "HR_pos@20 = 0.1212, HR_neg@20 = 0.0693\n",
      "MRR_pos@20 = 0.0208, MRR_neg@20 = 0.0019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latte_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "latte_scores = tf_scoring(latte_params, testset, data_description, \"3+4+5\")\n",
    "downvote_seen_items(latte_scores, testset, data_description)\n",
    "\n",
    "make_prediction(latte_scores, holdout, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:18.027046Z",
     "start_time": "2022-04-27T15:28:17.918037Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_prediction(scores, holdout_valid, data_description):\n",
    "    metrics = np.zeros((8, 100))\n",
    "    for n in range(1, 101):\n",
    "        recs = topn_recommendations(scores, n)\n",
    "        metrics[:, n-1] = model_evaluate(recs, holdout_valid, data_description, topn=n)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:26.722583Z",
     "start_time": "2022-04-27T15:28:18.657588Z"
    }
   },
   "outputs": [],
   "source": [
    "latte_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "latte_scores = tf_scoring(latte_params, testset, data_description, \"3+4+5\")\n",
    "downvote_seen_items(latte_scores, testset, data_description)\n",
    "\n",
    "latte_metrics = make_prediction(latte_scores, holdout, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-27T15:28:29.568029Z",
     "start_time": "2022-04-27T15:28:29.447971Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open('metrics.txt','w')\n",
    "f.write(str(list(map(list, latte_metrics))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LaTTE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
