{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6zfbrvMoy9Ed"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Jd1axtgLy9Id"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import polara\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items\n",
    "\n",
    "from polara.lib.tensor import hooi\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "\n",
    "from sa_hooi import sa_hooi, form_attention_matrix, get_scaling_weights, generate_position_projector\n",
    "\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.linalg import solve_triangular\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BDtwh0bdy9Mk"
   },
   "outputs": [],
   "source": [
    "def full_preproccessing():\n",
    "    data = get_movielens_data(include_time=True)\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.9, interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "    train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    "    )\n",
    "    \n",
    "    training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "    test_data = reindex(test_data_, data_index['items'])\n",
    "\n",
    "    testset_, holdout_ = leave_one_out(\n",
    "    test_data, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "    testset_valid_, holdout_valid_ = leave_one_out(\n",
    "        testset_, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "\n",
    "    test_users_val = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset_valid = testset_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "    holdout_valid = holdout_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "\n",
    "    test_users = np.intersect1d(testset_.userid.unique(), holdout_.userid.unique())\n",
    "    testset = testset_.query('userid in @test_users').sort_values('userid')\n",
    "    holdout = holdout_.query('userid in @test_users').sort_values('userid')\n",
    "\n",
    "\n",
    "    assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
    "        testset_valid\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "\n",
    "    data_description = dict(\n",
    "        users = data_index['users'].name,\n",
    "        items = data_index['items'].name,\n",
    "        feedback = 'rating',\n",
    "        n_users = len(data_index['users']),\n",
    "        n_items = len(data_index['items']),\n",
    "        n_ratings = training['rating'].nunique(),\n",
    "        min_rating = training['rating'].min()\n",
    "    )\n",
    "\n",
    "    return training, testset_valid, holdout_valid, testset, holdout, data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmYMpvcBy9QZ",
    "outputId": "bd702bab-2522-40a6-91df-ea8da2ceeede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 113 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description = full_preproccessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SM-pkXQx1GwO"
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "\n",
    "def tf_model_build(config, data, data_description, attention_matrix=np.array([])):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    if (attention_matrix.shape[0] == 0):\n",
    "        attention_matrix = form_attention_matrix(\n",
    "            data_description['n_ratings'],\n",
    "            **config['params'],\n",
    "            format = 'csr'\n",
    "        )\n",
    "\n",
    "    item_popularity = (\n",
    "        data[itemid]\n",
    "        .value_counts(sort=False)\n",
    "        .reindex(range(n_items))\n",
    "        .fillna(1)\n",
    "        .values\n",
    "    )\n",
    "    scaling_weights = get_scaling_weights(item_popularity, scaling=config[\"scaling\"])\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        u0, u1, u2 = sa_hooi(\n",
    "            idx, val, shape, config[\"mlrank\"],\n",
    "            attention_matrix = attention_matrix,\n",
    "            scaling_weights = scaling_weights,\n",
    "            max_iters = config[\"num_iters\"],\n",
    "            parallel_ttm = False,\n",
    "            randomized = config[\"randomized\"],\n",
    "            growth_tol = config[\"growth_tol\"],\n",
    "            seed = config[\"seed\"],\n",
    "            iter_callback = None,\n",
    "        )\n",
    "    \n",
    "    return u0, u1, u2, attention_matrix    \n",
    "    \n",
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"mlrank\": (30, 30, 5),\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 3,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "\n",
    "def tf_scoring(params, data, data_description, context=[\"3+4+5\"]):\n",
    "    user_factors, item_factors, feedback_factors, attention_matrix = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid)\n",
    "    useridx = data[userid]\n",
    "    itemidx = data[itemid].values\n",
    "    ratings = data[feedback].values\n",
    "    ratings = ratings - data_description['min_rating']\n",
    "    \n",
    "    n_users = useridx.nunique()\n",
    "    n_items = data_description['n_items']\n",
    "    n_ratings = data_description['n_ratings']\n",
    "    \n",
    "    #inv_attention = np.linalg.inv(attention_matrix.A) # change\n",
    "    inv_attention = solve_triangular(attention_matrix, np.eye(5), lower=True)\n",
    "    #np.testing.assert_almost_equal(inv_attention, inv_attention_)\n",
    "    \n",
    "    tensor_outer = tensor_outer_at('cpu')\n",
    "    \n",
    "    if (context == \"5\"):\n",
    "        inv_aT_feedback = (inv_attention.T @ feedback_factors)[-1, :]\n",
    "    elif (context == \"4+5\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-2:, :], axis=0)\n",
    "    elif (context == \"3+4+5\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-3:, :], axis=0)\n",
    "    elif (context == \"2+3+4+5\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-4:, :], axis=0)\n",
    "    elif (context == \"3+4+5-2-1\"):\n",
    "        inv_aT_feedback = np.sum((inv_attention.T @ feedback_factors)[-3:, :], axis=0) - np.sum((inv_attention.T @ feedback_factors)[:2, :], axis=0)\n",
    "        \n",
    "    scores = tensor_outer(\n",
    "        1.0,\n",
    "        item_factors,\n",
    "        attention_matrix @ feedback_factors,\n",
    "        itemidx,\n",
    "        ratings\n",
    "    )\n",
    "    scores = np.add.reduceat(scores, np.r_[0, np.where(np.diff(useridx))[0]+1]) # sort by users\n",
    "    scores = np.tensordot(\n",
    "        scores,\n",
    "        inv_aT_feedback,\n",
    "        axes=(2, 0)\n",
    "    ).dot(item_factors.T)\n",
    "\n",
    "#     scores = np.zeros((n_users, n_items))\n",
    "#     print(scores.shape)\n",
    "#     #inv_attention = np.linalg.inv(attention_matrix.A)\n",
    "#     for i, u in tqdm(enumerate(np.unique(useridx))):\n",
    "#         data_u = data[data.userid==u]\n",
    "#         P = csr_matrix((np.ones(data_u.shape[0]), (data_u[itemid].values, data_u[feedback].values - data_description['min_rating'])), (n_items, n_ratings))\n",
    "#         res = item_factors @ (item_factors.T @ (P @ (attention_matrix @ (feedback_factors @ (inv_attention.T @ feedback_factors).T))))\n",
    "#         if (context == \"5\"):\n",
    "#             scores[i] = np.sum(res[:, -1:], axis=1)\n",
    "#         elif (context == \"4+5\"):\n",
    "#             scores[i] = np.sum(res[:, -2:], axis=1)\n",
    "#         elif (context == \"3+4+5\"):\n",
    "#             scores[i] = np.sum(res[:, -3:], axis=1)\n",
    "#         elif (context == \"2+3+4+5\"):\n",
    "#             scores[i] = np.sum(res[:, -4:], axis=1)\n",
    "#         elif (context == \"3+4+5-2-1\"):\n",
    "#             scores[i] = np.sum(res[:, 2:], axis=1) - np.sum(res[:, :2], axis=1)\n",
    "        \n",
    "#     if (context == \"4+5\"):\n",
    "#         np.testing.assert_almost_equal(scores, scores_)\n",
    "    return scores\n",
    "\n",
    "def model_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    holdout_items = holdout[itemid].values\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    # HR calculation\n",
    "    hr = np.mean(hits_mask.any(axis=1))\n",
    "    # MRR calculation\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    # DCG calculation\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    ndcg = np.sum(1 / np.log2(pos_hit_rank+1)) / n_test_users\n",
    "    ndcl = np.sum(1 / np.log2(neg_hit_rank+1)) / n_test_users\n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    return hr, mrr, cov, ndcg, ndcl\n",
    "\n",
    "def make_prediction(tf_scores, holdout, data_description, mode, context=\"\", print_mode=True):\n",
    "    if (mode and print_mode):\n",
    "        print(f\"for context {context} evaluation:\")\n",
    "    for n in [5, 10, 20]:\n",
    "        tf_recs = topn_recommendations(tf_scores, n)\n",
    "        hr, mrr, cov, dcg, dcl = model_evaluate(tf_recs, holdout, data_description, topn=n)\n",
    "        if (print_mode):\n",
    "            print(f\"Test : HR@{n} = {hr:.4f}, MRR@{n} = {mrr:.4f}, Coverage@{n} = {cov:.4f}, nDCG@{n} = {dcg:.5f}, nDCL@{n} = {dcl:.5f}\")\n",
    "        if (n == 10):\n",
    "            mrr10 = mrr\n",
    "            hr10 = hr\n",
    "    return mrr10, hr10\n",
    "\n",
    "def valid_mlrank(mlrank):\n",
    "    '''\n",
    "    Only allow ranks that are suitable for truncated SVD computations\n",
    "    on unfolded compressed tensor (the result of ttm product in HOOI).\n",
    "    '''\n",
    "    #s, r1, r2, r3 = mlrank\n",
    "    s, r1, r3 = mlrank\n",
    "    r2 = r1\n",
    "    #print(s, r1, r2, r3)\n",
    "    return r1*r2 > r3 and r1*r3 > r2 and r2*r3 > r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_num_iter_sa_hooi(config, training, data_description, attention_matrix, testset, holdout):\n",
    "    # Claculate optimal number of iteration for each context for metrics : MRR@10, HR@10\n",
    "    # Input:\n",
    "    # config - dict of params\n",
    "    # training - training dataset\n",
    "    # data_description - dict of data_description\n",
    "    # attention_matrix - attention_matrix which will be used in sa_hooi algo\n",
    "    # testset - test or validation part of dataset\n",
    "    # holdout - holdout which corresponding to users from testset\n",
    "    \n",
    "    print(\"Starting tuning number of iteration in sa_hooi algo...\\n\")\n",
    "    init_max_iter = config[\"num_iters\"]\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"2+3+4+5\", \"3+4+5-2-1\"]:\n",
    "        best_mrr, best_hr = -1, -1\n",
    "        for max_iter in range(1, 10):\n",
    "            config[\"num_iters\"] = max_iter\n",
    "            tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "            tf_scores = tf_scoring(tf_params, testset, data_description, context)\n",
    "            downvote_seen_items(tf_scores, testset, data_description)\n",
    "            cur_mrr, cur_hr = make_prediction(tf_scores, holdout, data_description, \"Validation\", context, print_mode=False)\n",
    "            if (cur_mrr > best_mrr):\n",
    "                best_mrr = cur_mrr\n",
    "                best_iter_mrr = max_iter\n",
    "            if (cur_hr > best_hr):\n",
    "                best_hr = cur_hr\n",
    "                best_iter_hr = max_iter\n",
    "            \n",
    "        print(f\"For context '{context}' the following parameters were found:\")\n",
    "        print(f\"\\tFor HR@10 ({best_hr:.4f}) -- number of iteration is {best_iter_hr}\")\n",
    "        print(f\"\\tFor MRR@10 ({best_mrr:.4f}) -- number of iteration is {best_iter_mrr}\")\n",
    "        print(\"------------------------------------------------------\\n\")\n",
    "    config[\"num_iters\"] = init_max_iter\n",
    "    print(\"Tuning ended.\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3p0AyeCf3QVU"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "def full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix):\n",
    "\n",
    "    config[\"mlrank\"] = (30, 30, 5)\n",
    "    print(\"Starting pipeline...\")\n",
    "    print(\"Training with different context in progress...\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    best_mrr_context = \"3+4+5\"\n",
    "    best_mrr = 0.0\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"2+3+4+5\", \"3+4+5-2-1\"]:\n",
    "        tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "        seen_data = testset_valid\n",
    "        tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "        downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "        cur_mrr, cur_hr = make_prediction(tf_scores, holdout_valid, data_description, \"Validation\", context)\n",
    "        print(\"------------------------------------------------------\")\n",
    "        if (cur_mrr > best_mrr):\n",
    "            best_mrr = cur_mrr\n",
    "            best_mrr_context = context\n",
    "\n",
    "    best_mrr_context = \"3+4+5\" # intuitively this is better \n",
    "    #print(f\"Tuning model with context {best_mrr_context}...\")\n",
    "    print(f\"Tuning model for all contexts...\\n\")\n",
    "\n",
    "    tf_hyper = {\n",
    "    'scaling': np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]),\n",
    "    'r1': np.arange(100, 301, 25),\n",
    "    #'r2': np.arange(50, 801, 25),\n",
    "    'r3': range(2, 6, 1),\n",
    "    }\n",
    "\n",
    "    grid, param_names = random_grid(tf_hyper, n=0)\n",
    "    tf_grid = [tuple(mlrank) for mlrank in grid if valid_mlrank(mlrank)]\n",
    "\n",
    "    hr_tf = {}\n",
    "    mrr_tf = {}\n",
    "    cov_tf = {}\n",
    "    seen_data = testset_valid\n",
    "    full_result = dict()\n",
    "    for mlrank in tqdm(tf_grid):\n",
    "        with io.capture_output() as captured:\n",
    "            r1, r3 = mlrank[1:]\n",
    "            cur_mlrank = tuple((r1, r1, r3))\n",
    "            config['mlrank'] = cur_mlrank\n",
    "            config['scaling'] = mlrank[0]\n",
    "            tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "            for context in [\"5\", \"4+5\", \"3+4+5\", \"2+3+4+5\", \"3+4+5-2-1\"]:\n",
    "                tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "                downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "                tf_recs = topn_recommendations(tf_scores, topn=10)\n",
    "                hr, mrr, cov, dcg, dcl = model_evaluate(tf_recs, holdout_valid, data_description, topn=10)\n",
    "                hr_tf[(context, cur_mlrank, mlrank[0])] = hr\n",
    "                mrr_tf[(context, cur_mlrank, mlrank[0])] = mrr\n",
    "                cov_tf[(context, cur_mlrank, mlrank[0])] = cov\n",
    "\n",
    "    print(f'Best HR={pd.Series(hr_tf).max():.4f} achieved with context {pd.Series(hr_tf).idxmax()[0]} and mlrank = {pd.Series(hr_tf).idxmax()[1]} and scale factor = {pd.Series(hr_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR={pd.Series(mrr_tf).max():.4f} achieved with context {pd.Series(mrr_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_tf).idxmax()[2]}')\n",
    "    print(f'COV={pd.Series(cov_tf)[pd.Series(mrr_tf).idxmax()]:.4f} (based on best MRR value)')\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"Evaluation of the best model on test holdout in progress...\\n\")\n",
    "    \n",
    "    print(\"Best by MRR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(mrr_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(mrr_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(mrr_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by HR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(hr_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(hr_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(hr_tf).idxmax()[0])\n",
    "    print(\"Pipeline ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAJa3SH0_RNF"
   },
   "source": [
    "## Linear attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VpdpVwzd-lwL"
   },
   "outputs": [],
   "source": [
    "linear_attentions_list = [\n",
    "    {'decay_factor': 1, 'exponential_decay': False, 'reverse': False},\n",
    "    #{'decay_factor': 1, 'exponential_decay': False, 'reverse': False},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkAHiLwl-lwL",
    "outputId": "1157331d-951f-44ef-befc-0caeb4e7a357",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n",
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0255, MRR@5 = 0.0142, Coverage@5 = 0.1133, nDCG@5 = 0.01701, nDCL@5 = 0.00000\n",
      "Test : HR@10 = 0.0440, MRR@10 = 0.0168, Coverage@10 = 0.1618, nDCG@10 = 0.02248, nDCL@10 = 0.00063\n",
      "Test : HR@20 = 0.0792, MRR@20 = 0.0193, Coverage@20 = 0.2239, nDCG@20 = 0.03072, nDCL@20 = 0.00132\n",
      "------------------------------------------------------\n",
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 = 0.0171, Coverage@5 = 0.1095, nDCG@5 = 0.02032, nDCL@5 = 0.00034\n",
      "Test : HR@10 = 0.0651, MRR@10 = 0.0213, Coverage@10 = 0.1508, nDCG@10 = 0.03001, nDCL@10 = 0.00119\n",
      "Test : HR@20 = 0.1082, MRR@20 = 0.0242, Coverage@20 = 0.2080, nDCG@20 = 0.03949, nDCL@20 = 0.00249\n",
      "------------------------------------------------------\n",
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0352, MRR@5 = 0.0185, Coverage@5 = 0.1158, nDCG@5 = 0.02183, nDCL@5 = 0.00072\n",
      "Test : HR@10 = 0.0642, MRR@10 = 0.0224, Coverage@10 = 0.1554, nDCG@10 = 0.03041, nDCL@10 = 0.00152\n",
      "Test : HR@20 = 0.1161, MRR@20 = 0.0259, Coverage@20 = 0.2118, nDCG@20 = 0.04240, nDCL@20 = 0.00259\n",
      "------------------------------------------------------\n",
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0343, MRR@5 = 0.0184, Coverage@5 = 0.1208, nDCG@5 = 0.02149, nDCL@5 = 0.00078\n",
      "Test : HR@10 = 0.0668, MRR@10 = 0.0227, Coverage@10 = 0.1590, nDCG@10 = 0.03115, nDCL@10 = 0.00159\n",
      "Test : HR@20 = 0.1143, MRR@20 = 0.0260, Coverage@20 = 0.2179, nDCG@20 = 0.04164, nDCL@20 = 0.00311\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/216 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 = 0.0173, Coverage@5 = 0.1164, nDCG@5 = 0.02002, nDCL@5 = 0.00055\n",
      "Test : HR@10 = 0.0580, MRR@10 = 0.0208, Coverage@10 = 0.1546, nDCG@10 = 0.02792, nDCL@10 = 0.00133\n",
      "Test : HR@20 = 0.1055, MRR@20 = 0.0240, Coverage@20 = 0.2099, nDCG@20 = 0.03943, nDCL@20 = 0.00173\n",
      "------------------------------------------------------\n",
      "Tuning model for all contexts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [1:59:13<00:00, 33.12s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.1038 achieved with context 2+3+4+5 and mlrank = (275, 275, 5) and scale factor = 0.5\n",
      "Best MRR=0.0428 achieved with context 2+3+4+5 and mlrank = (300, 300, 4) and scale factor = 0.5\n",
      "COV=0.3010 (based on best MRR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n",
      "\n",
      "Best by MRR@10:\n",
      "\n",
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0519, MRR@5 = 0.0263, Coverage@5 = 0.2355, nDCG@5 = 0.02570, nDCL@5 = 0.00685\n",
      "Test : HR@10 = 0.0739, MRR@10 = 0.0292, Coverage@10 = 0.2996, nDCG@10 = 0.03199, nDCL@10 = 0.00766\n",
      "Test : HR@20 = 0.1126, MRR@20 = 0.0318, Coverage@20 = 0.3777, nDCG@20 = 0.04073, nDCL@20 = 0.00861\n",
      "---------------------------------------------------------\n",
      "Best by HR@10:\n",
      "\n",
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0475, MRR@5 = 0.0239, Coverage@5 = 0.2264, nDCG@5 = 0.02358, nDCL@5 = 0.00611\n",
      "Test : HR@10 = 0.0721, MRR@10 = 0.0272, Coverage@10 = 0.2927, nDCG@10 = 0.03067, nDCL@10 = 0.00700\n",
      "Test : HR@20 = 0.1082, MRR@20 = 0.0298, Coverage@20 = 0.3722, nDCG@20 = 0.03849, nDCL@20 = 0.00837\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "for params in linear_attentions_list:\n",
    "    \n",
    "    config[\"params\"] = params\n",
    "    \n",
    "    #best_num_iter_sa_hooi(config, training, data_description, np.array([]), testset_valid, holdout_valid)\n",
    "    full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.85, 0.5 , 0.1 , 0.  ],\n",
       "       [0.85, 1.  , 0.65, 0.2 , 0.05],\n",
       "       [0.5 , 0.65, 1.  , 0.75, 0.2 ],\n",
       "       [0.1 , 0.2 , 0.75, 1.  , 0.85],\n",
       "       [0.  , 0.05, 0.2 , 0.85, 1.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = np.array([[1, 0.85, 0.5, 0.1, 0], [0.85, 1, 0.65, 0.2, 0.05], [0.5, 0.65, 1, 0.75, 0.2], [0.1, 0.2, 0.75, 1, 0.85], [0, 0.05, 0.2, 0.85, 1]])\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86030365,  0.46408882,  0.21104287, -0.0075498 , -0.00117653],\n",
       "       [ 0.46408882,  0.8228861 ,  0.32961986,  0.02604066,  0.02409949],\n",
       "       [ 0.21104287,  0.32961986,  0.79451066,  0.48479688, -0.0301396 ],\n",
       "       [-0.0075498 ,  0.02604066,  0.48479688,  0.71597228,  0.53580926],\n",
       "       [-0.00117653,  0.02409949, -0.0301396 ,  0.53580926,  0.85263566]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "attention_matrix = scipy.linalg.sqrtm(similarity_matrix).real\n",
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n",
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0161, Coverage@5 = 0.1062, nDCG@5 = 0.01947, nDCL@5 = 0.00000\n",
      "Test : HR@10 = 0.0624, MRR@10 = 0.0203, Coverage@10 = 0.1475, nDCG@10 = 0.02957, nDCL@10 = 0.00029\n",
      "Test : HR@20 = 0.0994, MRR@20 = 0.0228, Coverage@20 = 0.2039, nDCG@20 = 0.03734, nDCL@20 = 0.00183\n",
      "------------------------------------------------------\n",
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0175, Coverage@5 = 0.1078, nDCG@5 = 0.02008, nDCL@5 = 0.00044\n",
      "Test : HR@10 = 0.0668, MRR@10 = 0.0223, Coverage@10 = 0.1486, nDCG@10 = 0.03109, nDCL@10 = 0.00126\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0260, Coverage@20 = 0.1997, nDCG@20 = 0.04317, nDCL@20 = 0.00261\n",
      "------------------------------------------------------\n",
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0169, Coverage@5 = 0.1125, nDCG@5 = 0.01963, nDCL@5 = 0.00044\n",
      "Test : HR@10 = 0.0677, MRR@10 = 0.0219, Coverage@10 = 0.1549, nDCG@10 = 0.03154, nDCL@10 = 0.00073\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0255, Coverage@20 = 0.2074, nDCG@20 = 0.04259, nDCL@20 = 0.00274\n",
      "------------------------------------------------------\n",
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 = 0.0182, Coverage@5 = 0.1180, nDCG@5 = 0.02078, nDCL@5 = 0.00044\n",
      "Test : HR@10 = 0.0660, MRR@10 = 0.0227, Coverage@10 = 0.1612, nDCG@10 = 0.03144, nDCL@10 = 0.00099\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0265, Coverage@20 = 0.2171, nDCG@20 = 0.04285, nDCL@20 = 0.00320\n",
      "------------------------------------------------------\n",
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0281, MRR@5 = 0.0160, Coverage@5 = 0.1122, nDCG@5 = 0.01897, nDCL@5 = 0.00000\n",
      "Test : HR@10 = 0.0624, MRR@10 = 0.0206, Coverage@10 = 0.1530, nDCG@10 = 0.02941, nDCL@10 = 0.00061\n",
      "Test : HR@20 = 0.1196, MRR@20 = 0.0245, Coverage@20 = 0.2050, nDCG@20 = 0.04208, nDCL@20 = 0.00232\n",
      "------------------------------------------------------\n",
      "Tuning model for all contexts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/324 [02:20<12:35:38, 140.37s/it]"
     ]
    }
   ],
   "source": [
    "config[\"params\"] = {}\n",
    "\n",
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHY4qoqt_aEi"
   },
   "source": [
    "## Exponential attention, decay factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX1ein75-lwN"
   },
   "outputs": [],
   "source": [
    "exponential_attentions_list = [\n",
    "    {'decay_factor': 1, 'exponential_decay': True, 'reverse': True},\n",
    "    {'decay_factor': 1, 'exponential_decay': True, 'reverse': False}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARiPOSQn-lwO",
    "outputId": "bf3c637c-55b2-4525-e81d-d8fa13ca6f9f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1346.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0162, Coverage@5 = 0.0754\n",
      "Validation : HR@10 = 0.0431, MRR@10 == 0.0180, Coverage@10 = 0.1111\n",
      "Validation : HR@20 = 0.0853, MRR@20 == 0.0207, Coverage@20 = 0.1565\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1391.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0133, Coverage@5 = 0.0779\n",
      "Validation : HR@10 = 0.0545, MRR@10 == 0.0166, Coverage@10 = 0.1092\n",
      "Validation : HR@20 = 0.0897, MRR@20 == 0.0188, Coverage@20 = 0.1538\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1387.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0264, MRR@5 == 0.0158, Coverage@5 = 0.0817\n",
      "Validation : HR@10 = 0.0519, MRR@10 == 0.0193, Coverage@10 = 0.1136\n",
      "Validation : HR@20 = 0.0959, MRR@20 == 0.0222, Coverage@20 = 0.1538\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1311.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0264, MRR@5 == 0.0165, Coverage@5 = 0.0820\n",
      "Validation : HR@10 = 0.0536, MRR@10 == 0.0201, Coverage@10 = 0.1142\n",
      "Validation : HR@20 = 0.0950, MRR@20 == 0.0228, Coverage@20 = 0.1554\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1171.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0211, MRR@5 == 0.0133, Coverage@5 = 0.0795\n",
      "Validation : HR@10 = 0.0501, MRR@10 == 0.0171, Coverage@10 = 0.1109\n",
      "Validation : HR@20 = 0.0906, MRR@20 == 0.0199, Coverage@20 = 0.1543\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:48<00:00,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0721 achieved with mlrank=(50, 55, 5)\n",
      "Best MRR=0.0259 achieved with mlrank=(55, 55, 5)\n",
      "COV=0.1334 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1035.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 == 0.0147, Coverage@5 = 0.1021\n",
      "Test : HR@10 = 0.0519, MRR@10 == 0.0173, Coverage@10 = 0.1343\n",
      "Test : HR@20 = 0.0932, MRR@20 == 0.0201, Coverage@20 = 0.1843\n",
      "Pipeline ended.\n",
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1282.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0273, MRR@5 == 0.0150, Coverage@5 = 0.1078\n",
      "Validation : HR@10 = 0.0466, MRR@10 == 0.0175, Coverage@10 = 0.1521\n",
      "Validation : HR@20 = 0.0765, MRR@20 == 0.0194, Coverage@20 = 0.2135\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1282.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0273, MRR@5 == 0.0155, Coverage@5 = 0.1040\n",
      "Validation : HR@10 = 0.0563, MRR@10 == 0.0192, Coverage@10 = 0.1450\n",
      "Validation : HR@20 = 0.0985, MRR@20 == 0.0221, Coverage@20 = 0.1981\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1218.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0162, Coverage@5 = 0.1114\n",
      "Validation : HR@10 = 0.0580, MRR@10 == 0.0197, Coverage@10 = 0.1554\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0228, Coverage@20 = 0.2085\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1191.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0162, Coverage@5 = 0.1147\n",
      "Validation : HR@10 = 0.0589, MRR@10 == 0.0200, Coverage@10 = 0.1574\n",
      "Validation : HR@20 = 0.1064, MRR@20 == 0.0234, Coverage@20 = 0.2138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1139.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0163, Coverage@5 = 0.1073\n",
      "Validation : HR@10 = 0.0519, MRR@10 == 0.0189, Coverage@10 = 0.1469\n",
      "Validation : HR@20 = 0.0932, MRR@20 == 0.0218, Coverage@20 = 0.2072\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:02<00:00,  6.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0712 achieved with mlrank=(55, 45, 5)\n",
      "Best MRR=0.0260 achieved with mlrank=(55, 45, 5)\n",
      "COV=0.1678 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1129.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0229, MRR@5 == 0.0121, Coverage@5 = 0.1241\n",
      "Test : HR@10 = 0.0493, MRR@10 == 0.0157, Coverage@10 = 0.1673\n",
      "Test : HR@20 = 0.1003, MRR@20 == 0.0191, Coverage@20 = 0.2261\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "for params in exponential_attentions_list:\n",
    "    \n",
    "    config[\"params\"] = params\n",
    "    \n",
    "    full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZJWFtvA_fMT"
   },
   "source": [
    "## Eucledian distance attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVn3hrQqAThd"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        eucl_matrix[i, j] = 1.0 / np.exp(abs(i - j)) if i != j else 1#5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "#for i in range(5):\n",
    "#    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqjrI5XWTmdv",
    "outputId": "efbdd857-1dc6-4fce-d44a-eb94243650c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 454.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0281, MRR@5 = 0.0146, Coverage@5 = 0.1062, nDCG@5 = 0.017867376002130942, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0449, MRR@10 = 0.0167, Coverage@10 = 0.1486, nDCG@10 = 0.022810376704779294, nDCL@10 = 0.00031328688400001953\n",
      "Test : HR@20 = 0.0827, MRR@20 = 0.0192, Coverage@20 = 0.2074, nDCG@20 = 0.03182850401950546, nDCL@20 = 0.0007760803573836037\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 428.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0246, MRR@5 = 0.0142, Coverage@5 = 0.1059, nDCG@5 = 0.01677526696874801, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0589, MRR@10 = 0.0186, Coverage@10 = 0.1431, nDCG@10 = 0.02712028100059107, nDCL@10 = 0.0005780450156306099\n",
      "Test : HR@20 = 0.1003, MRR@20 = 0.0215, Coverage@20 = 0.1981, nDCG@20 = 0.03698954841129931, nDCL@20 = 0.0011894372442691652\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 429.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0290, MRR@5 = 0.0153, Coverage@5 = 0.1125, nDCG@5 = 0.01865985435740027, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0563, MRR@10 = 0.0188, Coverage@10 = 0.1549, nDCG@10 = 0.026520271658344773, nDCL@10 = 0.0008196655666098846\n",
      "Test : HR@20 = 0.1064, MRR@20 = 0.0223, Coverage@20 = 0.2063, nDCG@20 = 0.03840486802109786, nDCL@20 = 0.0016456180005074892\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 422.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0159, Coverage@5 = 0.1155, nDCG@5 = 0.019391362227246023, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0607, MRR@10 = 0.0199, Coverage@10 = 0.1604, nDCG@10 = 0.028057738861461328, nDCL@10 = 0.0010970378230025263\n",
      "Test : HR@20 = 0.1073, MRR@20 = 0.0232, Coverage@20 = 0.2157, nDCG@20 = 0.03890728791062438, nDCL@20 = 0.0021498433369555206\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 406.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0299, MRR@5 = 0.0154, Coverage@5 = 0.1067, nDCG@5 = 0.018939600060349285, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0545, MRR@10 = 0.0185, Coverage@10 = 0.1494, nDCG@10 = 0.026126076323414085, nDCL@10 = 0.000570622876094162\n",
      "Test : HR@20 = 0.0959, MRR@20 = 0.0213, Coverage@20 = 0.2088, nDCG@20 = 0.035744226202484616, nDCL@20 = 0.0013849021974513384\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:31<00:00, 10.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0704 achieved with mlrank=(55, 50, 5)\n",
      "Best MRR=0.0260 achieved with mlrank=(55, 45, 5)\n",
      "COV=0.1684 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:03, 377.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0229, MRR@5 = 0.0130, Coverage@5 = 0.1230, nDCG@5 = 0.013501595259558496, nDCL@5 = 0.0019002272838202505\n",
      "Test : HR@10 = 0.0510, MRR@10 = 0.0167, Coverage@10 = 0.1673, nDCG@10 = 0.021426338215084297, nDCL@10 = 0.0030055584084011963\n",
      "Test : HR@20 = 0.1003, MRR@20 = 0.0200, Coverage@20 = 0.2256, nDCG@20 = 0.03159885631636453, nDCL@20 = 0.005175396057991248\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9NOoGl7_jYO"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        eucl_matrix[i, j] = abs(i - j) / np.exp(abs(i - j)) if i != j else 1#5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "#for i in range(5):\n",
    "#    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_O5eTPe_i91",
    "outputId": "9faf46ec-56ef-4c08-ca48-7849d8fbc4ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36787944, 0.27067057, 0.14936121, 0.07326256],\n",
       "       [0.36787944, 1.        , 0.36787944, 0.27067057, 0.14936121],\n",
       "       [0.27067057, 0.36787944, 1.        , 0.36787944, 0.27067057],\n",
       "       [0.14936121, 0.27067057, 0.36787944, 1.        , 0.36787944],\n",
       "       [0.07326256, 0.14936121, 0.27067057, 0.36787944, 1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eucl_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5W5oYqHs-lwS",
    "outputId": "66a59e69-ecd8-4975-abf6-62702a42341b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 449.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0325, MRR@5 = 0.0173, Coverage@5 = 0.1133, nDCG@5 = 0.02060432236528717, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0484, MRR@10 = 0.0195, Coverage@10 = 0.1615, nDCG@10 = 0.024949103516384515, nDCL@10 = 0.0013205621816481372\n",
      "Test : HR@20 = 0.0862, MRR@20 = 0.0221, Coverage@20 = 0.2184, nDCG@20 = 0.03389446271350918, nDCL@20 = 0.0019477206355299238\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 436.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0273, MRR@5 = 0.0165, Coverage@5 = 0.1067, nDCG@5 = 0.0188046987495604, nDCL@5 = 0.0003402399360022354\n",
      "Test : HR@10 = 0.0607, MRR@10 = 0.0208, Coverage@10 = 0.1464, nDCG@10 = 0.029122114892130457, nDCL@10 = 0.0006176936534918825\n",
      "Test : HR@20 = 0.1055, MRR@20 = 0.0239, Coverage@20 = 0.2014, nDCG@20 = 0.03892623484222006, nDCL@20 = 0.002164813185781927\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 435.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0308, MRR@5 = 0.0182, Coverage@5 = 0.1117, nDCG@5 = 0.02095813684883867, nDCL@5 = 0.0003402399360022354\n",
      "Test : HR@10 = 0.0651, MRR@10 = 0.0228, Coverage@10 = 0.1552, nDCG@10 = 0.031430396324063546, nDCL@10 = 0.0009309805374919021\n",
      "Test : HR@20 = 0.1117, MRR@20 = 0.0260, Coverage@20 = 0.2083, nDCG@20 = 0.041667131483007276, nDCL@20 = 0.00242245621538168\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 433.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0182, Coverage@5 = 0.1177, nDCG@5 = 0.02147860868588538, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0677, MRR@10 = 0.0227, Coverage@10 = 0.1604, nDCG@10 = 0.0318932798429734, nDCL@10 = 0.001030494339396439\n",
      "Test : HR@20 = 0.1170, MRR@20 = 0.0260, Coverage@20 = 0.2162, nDCG@20 = 0.041897268132751256, nDCL@20 = 0.003395215076820426\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 422.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 = 0.0182, Coverage@5 = 0.1087, nDCG@5 = 0.02105086337696857, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0536, MRR@10 = 0.0211, Coverage@10 = 0.1516, nDCG@10 = 0.02782691500401366, nDCL@10 = 0.0007172074553964193\n",
      "Test : HR@20 = 0.0994, MRR@20 = 0.0242, Coverage@20 = 0.2061, nDCG@20 = 0.03847711975476604, nDCL@20 = 0.0015739320900605947\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:32<00:00, 10.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0756 achieved with mlrank=(55, 45, 5)\n",
      "Best MRR=0.0261 achieved with mlrank=(55, 50, 5)\n",
      "COV=0.1714 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:03, 371.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0264, MRR@5 = 0.0140, Coverage@5 = 0.1285, nDCG@5 = 0.015803032964804557, nDCL@5 = 0.001235387306983765\n",
      "Test : HR@10 = 0.0563, MRR@10 = 0.0178, Coverage@10 = 0.1714, nDCG@10 = 0.02423695351166098, nDCL@10 = 0.002307115419365183\n",
      "Test : HR@20 = 0.0959, MRR@20 = 0.0205, Coverage@20 = 0.2325, nDCG@20 = 0.031898621460716925, nDCL@20 = 0.004529182667381669\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYMZzRsB-lwT"
   },
   "source": [
    "## Rating distribution attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOW0iu_z-lwV",
    "outputId": "f9e5e9c0-4737-4b68-ed50-079df0d9121c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.056644931644931645,\n",
       " 0.10500693000693001,\n",
       " 0.25943898443898444,\n",
       " 0.3442087192087192,\n",
       " 0.2347004347004347]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_dist = []\n",
    "\n",
    "total_cnt = training.shape[0]\n",
    "\n",
    "for i in range(5):\n",
    "    val = training.query(f'rating == {i + 1}').count()[0] / total_cnt\n",
    "    \n",
    "    rating_dist.append(val)\n",
    "\n",
    "rating_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cGm3uxPQK-4",
    "outputId": "a0465ef1-27b6-48ac-bb3c-e89f10000879"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[        inf,  1.17126946,  0.27932245,  0.19698214,  0.31813076],\n",
       "       [ 2.17126946,         inf,  0.67995553,  0.4389889 ,  0.8096545 ],\n",
       "       [ 1.27932245,  1.67995553,         inf,  3.06051429, 10.48723499],\n",
       "       [ 1.19698214,  1.4389889 ,  4.06051429,         inf,  3.14322081],\n",
       "       [ 1.31813076,  1.8096545 ,  9.48723499,  2.14322081,         inf]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        rat_dist_matrix[i, j] = rating_dist[i] / abs(rating_dist[i] - rating_dist[j])\n",
    "        #rat_dist_matrix[i, j] = diff / np.exp(diff) if i != j else 1. + 1e-1\n",
    "\n",
    "rat_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVtjj-UD-lwW"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        diff = abs(rating_dist[i] - rating_dist[j])\n",
    "        rat_dist_matrix[i, j] = diff / np.exp(diff) if i != j else 1. + 1e-1\n",
    "        \n",
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)\n",
    "#rat_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qcbsCWe-lwZ",
    "outputId": "8f1da19a-e989-4a15-d5ae-64fc43e5683c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 445.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Test : HR@5 = 0.0237, MRR@5 = 0.0144, Coverage@5 = 0.1117, nDCG@5 = 0.016772111754940346, nDCL@5 = 0.0\n",
      "Test : HR@10 = 0.0466, MRR@10 = 0.0175, Coverage@10 = 0.1546, nDCG@10 = 0.023598806239983595, nDCL@10 = 0.0005780450156306099\n",
      "Test : HR@20 = 0.0783, MRR@20 = 0.0197, Coverage@20 = 0.2036, nDCG@20 = 0.03118319086912337, nDCL@20 = 0.0010092849309640722\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 421.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0200, Coverage@5 = 0.1109, nDCG@5 = 0.02287084881401924, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0642, MRR@10 = 0.0240, Coverage@10 = 0.1499, nDCG@10 = 0.03215653999889215, nDCL@10 = 0.001030494339396439\n",
      "Test : HR@20 = 0.1091, MRR@20 = 0.0270, Coverage@20 = 0.2014, nDCG@20 = 0.042042408086102726, nDCL@20 = 0.002324415387296944\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 430.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0352, MRR@5 = 0.0200, Coverage@5 = 0.1131, nDCG@5 = 0.023292283101531776, nDCL@5 = 0.00043975373790677223\n",
      "Test : HR@10 = 0.0774, MRR@10 = 0.0255, Coverage@10 = 0.1508, nDCG@10 = 0.035593016466947444, nDCL@10 = 0.0015958437691679919\n",
      "Test : HR@20 = 0.1223, MRR@20 = 0.0283, Coverage@20 = 0.2044, nDCG@20 = 0.04514020087027024, nDCL@20 = 0.003077443022063615\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 428.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0369, MRR@5 = 0.0199, Coverage@5 = 0.1142, nDCG@5 = 0.023307446744329403, nDCL@5 = 0.0007190231884854308\n",
      "Test : HR@10 = 0.0712, MRR@10 = 0.0242, Coverage@10 = 0.1535, nDCG@10 = 0.033375587900277, nDCL@10 = 0.0015386887550953153\n",
      "Test : HR@20 = 0.1187, MRR@20 = 0.0274, Coverage@20 = 0.2052, nDCG@20 = 0.043284447809058275, nDCL@20 = 0.0034691192822309458\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:02, 402.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Test : HR@5 = 0.0334, MRR@5 = 0.0172, Coverage@5 = 0.1144, nDCG@5 = 0.02074601094985069, nDCL@5 = 0.0003787832524831953\n",
      "Test : HR@10 = 0.0712, MRR@10 = 0.0221, Coverage@10 = 0.1552, nDCG@10 = 0.03205373289389733, nDCL@10 = 0.0012005394879658672\n",
      "Test : HR@20 = 0.1214, MRR@20 = 0.0255, Coverage@20 = 0.2028, nDCG@20 = 0.04261636016198688, nDCL@20 = 0.0031542602033563837\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [06:30<00:00, 10.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0844 achieved with mlrank=(50, 45, 5)\n",
      "Best MRR=0.0306 achieved with mlrank=(55, 55, 5)\n",
      "COV=0.1772 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:03, 344.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0317, MRR@5 = 0.0143, Coverage@5 = 0.1348, nDCG@5 = 0.016939382722254145, nDCL@5 = 0.0016141705594669602\n",
      "Test : HR@10 = 0.0580, MRR@10 = 0.0179, Coverage@10 = 0.1774, nDCG@10 = 0.02469648307522927, nDCL@10 = 0.0024464502508388963\n",
      "Test : HR@20 = 0.1055, MRR@20 = 0.0211, Coverage@20 = 0.2333, nDCG@20 = 0.034409123222778414, nDCL@20 = 0.004649546849046022\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU04z-n1-lwa"
   },
   "source": [
    "## Trigonometry scale attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJiHTF7_-lwb"
   },
   "outputs": [],
   "source": [
    "def rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pQN1IHU-lwc"
   },
   "outputs": [],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = rescale_score(i + 1), rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = diff / np.exp(diff) if i != j else 5 + 1e-2\n",
    "        \n",
    "a = np.linalg.cholesky(eucl_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQtcfKcE-lwc",
    "outputId": "989556b9-ee77-47f7-ada3-7819ec240f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1441.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0343, MRR@5 == 0.0208, Coverage@5 = 0.1048\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1461\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0271, Coverage@20 = 0.2014\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1129.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0183, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0633, MRR@10 == 0.0228, Coverage@10 = 0.1475\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0260, Coverage@20 = 0.2003\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1357.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0730, MRR@10 == 0.0243, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1258, MRR@20 == 0.0277, Coverage@20 = 0.2047\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1302.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0369, MRR@5 == 0.0198, Coverage@5 = 0.1150\n",
      "Validation : HR@10 = 0.0704, MRR@10 == 0.0242, Coverage@10 = 0.1541\n",
      "Validation : HR@20 = 0.1249, MRR@20 == 0.0278, Coverage@20 = 0.2096\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1127.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0009, MRR@5 == 0.0003, Coverage@5 = 0.1653\n",
      "Validation : HR@10 = 0.0018, MRR@10 == 0.0004, Coverage@10 = 0.2360\n",
      "Validation : HR@20 = 0.0026, MRR@20 == 0.0005, Coverage@20 = 0.3249\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:58<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0844 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0303 achieved with mlrank=(50, 50, 5)\n",
      "COV=0.1750 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1045.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0237, MRR@5 == 0.0103, Coverage@5 = 0.1287\n",
      "Test : HR@10 = 0.0589, MRR@10 == 0.0150, Coverage@10 = 0.1744\n",
      "Test : HR@20 = 0.0994, MRR@20 == 0.0177, Coverage@20 = 0.2338\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56vIkauV-lwd"
   },
   "outputs": [],
   "source": [
    "def center_and_rescale_score(x, func=None):\n",
    "    \n",
    "    if func is None:\n",
    "        func = np.arctan\n",
    "    \n",
    "    return func(x - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AyRMQch-lwe",
    "outputId": "549aaf3d-a9ea-4476-b139-7e64607dbf1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.75657241 0.47457495 0.34571609 0.31110998]\n",
      " [0.75657241 1.         0.56009915 0.38898453 0.34571609]\n",
      " [0.47457495 0.56009915 1.         0.56009915 0.47457495]\n",
      " [0.34571609 0.38898453 0.56009915 1.         0.75657241]\n",
      " [0.31110998 0.34571609 0.47457495 0.75657241 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "eucl_matrix = np.zeros((5, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        \n",
    "        k, l = center_and_rescale_score(i + 1), center_and_rescale_score(j + 1)\n",
    "        \n",
    "        diff = abs(k - l)\n",
    "        \n",
    "        eucl_matrix[i, j] = 1 / (diff + 1)\n",
    "\n",
    "similarity = eucl_matrix\n",
    "        \n",
    "print(similarity)\n",
    "    \n",
    "a = np.linalg.cholesky(similarity)        \n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdXGb7Wb-lwf",
    "outputId": "604d12fb-6502-4041-cc4e-5c6d163c1254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1482.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0190, Coverage@5 = 0.1111\n",
      "Validation : HR@10 = 0.0528, MRR@10 == 0.0222, Coverage@10 = 0.1530\n",
      "Validation : HR@20 = 0.0871, MRR@20 == 0.0245, Coverage@20 = 0.2168\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1424.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0281, MRR@5 == 0.0192, Coverage@5 = 0.1103\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0235, Coverage@10 = 0.1505\n",
      "Validation : HR@20 = 0.1108, MRR@20 == 0.0270, Coverage@20 = 0.2039\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1415.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0308, MRR@5 == 0.0197, Coverage@5 = 0.1139\n",
      "Validation : HR@10 = 0.0686, MRR@10 == 0.0246, Coverage@10 = 0.1552\n",
      "Validation : HR@20 = 0.1161, MRR@20 == 0.0279, Coverage@20 = 0.2110\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1366.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0290, MRR@5 == 0.0187, Coverage@5 = 0.1164\n",
      "Validation : HR@10 = 0.0677, MRR@10 == 0.0239, Coverage@10 = 0.1596\n",
      "Validation : HR@20 = 0.1152, MRR@20 == 0.0272, Coverage@20 = 0.2138\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1312.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0180, Coverage@5 = 0.1109\n",
      "Validation : HR@10 = 0.0572, MRR@10 == 0.0217, Coverage@10 = 0.1527\n",
      "Validation : HR@20 = 0.1099, MRR@20 == 0.0253, Coverage@20 = 0.2116\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:38<00:00,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0827 achieved with mlrank=(50, 50, 5)\n",
      "Best MRR=0.0293 achieved with mlrank=(55, 50, 5)\n",
      "COV=0.1816 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1105.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0246, MRR@5 == 0.0129, Coverage@5 = 0.1312\n",
      "Test : HR@10 = 0.0554, MRR@10 == 0.0168, Coverage@10 = 0.1816\n",
      "Test : HR@20 = 0.0985, MRR@20 == 0.0198, Coverage@20 = 0.2454\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ5eMt1G-lwg"
   },
   "source": [
    "## Conditional prob attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2f472Za-lwg"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count12_tot = 0\n",
    "count12_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "     count12_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count12_loc += 1\n",
    "  count12_tot += count12_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvf78Rfb-lwh"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count13_tot = 0\n",
    "count13_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count13_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count13_loc += 1\n",
    "  count13_tot += count13_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJHQliXB-lwh"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count14_tot = 0\n",
    "count14_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count14_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count14_loc += 1\n",
    "  count14_tot += count14_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uc9cn3J-lwj"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count15_tot = 0\n",
    "count15_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 1 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count15_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 1:\n",
    "      count15_loc += 1\n",
    "  count15_tot += count15_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLXk6x4G-lwk"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count23_tot = 0\n",
    "count23_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "     count23_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count23_loc += 1\n",
    "  count23_tot += count23_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FlI1HRm-lwo"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count24_tot = 0\n",
    "count24_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count24_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count24_loc += 1\n",
    "  count24_tot += count24_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tawueqnY-lwq"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count25_tot = 0\n",
    "count25_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 2 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count25_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 2:\n",
    "      count25_loc += 1\n",
    "  count25_tot += count25_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-A4Q24n-lwu"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count34_tot = 0\n",
    "count34_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "     count34_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count34_loc += 1\n",
    "  count34_tot += count34_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3YNSNjX-lwv"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count35_tot = 0\n",
    "count35_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 3 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count35_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 3:\n",
    "      count35_loc += 1\n",
    "  count35_tot += count35_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AisgFMpm-lww"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4| rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count45_tot = 0\n",
    "count45_loc = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  train_new_part_user = train_new_part_user.reset_index()\n",
    "  for i in range(1, len(train_new_part_user)):\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 4 and train_new_part_user.loc[i-1, 'rating' ]== 5:\n",
    "     count45_loc += 1\n",
    "    if train_new_part_user.loc[i, 'rating' ] == 5 and train_new_part_user.loc[i-1, 'rating' ]== 4:\n",
    "      count45_loc += 1\n",
    "  count45_tot += count45_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJ_R_SJS-lwx"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 1')\n",
    "users = train_new_part.userid.unique()\n",
    "count11_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count11_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBDskvQm-lwy"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 2')\n",
    "users = train_new_part.userid.unique()\n",
    "count22_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count22_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YkuEEsn-lwy"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 3')\n",
    "users = train_new_part.userid.unique()\n",
    "count33_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count33_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmfoz1Mw-lw0"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 4')\n",
    "users = train_new_part.userid.unique()\n",
    "count44_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count44_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpfZSAEp-lw1"
   },
   "outputs": [],
   "source": [
    "train_new_part = train_new.query('rating == 5')\n",
    "users = train_new_part.userid.unique()\n",
    "count55_tot = 0\n",
    "for user in users:\n",
    "  train_new_part_user = train_new_part.query('userid == @user') \n",
    "  count55_tot += len(train_new_part_user)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ri7dKAgV-lw2"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix = np.zeros((5, 5))\n",
    "\n",
    "rat_dist_matrix[0][0] = count11_tot\n",
    "rat_dist_matrix[0][1] = rat_dist_matrix[1][0]= count12_tot\n",
    "rat_dist_matrix[0][2] = rat_dist_matrix[2][0]= count13_tot\n",
    "rat_dist_matrix[0][3] = rat_dist_matrix[3][0]= count14_tot\n",
    "rat_dist_matrix[0][4] = rat_dist_matrix[4][0]= count15_tot\n",
    "rat_dist_matrix[1][1] = count22_tot\n",
    "rat_dist_matrix[1][2] = rat_dist_matrix[2][1] = count23_tot\n",
    "rat_dist_matrix[1][3] = rat_dist_matrix[3][1] = count24_tot\n",
    "rat_dist_matrix[1][4] = rat_dist_matrix[4][1] = count25_tot\n",
    "rat_dist_matrix[2][2] = count33_tot\n",
    "rat_dist_matrix[2][3] = rat_dist_matrix[3][2] = count34_tot\n",
    "rat_dist_matrix[2][4] = rat_dist_matrix[4][2] = count35_tot\n",
    "rat_dist_matrix[3][3] = count44_tot\n",
    "rat_dist_matrix[3][4] = rat_dist_matrix[4][3] = count45_tot\n",
    "rat_dist_matrix[4][4] = count55_tot       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9tfKojo-lw3"
   },
   "outputs": [],
   "source": [
    "summ = np.sum(rat_dist_matrix)\n",
    "rat_dist_matrix /= summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63xlkdVN-lw4"
   },
   "outputs": [],
   "source": [
    "rat_dist_matrix[0,0] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[1,1] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[2,2] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[3,3] += np.random.uniform(low=0.0, high=1.0)\n",
    "rat_dist_matrix[4,4] += np.random.uniform(low=0.0, high=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9_koO81-lw4"
   },
   "outputs": [],
   "source": [
    "a = np.linalg.cholesky(rat_dist_matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    a[i, i] = 1e-5\n",
    "\n",
    "attention_matrix = csr_matrix(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOP1rnpS-lw5",
    "outputId": "722042ce-74d0-4138-aaf3-9f15b38ed67e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1542.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 5 evaluation:\n",
      "Validation : HR@5 = 0.0299, MRR@5 == 0.0164, Coverage@5 = 0.0949\n",
      "Validation : HR@10 = 0.0554, MRR@10 == 0.0195, Coverage@10 = 0.1337\n",
      "Validation : HR@20 = 0.0880, MRR@20 == 0.0217, Coverage@20 = 0.1796\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1359.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 4+5 evaluation:\n",
      "Validation : HR@5 = 0.0317, MRR@5 == 0.0188, Coverage@5 = 0.0988\n",
      "Validation : HR@10 = 0.0598, MRR@10 == 0.0226, Coverage@10 = 0.1309\n",
      "Validation : HR@20 = 0.0950, MRR@20 == 0.0250, Coverage@20 = 0.1772\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1444.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0352, MRR@5 == 0.0207, Coverage@5 = 0.0993\n",
      "Validation : HR@10 = 0.0642, MRR@10 == 0.0245, Coverage@10 = 0.1315\n",
      "Validation : HR@20 = 0.1047, MRR@20 == 0.0273, Coverage@20 = 0.1777\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1446.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 2+3+4+5 evaluation:\n",
      "Validation : HR@5 = 0.0334, MRR@5 == 0.0205, Coverage@5 = 0.1007\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0245, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1038, MRR@20 == 0.0273, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:00, 1284.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5-2-1 evaluation:\n",
      "Validation : HR@5 = 0.0325, MRR@5 == 0.0203, Coverage@5 = 0.1004\n",
      "Validation : HR@10 = 0.0624, MRR@10 == 0.0244, Coverage@10 = 0.1304\n",
      "Validation : HR@20 = 0.1029, MRR@20 == 0.0272, Coverage@20 = 0.1769\n",
      "------------------------------------------------------\n",
      "Tuning model with context 3+4+5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [03:55<00:00,  6.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0800 achieved with mlrank=(45, 45, 5)\n",
      "Best MRR=0.0279 achieved with mlrank=(40, 45, 5)\n",
      "COV=0.1560 (based on best HR value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1137it [00:01, 1100.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context 3+4+5 evaluation:\n",
      "Test : HR@5 = 0.0290, MRR@5 == 0.0126, Coverage@5 = 0.1161\n",
      "Test : HR@10 = 0.0528, MRR@10 == 0.0157, Coverage@10 = 0.1549\n",
      "Test : HR@20 = 0.1038, MRR@20 == 0.0190, Coverage@20 = 0.2077\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LaTTE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
