{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa30afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a3a2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:19:16.165861Z",
     "start_time": "2022-05-02T10:19:13.932737Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import polara\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, downvote_seen_items\n",
    "\n",
    "from polara.lib.tensor import hooi\n",
    "from polara.lib.sparse import tensor_outer_at\n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "from sa_hooi import sa_hooi, form_attention_matrix, get_scaling_weights, generate_position_projector\n",
    "\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from scipy.sparse.linalg import norm, svds\n",
    "from scipy.linalg import solve_triangular, sqrtm\n",
    "\n",
    "from IPython.utils import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a766d87d",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e737d371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:19:16.603929Z",
     "start_time": "2022-05-02T10:19:16.592930Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def full_preproccessing(data = None):\n",
    "    if (data is None):\n",
    "        data = get_movielens_data(\"ml-1m.zip\", include_time=True)\n",
    "    test_timepoint = data['timestamp'].quantile(\n",
    "    q=0.8, interpolation='nearest'\n",
    "    )\n",
    "    \n",
    "    if (data[\"rating\"].nunique() > 5):\n",
    "        data[\"rating\"] = (data[\"rating\"] * 2).astype(int)\n",
    "\n",
    "    test_data_ = data.query('timestamp >= @test_timepoint')\n",
    "    train_data_ = data.query(\n",
    "    'userid not in @test_data_.userid.unique() and timestamp < @test_timepoint'\n",
    "    )\n",
    "    \n",
    "    training, data_index = transform_indices(train_data_.copy(), 'userid', 'movieid')\n",
    "    test_data = reindex(test_data_, data_index['items'])\n",
    "\n",
    "    testset_, holdout_ = leave_one_out(\n",
    "    test_data, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "    testset_valid_, holdout_valid_ = leave_one_out(\n",
    "        testset_, target='timestamp', sample_top=True, random_state=0\n",
    "    )\n",
    "\n",
    "    test_users_val = np.intersect1d(testset_valid_.userid.unique(), holdout_valid_.userid.unique())\n",
    "    testset_valid = testset_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "    holdout_valid = holdout_valid_.query('userid in @test_users_val').sort_values('userid')\n",
    "\n",
    "    test_users = np.intersect1d(testset_.userid.unique(), holdout_.userid.unique())\n",
    "    testset = testset_.query('userid in @test_users').sort_values('userid')\n",
    "    holdout = holdout_.query('userid in @test_users').sort_values('userid')\n",
    "\n",
    "\n",
    "    assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
    "        testset_valid\n",
    "        .groupby('userid')\n",
    "        ['timestamp'].max()\n",
    "    ).all()\n",
    "\n",
    "    data_description = dict(\n",
    "        users = data_index['users'].name,\n",
    "        items = data_index['items'].name,\n",
    "        feedback = 'rating',\n",
    "        n_users = len(data_index['users']),\n",
    "        n_items = len(data_index['items']),\n",
    "        n_ratings = training['rating'].nunique(),\n",
    "        min_rating = training['rating'].min(),\n",
    "        test_users = holdout_valid[data_index['users'].name].drop_duplicates().values, # NEW\n",
    "        n_test_users = holdout_valid[data_index['users'].name].nunique() # NEW\n",
    "    )\n",
    "\n",
    "    return training, testset_valid, holdout_valid, testset, holdout, data_description, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd32a931",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:19:17.931854Z",
     "start_time": "2022-05-02T10:19:17.080259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 177 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, testset_valid, holdout_valid, testset, holdout, data_description, data_index = full_preproccessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d48263",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ab685b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:19:19.802459Z",
     "start_time": "2022-05-02T10:19:19.784400Z"
    },
    "code_folding": [
     52,
     70
    ]
   },
   "outputs": [],
   "source": [
    "def model_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10, dcg=False):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    alpha = 3 if holdout_description[\"n_ratings\"] == 5 else 6\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    holdout_items = holdout[itemid].values\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    \n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    \n",
    "    # HR calculation\n",
    "    #hr = np.sum(hits_mask.any(axis=1)) / n_test_users\n",
    "    hr_pos = np.sum(hits_mask[pos_mask].any(axis=1)) / n_test_users\n",
    "    hr_neg = np.sum(hits_mask[neg_mask].any(axis=1)) / n_test_users\n",
    "    hr = hr_pos + hr_neg\n",
    "    \n",
    "    # MRR calculation\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    mrr_pos = np.sum(1 / pos_hit_rank) / n_test_users\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    mrr_neg = np.sum(1 / neg_hit_rank) / n_test_users\n",
    "    \n",
    "    # Matthews correlation\n",
    "    TP = np.sum(hits_mask[pos_mask]) # + \n",
    "    FP = np.sum(hits_mask[neg_mask]) # +\n",
    "    cond = (hits_mask.sum(axis = 1) == 0)\n",
    "    FN = np.sum(cond[pos_mask])\n",
    "    TN = np.sum(cond[neg_mask])\n",
    "    N = TP+FP+TN+FN\n",
    "    S = (TP+FN)/N\n",
    "    P = (TP+FP)/N\n",
    "    C = (TP/N - S*P) / np.sqrt(P*S*(1-P)*(1-S))\n",
    "    \n",
    "    # DCG calculation\n",
    "    if dcg:\n",
    "        pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "        neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "        ndcg = np.mean(1 / np.log2(pos_hit_rank+1))\n",
    "        ndcl = np.mean(1 / np.log2(neg_hit_rank+1))\n",
    "    \n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    if dcg:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C, ndcg, ndcl\n",
    "    else:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C\n",
    "\n",
    "def make_prediction(tf_scores, holdout, data_description, mode, context=\"\", print_mode=True):\n",
    "    if (mode and print_mode):\n",
    "        print(f\"for context {context} evaluation ({mode}): \\n\")\n",
    "    for n in [5, 10, 20]:\n",
    "        tf_recs = topn_recommendations(tf_scores, n)\n",
    "        hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout, data_description, topn=n)\n",
    "        if (print_mode):\n",
    "            print(f\"HR@{n} = {hr:.4f}, MRR@{n} = {mrr:.4f}, Coverage@{n} = {cov:.4f}\")\n",
    "            print(f\"HR_pos@{n} = {hr_pos:.4f}, HR_neg@{n} = {hr_neg:.4f}\")\n",
    "            print(f\"MRR_pos@{n} = {mrr_pos:.4f}, MRR_neg@{n} = {mrr_neg:.4f}\")\n",
    "            print(f\"Matthews@{n} = {C:.4f}\")\n",
    "            print(\"-------------------------------------\")\n",
    "        if (n == 10):\n",
    "            mrr10 = mrr\n",
    "            hr10 = hr\n",
    "            c10 = C\n",
    "    return mrr10, hr10, c10\n",
    "\n",
    "def valid_mlrank(mlrank):\n",
    "    '''\n",
    "    Only allow ranks that are suitable for truncated SVD computations\n",
    "    on unfolded compressed tensor (the result of ttm product in HOOI).\n",
    "    '''\n",
    "    #s, r1, r2, r3 = mlrank\n",
    "    s, r1, r3 = mlrank\n",
    "    r2 = r1\n",
    "    #print(s, r1, r2, r3)\n",
    "    return r1*r2 > r3 and r1*r3 > r2 and r2*r3 > r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60995ae",
   "metadata": {},
   "source": [
    "# CoFFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64bd8402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:15:08.316548Z",
     "start_time": "2022-04-30T17:15:08.290549Z"
    },
    "code_folding": [
     3,
     55,
     66
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "from scipy.special import softmax\n",
    "\n",
    "def tf_model_build(config, data, data_description, testset, holdout, attention_matrix=np.array([])):\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    idx = data[[userid, itemid, feedback]].values\n",
    "    idx[:, -1] = idx[:, -1] - data_description['min_rating'] # works only for integer ratings!\n",
    "    val = np.ones(idx.shape[0], dtype='f8')\n",
    "    \n",
    "    n_users = data_description[\"n_users\"]\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    n_ratings = data_description[\"n_ratings\"]\n",
    "    shape = (n_users, n_items, n_ratings)\n",
    "    core_shape = config['mlrank']\n",
    "    num_iters = config[\"num_iters\"]\n",
    "    \n",
    "    if (attention_matrix.shape[0] == 0):\n",
    "        attention_matrix = form_attention_matrix(\n",
    "            data_description['n_ratings'],\n",
    "            **config['params'],\n",
    "            format = 'csr'\n",
    "        )\n",
    "        \n",
    "    attention_matrix = np.array(attention_matrix)\n",
    "\n",
    "    item_popularity = (\n",
    "        data[itemid]\n",
    "        .value_counts(sort=False)\n",
    "        .reindex(range(n_items))\n",
    "        .fillna(1)\n",
    "        .values\n",
    "    )\n",
    "    scaling_weights = get_scaling_weights(item_popularity, scaling=config[\"scaling\"])\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        u0, u1, u2 = sa_hooi(\n",
    "            idx, val, shape, config[\"mlrank\"],\n",
    "            attention_matrix = attention_matrix,\n",
    "            scaling_weights = scaling_weights,\n",
    "            testset = testset,\n",
    "            holdout = holdout,\n",
    "            data_description = data_description,\n",
    "            max_iters = config[\"num_iters\"],\n",
    "            parallel_ttm = True,\n",
    "            randomized = config[\"randomized\"],\n",
    "            growth_tol = config[\"growth_tol\"],\n",
    "            seed = config[\"seed\"],\n",
    "            iter_callback = None,\n",
    "        )\n",
    "    \n",
    "    return u0, u1, u2, attention_matrix    \n",
    "    \n",
    "config = {\n",
    "    \"scaling\": 1,\n",
    "    \"mlrank\": (30, 30, data_description['n_ratings']),\n",
    "    \"n_ratings\": data_description['n_ratings'],\n",
    "    \"num_iters\": 4,\n",
    "    \"params\": None,\n",
    "    \"randomized\": True,\n",
    "    \"growth_tol\": 1e-4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "def tf_scoring(params, data, data_description, context=[\"3+4+5\"]):\n",
    "    user_factors, item_factors, feedback_factors, attention_matrix = params\n",
    "    userid = data_description[\"users\"]\n",
    "    itemid = data_description[\"items\"]\n",
    "    feedback = data_description[\"feedback\"]\n",
    "\n",
    "    data = data.sort_values(userid) \n",
    "    data_new = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    ) # NEW\n",
    "    useridx = data_new[userid]\n",
    "    itemidx = data_new[itemid].values\n",
    "    ratings = data_new[feedback].values\n",
    "    ratings = ratings - data_description['min_rating'] # NEW\n",
    "    \n",
    "    n_users = useridx.nunique()\n",
    "    n_items = data_description['n_items']\n",
    "    n_ratings = data_description['n_ratings']\n",
    "    \n",
    "    inv_attention = solve_triangular(attention_matrix, np.eye(n_ratings), lower=True)\n",
    "    \n",
    "    tensor_outer = tensor_outer_at('cpu')\n",
    "    #matrix_softmax = softmax(inv_attention.T @ feedback_factors)\n",
    "    matrix_softmax = inv_attention.T @ feedback_factors\n",
    "    #\n",
    "    if (n_ratings == 10):\n",
    "        coef = 2\n",
    "    else:\n",
    "        coef = 1\n",
    "        \n",
    "    if (context == \"5\"): # make softmax \n",
    "        inv_aT_feedback = matrix_softmax[(-1 * coef) , :]\n",
    "    elif (context == \"4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[(-2 * coef):, :], axis=0)\n",
    "    elif (context == \"3+4+5\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[(-3 * coef):, :], axis=0)\n",
    "    #elif (context == \"2+3+4+5\"):\n",
    "    #    inv_aT_feedback = np.sum(matrix_softmax[-4:, :], axis=0)\n",
    "    elif (context == \"3+4+5-2-1\"):\n",
    "        inv_aT_feedback = np.sum(matrix_softmax[(-3 * coef):, :], axis=0) - np.sum(matrix_softmax[:(2 * coef), :], axis=0)\n",
    "        \n",
    "    scores = tensor_outer(\n",
    "        1.0,\n",
    "        item_factors,\n",
    "        attention_matrix @ feedback_factors,\n",
    "        itemidx,\n",
    "        ratings\n",
    "    )\n",
    "    scores = np.add.reduceat(scores, np.r_[0, np.where(np.diff(useridx))[0]+1]) # sort by users\n",
    "    scores = np.tensordot(\n",
    "        scores,\n",
    "        inv_aT_feedback,\n",
    "        axes=(2, 0)\n",
    "    ).dot(item_factors.T)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7880c95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:13:14.269550Z",
     "start_time": "2022-04-30T17:13:14.239537Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from polara.evaluation.pipelines import random_grid\n",
    "\n",
    "def full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix):\n",
    "\n",
    "    config[\"mlrank\"] = (64, 64, data_description[\"n_ratings\"])\n",
    "    print(\"Starting pipeline...\")\n",
    "    print(\"Training with different context in progress...\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "\n",
    "    for context in [\"5\", \"4+5\", \"3+4+5\", \"3+4+5-2-1\"]:\n",
    "        tf_params = tf_model_build(config, training, data_description, testset_valid, holdout_valid, attention_matrix=attention_matrix)\n",
    "        seen_data = testset_valid\n",
    "        tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "        downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "        cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout_valid, data_description, \"Validation\", context)\n",
    "        print(\"------------------------------------------------------\")\n",
    "\n",
    "    print(f\"Tuning model for all contexts...\\n\")\n",
    "\n",
    "    rank_grid = []\n",
    "    for i in range(5, 7):\n",
    "        rank_grid.append(2 * 2 ** i)\n",
    "        rank_grid.append(3 * 2 ** i)\n",
    "    \n",
    "    rank_grid = np.array(rank_grid)\n",
    "    tf_hyper = {\n",
    "    'scaling': [0.7, 1.9], #np.linspace(0, 2, 21),\n",
    "    'r1': rank_grid, #np.arange(100, 220, 25),\n",
    "    #'r2': np.arange(50, 801, 25),\n",
    "    'r3': range(1, 6, 1)#range(2, 11, 2), # change\n",
    "    }\n",
    "\n",
    "    grid, param_names = random_grid(tf_hyper, n=0)\n",
    "    tf_grid = [tuple(mlrank) for mlrank in grid if valid_mlrank(mlrank)]\n",
    "\n",
    "    hr_tf = {}\n",
    "    hr_pos_tf = {}\n",
    "    hr_neg_tf = {}\n",
    "    mrr_tf = {}\n",
    "    mrr_pos_tf = {}\n",
    "    mrr_neg_tf = {}\n",
    "    cov_tf = {}\n",
    "    C_tf = {}\n",
    "    \n",
    "    seen_data = testset_valid\n",
    "    \n",
    "    for mlrank in tqdm(tf_grid):\n",
    "        with io.capture_output() as captured:\n",
    "            r1, r3 = mlrank[1:]\n",
    "            cur_mlrank = tuple((r1, r1, r3))\n",
    "            config['mlrank'] = cur_mlrank\n",
    "            config['scaling'] = mlrank[0]\n",
    "            tf_params = tf_model_build(config, training, data_description, testset_valid, holdout_valid, attention_matrix=attention_matrix)\n",
    "            for context in [\"5\", \"4+5\", \"3+4+5\", \"3+4+5-2-1\"]:\n",
    "                tf_scores = tf_scoring(tf_params, seen_data, data_description, context)\n",
    "                downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "                tf_recs = topn_recommendations(tf_scores, topn=10)\n",
    "                \n",
    "                hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(tf_recs, holdout_valid, data_description, topn=10)\n",
    "                hr_tf[(context, cur_mlrank, mlrank[0])] = hr\n",
    "                hr_pos_tf[(context, cur_mlrank, mlrank[0])] = hr_pos\n",
    "                hr_neg_tf[(context, cur_mlrank, mlrank[0])] = hr_neg\n",
    "                mrr_tf[(context, cur_mlrank, mlrank[0])] = mrr\n",
    "                mrr_pos_tf[(context, cur_mlrank, mlrank[0])] = mrr_pos\n",
    "                mrr_neg_tf[(context, cur_mlrank, mlrank[0])] = mrr_neg\n",
    "                cov_tf[(context, cur_mlrank, mlrank[0])] = cov\n",
    "                C_tf[(context, cur_mlrank, mlrank[0])] = C\n",
    "\n",
    "    print(f'Best HR={pd.Series(hr_tf).max():.4f} achieved with context {pd.Series(hr_tf).idxmax()[0]} and mlrank = {pd.Series(hr_tf).idxmax()[1]} and scale factor = {pd.Series(hr_tf).idxmax()[2]}')\n",
    "    print(f'Best HR_pos={pd.Series(hr_pos_tf).max():.4f} achieved with context {pd.Series(hr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(hr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(hr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best HR_neg={pd.Series(hr_neg_tf).min():.4f} achieved with context {pd.Series(hr_neg_tf).idxmin()[0]} and mlrank = {pd.Series(hr_neg_tf).idxmin()[1]} and scale factor = {pd.Series(hr_neg_tf).idxmin()[2]}')\n",
    "    \n",
    "    print(f'Best MRR={pd.Series(mrr_tf).max():.4f} achieved with context {pd.Series(mrr_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR_pos={pd.Series(mrr_pos_tf).max():.4f} achieved with context {pd.Series(mrr_pos_tf).idxmax()[0]} and mlrank = {pd.Series(mrr_pos_tf).idxmax()[1]} and scale factor = {pd.Series(mrr_pos_tf).idxmax()[2]}')\n",
    "    print(f'Best MRR_neg={pd.Series(mrr_neg_tf).min():.4f} achieved with context {pd.Series(mrr_neg_tf).idxmin()[0]} and mlrank = {pd.Series(mrr_neg_tf).idxmin()[1]} and scale factor = {pd.Series(mrr_neg_tf).idxmin()[2]}')\n",
    "    \n",
    "    print(f'Best Matthews={pd.Series(C_tf).max():.4f} achieved with context {pd.Series(C_tf).idxmax()[0]} and mlrank = {pd.Series(C_tf).idxmax()[1]} and scale factor = {pd.Series(C_tf).idxmax()[2]}')\n",
    "                          \n",
    "    print(f'COV={pd.Series(cov_tf)[pd.Series(C_tf).idxmax()]:.4f} (based on best Matthews value)')\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"Evaluation of the best model on test holdout in progress...\\n\")\n",
    "    \n",
    "    print(\"Best by MRR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(mrr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(mrr_pos_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by HR@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(hr_pos_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(hr_pos_tf).idxmax()[0])\n",
    "    \n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    print(\"Best by Matthews@10:\\n\")\n",
    "    config[\"mlrank\"] = pd.Series(C_tf).idxmax()[1]\n",
    "    tf_params = tf_model_build(config, training, data_description, testset, holdout, attention_matrix=attention_matrix)\n",
    "\n",
    "    seen_data = testset\n",
    "    tf_scores = tf_scoring(tf_params, seen_data, data_description, pd.Series(C_tf).idxmax()[0])\n",
    "    downvote_seen_items(tf_scores, seen_data, data_description)\n",
    "    cur_mrr, cur_hr, cur_C = make_prediction(tf_scores, holdout, data_description, \"Test\", pd.Series(C_tf).idxmax()[0])\n",
    "    print(\"Pipeline ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "184bb915",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n",
      "Training with different context in progress...\n",
      "------------------------------------------------------\n",
      "for context 5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0264, MRR@5 = 0.0141, Coverage@5 = 0.1233\n",
      "HR_pos@5 = 0.0252, HR_neg@5 = 0.0012\n",
      "MRR_pos@5 = 0.0137, MRR_neg@5 = 0.0003\n",
      "Matthews@5 = 0.0543\n",
      "-------------------------------------\n",
      "HR@10 = 0.0499, MRR@10 = 0.0172, Coverage@10 = 0.1740\n",
      "HR_pos@10 = 0.0469, HR_neg@10 = 0.0029\n",
      "MRR_pos@10 = 0.0166, MRR_neg@10 = 0.0006\n",
      "Matthews@10 = 0.0668\n",
      "-------------------------------------\n",
      "HR@20 = 0.0880, MRR@20 = 0.0197, Coverage@20 = 0.2368\n",
      "HR_pos@20 = 0.0821, HR_neg@20 = 0.0059\n",
      "MRR_pos@20 = 0.0190, MRR_neg@20 = 0.0008\n",
      "Matthews@20 = 0.0840\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0299, MRR@5 = 0.0152, Coverage@5 = 0.1297\n",
      "HR_pos@5 = 0.0287, HR_neg@5 = 0.0012\n",
      "MRR_pos@5 = 0.0145, MRR_neg@5 = 0.0007\n",
      "Matthews@5 = 0.0604\n",
      "-------------------------------------\n",
      "HR@10 = 0.0528, MRR@10 = 0.0184, Coverage@10 = 0.1779\n",
      "HR_pos@10 = 0.0487, HR_neg@10 = 0.0041\n",
      "MRR_pos@10 = 0.0173, MRR_neg@10 = 0.0011\n",
      "Matthews@10 = 0.0568\n",
      "-------------------------------------\n",
      "HR@20 = 0.0933, MRR@20 = 0.0211, Coverage@20 = 0.2365\n",
      "HR_pos@20 = 0.0862, HR_neg@20 = 0.0070\n",
      "MRR_pos@20 = 0.0198, MRR_neg@20 = 0.0013\n",
      "Matthews@20 = 0.0792\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 3+4+5 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0299, MRR@5 = 0.0160, Coverage@5 = 0.1453\n",
      "HR_pos@5 = 0.0287, HR_neg@5 = 0.0012\n",
      "MRR_pos@5 = 0.0152, MRR_neg@5 = 0.0009\n",
      "Matthews@5 = 0.0604\n",
      "-------------------------------------\n",
      "HR@10 = 0.0551, MRR@10 = 0.0194, Coverage@10 = 0.1921\n",
      "HR_pos@10 = 0.0499, HR_neg@10 = 0.0053\n",
      "MRR_pos@10 = 0.0180, MRR_neg@10 = 0.0014\n",
      "Matthews@10 = 0.0465\n",
      "-------------------------------------\n",
      "HR@20 = 0.1003, MRR@20 = 0.0225, Coverage@20 = 0.2513\n",
      "HR_pos@20 = 0.0903, HR_neg@20 = 0.0100\n",
      "MRR_pos@20 = 0.0207, MRR_neg@20 = 0.0017\n",
      "Matthews@20 = 0.0611\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "for context 3+4+5-2-1 evaluation (Validation): \n",
      "\n",
      "HR@5 = 0.0276, MRR@5 = 0.0159, Coverage@5 = 0.1378\n",
      "HR_pos@5 = 0.0264, HR_neg@5 = 0.0012\n",
      "MRR_pos@5 = 0.0151, MRR_neg@5 = 0.0008\n",
      "Matthews@5 = 0.0564\n",
      "-------------------------------------\n",
      "HR@10 = 0.0475, MRR@10 = 0.0186, Coverage@10 = 0.1815\n",
      "HR_pos@10 = 0.0440, HR_neg@10 = 0.0035\n",
      "MRR_pos@10 = 0.0175, MRR_neg@10 = 0.0011\n",
      "Matthews@10 = 0.0560\n",
      "-------------------------------------\n",
      "HR@20 = 0.0903, MRR@20 = 0.0215, Coverage@20 = 0.2415\n",
      "HR_pos@20 = 0.0827, HR_neg@20 = 0.0076\n",
      "MRR_pos@20 = 0.0201, MRR_neg@20 = 0.0014\n",
      "Matthews@20 = 0.0703\n",
      "-------------------------------------\n",
      "------------------------------------------------------\n",
      "Tuning model for all contexts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [08:37<00:00, 16.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best HR=0.0733 achieved with context 3+4+5-2-1 and mlrank = (128, 128, 2) and scale factor = 0.7\n",
      "Best HR_pos=0.0686 achieved with context 3+4+5-2-1 and mlrank = (128, 128, 2) and scale factor = 0.7\n",
      "Best HR_neg=0.0000 achieved with context 5 and mlrank = (192, 192, 4) and scale factor = 1.9\n",
      "Best MRR=0.0280 achieved with context 4+5 and mlrank = (128, 128, 3) and scale factor = 0.7\n",
      "Best MRR_pos=0.0269 achieved with context 4+5 and mlrank = (128, 128, 3) and scale factor = 0.7\n",
      "Best MRR_neg=0.0000 achieved with context 5 and mlrank = (192, 192, 4) and scale factor = 1.9\n",
      "Best Matthews=0.0936 achieved with context 5 and mlrank = (192, 192, 4) and scale factor = 1.9\n",
      "COV=0.2248 (based on best Matthews value)\n",
      "---------------------------------------------------------\n",
      "Evaluation of the best model on test holdout in progress...\n",
      "\n",
      "Best by MRR@10:\n",
      "\n",
      "for context 4+5 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0322, MRR@5 = 0.0163, Coverage@5 = 0.1637\n",
      "HR_pos@5 = 0.0305, HR_neg@5 = 0.0017\n",
      "MRR_pos@5 = 0.0150, MRR_neg@5 = 0.0013\n",
      "Matthews@5 = 0.0580\n",
      "-------------------------------------\n",
      "HR@10 = 0.0529, MRR@10 = 0.0191, Coverage@10 = 0.2094\n",
      "HR_pos@10 = 0.0477, HR_neg@10 = 0.0052\n",
      "MRR_pos@10 = 0.0173, MRR_neg@10 = 0.0018\n",
      "Matthews@10 = 0.0476\n",
      "-------------------------------------\n",
      "HR@20 = 0.0880, MRR@20 = 0.0214, Coverage@20 = 0.2724\n",
      "HR_pos@20 = 0.0811, HR_neg@20 = 0.0069\n",
      "MRR_pos@20 = 0.0195, MRR_neg@20 = 0.0019\n",
      "Matthews@20 = 0.0784\n",
      "-------------------------------------\n",
      "---------------------------------------------------------\n",
      "Best by HR@10:\n",
      "\n",
      "for context 3+4+5-2-1 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0414, MRR@5 = 0.0198, Coverage@5 = 0.1854\n",
      "HR_pos@5 = 0.0368, HR_neg@5 = 0.0046\n",
      "MRR_pos@5 = 0.0183, MRR_neg@5 = 0.0015\n",
      "Matthews@5 = 0.0346\n",
      "-------------------------------------\n",
      "HR@10 = 0.0627, MRR@10 = 0.0224, Coverage@10 = 0.2409\n",
      "HR_pos@10 = 0.0564, HR_neg@10 = 0.0063\n",
      "MRR_pos@10 = 0.0207, MRR_neg@10 = 0.0017\n",
      "Matthews@10 = 0.0500\n",
      "-------------------------------------\n",
      "HR@20 = 0.0972, MRR@20 = 0.0248, Coverage@20 = 0.3006\n",
      "HR_pos@20 = 0.0886, HR_neg@20 = 0.0086\n",
      "MRR_pos@20 = 0.0230, MRR_neg@20 = 0.0019\n",
      "Matthews@20 = 0.0739\n",
      "-------------------------------------\n",
      "---------------------------------------------------------\n",
      "Best by Matthews@10:\n",
      "\n",
      "for context 5 evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0270, MRR@5 = 0.0147, Coverage@5 = 0.1835\n",
      "HR_pos@5 = 0.0259, HR_neg@5 = 0.0012\n",
      "MRR_pos@5 = 0.0143, MRR_neg@5 = 0.0003\n",
      "Matthews@5 = 0.0579\n",
      "-------------------------------------\n",
      "HR@10 = 0.0454, MRR@10 = 0.0171, Coverage@10 = 0.2354\n",
      "HR_pos@10 = 0.0431, HR_neg@10 = 0.0023\n",
      "MRR_pos@10 = 0.0166, MRR_neg@10 = 0.0005\n",
      "Matthews@10 = 0.0711\n",
      "-------------------------------------\n",
      "HR@20 = 0.0719, MRR@20 = 0.0190, Coverage@20 = 0.2975\n",
      "HR_pos@20 = 0.0684, HR_neg@20 = 0.0035\n",
      "MRR_pos@20 = 0.0184, MRR_neg@20 = 0.0006\n",
      "Matthews@20 = 0.0926\n",
      "-------------------------------------\n",
      "Pipeline ended.\n"
     ]
    }
   ],
   "source": [
    "attention_matrix = np.eye(5)\n",
    "full_pipeline(config, training, data_description, testset_valid, holdout_valid, testset, holdout, attention_matrix=attention_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2fcbb",
   "metadata": {},
   "source": [
    "# Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f96e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:13:17.188528Z",
     "start_time": "2022-04-30T17:13:17.178630Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_random_model(trainset, trainset_description):\n",
    "    itemid = trainset_description['items']\n",
    "    n_items = trainset[itemid].max() + 1\n",
    "    random_state = np.random.RandomState(42)\n",
    "    return n_items, random_state\n",
    "\n",
    "def random_model_scoring(params, testset, testset_description):\n",
    "    n_items, random_state = params\n",
    "    n_users = testset_description['n_test_users']\n",
    "    scores = random_state.rand(n_users, n_items)\n",
    "    return scores\n",
    "\n",
    "def simple_model_recom_func(scores, topn=20):\n",
    "    recommendations = np.apply_along_axis(topidx, 1, scores, topn)\n",
    "    return recommendations\n",
    "\n",
    "def topidx(a, topn):\n",
    "    parted = np.argpartition(a, -topn)[-topn:]\n",
    "    return parted[np.argsort(-a[parted])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65f2338",
   "metadata": {
    "id": "LQaaMX1erOcc"
   },
   "source": [
    "# Popularity-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c98ccd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:13:17.739960Z",
     "start_time": "2022-04-30T17:13:17.721961Z"
    },
    "id": "oI3UZ4KMrR4i"
   },
   "outputs": [],
   "source": [
    "def build_popularity_model(trainset, trainset_description):\n",
    "    itemid = trainset_description['items']\n",
    "    item_popularity = trainset[itemid].value_counts()\n",
    "    return item_popularity\n",
    "\n",
    "def popularity_model_scoring(params, testset, testset_description):\n",
    "    item_popularity = params\n",
    "    n_items = item_popularity.index.max() + 1\n",
    "    n_users = testset_description['n_test_users']\n",
    "    # fill in popularity scores for each item with indices from 0 to n_items-1\n",
    "    popularity_scores = np.zeros(n_items,)\n",
    "    popularity_scores[item_popularity.index] = item_popularity.values\n",
    "    # same scores for each test user\n",
    "    scores = np.tile(popularity_scores, n_users).reshape(n_users, n_items)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e2d6ce",
   "metadata": {
    "id": "-c7NJyjoxbVF"
   },
   "source": [
    "# PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504340c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:19:23.495801Z",
     "start_time": "2022-05-02T10:19:23.475181Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHfx8WVYvJsQ",
    "outputId": "8791e807-11c9-41a1-c3a9-7b68cf85822d"
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), shape=(useridx.values.max() + 1, data_description[\"n_items\"]), dtype='f8')\n",
    "\n",
    "def build_svd_model(config, data, data_description):\n",
    "    source_matrix = matrix_from_observations(data, data_description)\n",
    "    #print(source_matrix.shape)\n",
    "    D = norm(source_matrix, axis=0)\n",
    "    A = source_matrix.dot(diags(D**(config['f']-1)))\n",
    "    _, _, vt = svds(A, k=config['rank'], return_singular_vectors='vh')\n",
    "#     singular_values = s[::-1]\n",
    "    item_factors = np.ascontiguousarray(vt[::-1, :].T)\n",
    "    return item_factors\n",
    "\n",
    "def svd_model_scoring(params, data, data_description):\n",
    "    item_factors = params\n",
    "    test_data = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    )\n",
    "    test_matrix = matrix_from_observations(test_data, data_description)\n",
    "    #print(test_matrix.shape, item_factors.shape)\n",
    "    scores = test_matrix.dot(item_factors) @ item_factors.T\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c75484",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a79d9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:20:07.565484Z",
     "start_time": "2022-05-02T10:20:07.555453Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "rank_grid = []\n",
    "for i in range(5, 10):\n",
    "    rank_grid.append(2 * 2 ** i)\n",
    "    rank_grid.append(3 * 2 ** i)\n",
    "    \n",
    "rank_grid = np.array(rank_grid)\n",
    "\n",
    "f_grid = np.linspace(0, 2, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b6c476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:21:40.684131Z",
     "start_time": "2022-05-02T10:20:08.093579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ec50bc4f5841a680f43129d3c23ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m r, f \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m      7\u001b[0m svd_config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mint\u001b[39m(r), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m: f}\n\u001b[1;32m----> 8\u001b[0m svd_params \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_svd_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvd_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m svd_scores \u001b[38;5;241m=\u001b[39m svd_model_scoring(svd_params, testset_valid, data_description)\n\u001b[0;32m     10\u001b[0m downvote_seen_items(svd_scores, testset_valid, data_description)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mbuild_svd_model\u001b[1;34m(config, data, data_description)\u001b[0m\n\u001b[0;32m     10\u001b[0m     D \u001b[38;5;241m=\u001b[39m norm(source_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m     A \u001b[38;5;241m=\u001b[39m source_matrix\u001b[38;5;241m.\u001b[39mdot(diags(D\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m---> 12\u001b[0m     _, _, vt \u001b[38;5;241m=\u001b[39m \u001b[43msvds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_singular_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#     singular_values = s[::-1]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     item_factors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(vt[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py:1869\u001b[0m, in \u001b[0;36msvds\u001b[1;34m(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors, solver)\u001b[0m\n\u001b[0;32m   1865\u001b[0m     eigvals, eigvec \u001b[38;5;241m=\u001b[39m lobpcg(XH_X, X, tol\u001b[38;5;241m=\u001b[39mtol \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   1866\u001b[0m                              largest\u001b[38;5;241m=\u001b[39mlargest)\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m solver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1869\u001b[0m     eigvals, eigvec \u001b[38;5;241m=\u001b[39m \u001b[43meigsh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXH_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1870\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mncv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhich\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlobpcg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py:1690\u001b[0m, in \u001b[0;36meigsh\u001b[1;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[0;32m   1689\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params\u001b[38;5;241m.\u001b[39mconverged:\n\u001b[1;32m-> 1690\u001b[0m         \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params\u001b[38;5;241m.\u001b[39mextract(return_eigenvectors)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py:536\u001b[0m, in \u001b[0;36m_SymmetricArpackParams.iterate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mido, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miparam, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 536\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arpack_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mido\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhich\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miparam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mipntr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     xslice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)\n\u001b[0;32m    541\u001b[0m     yslice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipntr[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "C_tf = {}\n",
    "grid = list(zip(np.meshgrid(rank_grid, f_grid)[0].flatten(), np.meshgrid(rank_grid, f_grid)[1].flatten()))\n",
    "for params in tqdm(grid):\n",
    "    r, f = params\n",
    "    svd_config = {'rank': int(r), 'f': f}\n",
    "    svd_params = build_svd_model(svd_config, training, data_description)\n",
    "    svd_scores = svd_model_scoring(svd_params, testset_valid, data_description)\n",
    "    downvote_seen_items(svd_scores, testset_valid, data_description)\n",
    "    svd_recs = topn_recommendations(svd_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(svd_recs, holdout_valid, data_description, alpha=3, topn=10, dcg=False)\n",
    "    hr_tf[f'r={r}, f={f:.2f}'] = hr\n",
    "    mrr_tf[f'r={r}, f={f:.2f}'] = mrr\n",
    "    C_tf[f'r={r}, f={f:.2f}'] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dae21797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=128, f=0.80 0.09736070381231672\n",
      "r=256, f=0.60 0.0967741935483871\n",
      "r=384, f=0.40 0.09442815249266863\n",
      "r=256, f=0.50 0.093841642228739\n",
      "r=192, f=0.80 0.09325513196480939\n"
     ]
    }
   ],
   "source": [
    "hr_sorted = sorted(hr_tf, key=hr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(hr_sorted[i], hr_tf[hr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d05f5875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=192, f=0.70 0.03413675929804962\n",
      "r=192, f=0.80 0.03355723129916678\n",
      "r=192, f=0.90 0.032957687473816506\n",
      "r=192, f=0.60 0.0326707163803938\n",
      "r=192, f=0.50 0.03247358376390634\n"
     ]
    }
   ],
   "source": [
    "mrr_sorted = sorted(mrr_tf, key=mrr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(mrr_sorted[i], mrr_tf[mrr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ee890ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=64, f=1.90 0.08595038846814079\n",
      "r=64, f=2.00 0.08380801742096403\n",
      "r=64, f=1.10 0.08350407592632614\n",
      "r=64, f=1.30 0.08073169474641102\n",
      "r=128, f=1.50 0.08057079114741801\n"
     ]
    }
   ],
   "source": [
    "C_sorted = sorted(C_tf, key=C_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(C_sorted[i], C_tf[C_sorted[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e1240",
   "metadata": {},
   "source": [
    "# EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f62dbd86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:13:20.763564Z",
     "start_time": "2022-04-30T17:13:20.753582Z"
    }
   },
   "outputs": [],
   "source": [
    "def matrix_from_observations(data, data_description):\n",
    "    useridx = data[data_description['users']]\n",
    "    itemidx = data[data_description['items']]\n",
    "    values = data[data_description['feedback']]\n",
    "    return csr_matrix((values, (useridx, itemidx)), dtype='f8')\n",
    "\n",
    "\n",
    "def easer(data, data_description, lmbda=500):\n",
    "    X = matrix_from_observations(data, data_description)\n",
    "    G = X.T.dot(X)\n",
    "    diag_indices = np.diag_indices(G.shape[0])\n",
    "    G[diag_indices] += lmbda\n",
    "    P = np.linalg.inv(G.A)\n",
    "    B = P / (-np.diag(P))\n",
    "    B[diag_indices] = 0\n",
    "    \n",
    "    return B\n",
    "\n",
    "def easer_scoring(params, data, data_description):\n",
    "    item_factors = params\n",
    "    test_data = data.assign(\n",
    "        userid = pd.factorize(data['userid'])[0]\n",
    "    )\n",
    "    test_matrix = matrix_from_observations(test_data, data_description)\n",
    "    scores = test_matrix.dot(item_factors)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0f110",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c77baa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:27:36.693937Z",
     "start_time": "2022-04-30T17:27:36.682937Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# lambda_grid = np.arange(50, 1000, 50)\n",
    "lambda_grid = np.arange(5, 55, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4ab5354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:03.051324Z",
     "start_time": "2022-04-30T17:27:37.866717Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "hr_tf = {}\n",
    "mrr_tf = {}\n",
    "C_tf = {}\n",
    "for lmbda in tqdm(lambda_grid):\n",
    "    easer_params = easer(training, data_description, lmbda=lmbda)\n",
    "    easer_scores = easer_scoring(easer_params, testset_valid, data_description)\n",
    "    downvote_seen_items(easer_scores, testset_valid, data_description)\n",
    "    easer_recs = topn_recommendations(easer_scores, topn=10)\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = model_evaluate(easer_recs, holdout_valid, data_description, alpha=3, topn=10, dcg=False)\n",
    "    hr_tf[lmbda] = hr\n",
    "    mrr_tf[lmbda] = mrr\n",
    "    C_tf[lmbda] = C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfc64474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:05.703740Z",
     "start_time": "2022-04-30T17:28:05.696738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 0.07448680351906159\n",
      "40 0.07390029325513198\n",
      "45 0.07390029325513198\n",
      "50 0.07390029325513198\n",
      "30 0.07214076246334311\n"
     ]
    }
   ],
   "source": [
    "hr_sorted = sorted(hr_tf, key=hr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(hr_sorted[i], hr_tf[hr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e9ec3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:06.065338Z",
     "start_time": "2022-04-30T17:28:06.052332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.02702858073825816\n",
      "45 0.026472326956197927\n",
      "40 0.02557161476516315\n",
      "35 0.025290462225946102\n",
      "30 0.025008611460224373\n"
     ]
    }
   ],
   "source": [
    "mrr_sorted = sorted(mrr_tf, key=mrr_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(mrr_sorted[i], mrr_tf[mrr_sorted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa875a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:28:06.539334Z",
     "start_time": "2022-04-30T17:28:06.521333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 0.08271079069920403\n",
      "5 0.08089233857404816\n",
      "25 0.08057079114741801\n",
      "35 0.0795338071497705\n",
      "20 0.0791246347084103\n"
     ]
    }
   ],
   "source": [
    "C_sorted = sorted(C_tf, key=C_tf.get, reverse=True)\n",
    "for i in range(5):\n",
    "    print(C_sorted[i], C_tf[C_sorted[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc72a18",
   "metadata": {},
   "source": [
    "# Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3fd9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:13:22.336245Z",
     "start_time": "2022-04-30T17:13:22.313261Z"
    }
   },
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    n_ratings = training['rating'].nunique(),\n",
    "    min_rating = training['rating'].min(),\n",
    "    test_users = holdout[data_index['users'].name].drop_duplicates().values,\n",
    "    n_test_users = holdout[data_index['users'].name].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c0d8c",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5c9144",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:13:24.725534Z",
     "start_time": "2022-04-30T17:13:24.417512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0023, MRR@5 = 0.0012, Coverage@5 = 0.9122\n",
      "HR_pos@5 = 0.0023, HR_neg@5 = 0.0000\n",
      "MRR_pos@5 = 0.0012, MRR_neg@5 = 0.0000\n",
      "Matthews@5 = 0.0221\n",
      "-------------------------------------\n",
      "HR@10 = 0.0023, MRR@10 = 0.0012, Coverage@10 = 0.9936\n",
      "HR_pos@10 = 0.0023, HR_neg@10 = 0.0000\n",
      "MRR_pos@10 = 0.0012, MRR_neg@10 = 0.0000\n",
      "Matthews@10 = 0.0221\n",
      "-------------------------------------\n",
      "HR@20 = 0.0069, MRR@20 = 0.0015, Coverage@20 = 1.0000\n",
      "HR_pos@20 = 0.0063, HR_neg@20 = 0.0006\n",
      "MRR_pos@20 = 0.0015, MRR_neg@20 = 0.0000\n",
      "Matthews@20 = 0.0200\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rnd_params = build_random_model(training, data_description)\n",
    "rnd_scores = random_model_scoring(rnd_params, None, data_description)\n",
    "downvote_seen_items(rnd_scores, testset, data_description)\n",
    "\n",
    "_ = make_prediction(rnd_scores, holdout, data_description, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36f895",
   "metadata": {},
   "source": [
    "## MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a696ad3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0115, MRR@5 = 0.0066, Coverage@5 = 0.0198\n",
      "HR_pos@5 = 0.0109, HR_neg@5 = 0.0006\n",
      "MRR_pos@5 = 0.0064, MRR_neg@5 = 0.0001\n",
      "Matthews@5 = 0.0353\n",
      "-------------------------------------\n",
      "HR@10 = 0.0230, MRR@10 = 0.0079, Coverage@10 = 0.0301\n",
      "HR_pos@10 = 0.0224, HR_neg@10 = 0.0006\n",
      "MRR_pos@10 = 0.0078, MRR_neg@10 = 0.0001\n",
      "Matthews@10 = 0.0604\n",
      "-------------------------------------\n",
      "HR@20 = 0.0483, MRR@20 = 0.0097, Coverage@20 = 0.0513\n",
      "HR_pos@20 = 0.0466, HR_neg@20 = 0.0017\n",
      "MRR_pos@20 = 0.0094, MRR_neg@20 = 0.0002\n",
      "Matthews@20 = 0.0823\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pop_params = build_popularity_model(training, data_description)\n",
    "pop_scores = popularity_model_scoring(pop_params, None, data_description)\n",
    "downvote_seen_items(pop_scores, testset, data_description)\n",
    "\n",
    "_ = make_prediction(pop_scores, holdout, data_description, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a75d4",
   "metadata": {},
   "source": [
    "## PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "759c796c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:22:03.805740Z",
     "start_time": "2022-05-02T10:22:01.750695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'rank': 768, 'f': 0.0}, 'HR')\n",
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0305, MRR@5 = 0.0176, Coverage@5 = 0.1043\n",
      "HR_pos@5 = 0.0299, HR_neg@5 = 0.0006\n",
      "MRR_pos@5 = 0.0173, MRR_neg@5 = 0.0003\n",
      "Matthews@5 = 0.0726\n",
      "-------------------------------------\n",
      "HR@10 = 0.0552, MRR@10 = 0.0208, Coverage@10 = 0.1302\n",
      "HR_pos@10 = 0.0495, HR_neg@10 = 0.0058\n",
      "MRR_pos@10 = 0.0198, MRR_neg@10 = 0.0010\n",
      "Matthews@10 = 0.0447\n",
      "-------------------------------------\n",
      "HR@20 = 0.0978, MRR@20 = 0.0238, Coverage@20 = 0.1715\n",
      "HR_pos@20 = 0.0880, HR_neg@20 = 0.0098\n",
      "MRR_pos@20 = 0.0225, MRR_neg@20 = 0.0013\n",
      "Matthews@20 = 0.0644\n",
      "-------------------------------------\n",
      "({'rank': 768, 'f': 0.0}, 'MRR')\n",
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0305, MRR@5 = 0.0176, Coverage@5 = 0.1043\n",
      "HR_pos@5 = 0.0299, HR_neg@5 = 0.0006\n",
      "MRR_pos@5 = 0.0173, MRR_neg@5 = 0.0003\n",
      "Matthews@5 = 0.0726\n",
      "-------------------------------------\n",
      "HR@10 = 0.0552, MRR@10 = 0.0208, Coverage@10 = 0.1302\n",
      "HR_pos@10 = 0.0495, HR_neg@10 = 0.0058\n",
      "MRR_pos@10 = 0.0198, MRR_neg@10 = 0.0010\n",
      "Matthews@10 = 0.0447\n",
      "-------------------------------------\n",
      "HR@20 = 0.0978, MRR@20 = 0.0238, Coverage@20 = 0.1715\n",
      "HR_pos@20 = 0.0880, HR_neg@20 = 0.0098\n",
      "MRR_pos@20 = 0.0225, MRR_neg@20 = 0.0013\n",
      "Matthews@20 = 0.0644\n",
      "-------------------------------------\n",
      "({'rank': 96, 'f': 0.0}, 'MC')\n",
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0305, MRR@5 = 0.0176, Coverage@5 = 0.1043\n",
      "HR_pos@5 = 0.0299, HR_neg@5 = 0.0006\n",
      "MRR_pos@5 = 0.0173, MRR_neg@5 = 0.0003\n",
      "Matthews@5 = 0.0726\n",
      "-------------------------------------\n",
      "HR@10 = 0.0552, MRR@10 = 0.0208, Coverage@10 = 0.1302\n",
      "HR_pos@10 = 0.0495, HR_neg@10 = 0.0058\n",
      "MRR_pos@10 = 0.0198, MRR_neg@10 = 0.0010\n",
      "Matthews@10 = 0.0447\n",
      "-------------------------------------\n",
      "HR@20 = 0.0978, MRR@20 = 0.0238, Coverage@20 = 0.1715\n",
      "HR_pos@20 = 0.0880, HR_neg@20 = 0.0098\n",
      "MRR_pos@20 = 0.0225, MRR_neg@20 = 0.0013\n",
      "Matthews@20 = 0.0644\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for_hr = sorted(hr_tf, key=hr_tf.get, reverse=True)[0]\n",
    "for_mrr = sorted(mrr_tf, key=mrr_tf.get, reverse=True)[0]\n",
    "for_mc = sorted(C_tf, key=C_tf.get, reverse=True)[0]\n",
    "\n",
    "svd_config_hr = {'rank': int(for_hr.split(\",\")[0][2:]), 'f': float(for_hr.split(\",\")[1][3:])}\n",
    "svd_config_mrr = {'rank': int(for_mrr.split(\",\")[0][2:]), 'f': float(for_mrr.split(\",\")[1][3:])}\n",
    "svd_config_mc = {'rank': int(for_mc.split(\",\")[0][2:]), 'f': float(for_mc.split(\",\")[1][3:])}\n",
    "\n",
    "svd_configs = [(svd_config_hr, \"HR\"), (svd_config_mrr, \"MRR\"), (svd_config_mc, \"MC\")]\n",
    "\n",
    "for svd_config in svd_configs:\n",
    "    print(svd_config)\n",
    "    svd_params = build_svd_model({'rank':64, 'f':1.9}, training, data_description)\n",
    "    svd_scores = svd_model_scoring(svd_params, testset, data_description)\n",
    "    downvote_seen_items(svd_scores, testset, data_description)\n",
    "\n",
    "    _ = make_prediction(svd_scores, holdout, data_description, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df751676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:34:53.634686Z",
     "start_time": "2022-05-02T10:34:53.614674Z"
    }
   },
   "outputs": [],
   "source": [
    "def vae_evaluate(recommended_items, holdout, holdout_description, alpha=3, topn=10, dcg=False):\n",
    "    itemid = holdout_description['items']\n",
    "    rateid = holdout_description['feedback']\n",
    "    alpha = 3 if holdout_description[\"n_ratings\"] == 5 else 6\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    \n",
    "    holdout_items = holdout[itemid].values \n",
    "    \n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    \n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    pos_mask = (holdout[rateid] >= alpha).values\n",
    "    neg_mask = (holdout[rateid] < alpha).values\n",
    "    \n",
    "    # HR calculation\n",
    "    #hr = np.sum(hits_mask.any(axis=1)) / n_test_users\n",
    "    hr_pos = np.sum(hits_mask[pos_mask].any(axis=1))# / n_test_users\n",
    "    hr_neg = np.sum(hits_mask[neg_mask].any(axis=1))# / n_test_users\n",
    "    hr = hr_pos + hr_neg\n",
    "    \n",
    "    # MRR calculation\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank)# / n_test_users\n",
    "    pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "    mrr_pos = np.sum(1 / pos_hit_rank)# / n_test_users\n",
    "    neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "    mrr_neg = np.sum(1 / neg_hit_rank)# / n_test_users\n",
    "    \n",
    "    # Matthews correlation\n",
    "    TP = np.sum(hits_mask[pos_mask]) # + \n",
    "    FP = np.sum(hits_mask[neg_mask]) # +\n",
    "    cond = (hits_mask.sum(axis = 1) == 0)\n",
    "    FN = np.sum(cond[pos_mask])\n",
    "    TN = np.sum(cond[neg_mask])\n",
    "    \n",
    "    C = list([TP, FP, FN, TN])\n",
    "    \n",
    "    # DCG calculation\n",
    "    if dcg:\n",
    "        pos_hit_rank = np.where(hits_mask[pos_mask])[1] + 1.0\n",
    "        neg_hit_rank = np.where(hits_mask[neg_mask])[1] + 1.0\n",
    "        ndcg = np.mean(1 / np.log2(pos_hit_rank+1))\n",
    "        ndcl = np.mean(1 / np.log2(neg_hit_rank+1))\n",
    "    \n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = list(np.unique(recommended_items))#.size / n_items\n",
    "    if dcg:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C, ndcg, ndcl\n",
    "    else:\n",
    "        return hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aae6881",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:34:53.775244Z",
     "start_time": "2022-05-02T10:34:53.768246Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mattew_c(TP, FP, FN, TN):\n",
    "    \n",
    "    N = TP + FP + TN + FN\n",
    "    S = (TP + FN) / N\n",
    "    P = (TP + FP) / N\n",
    "    \n",
    "    return (TP/N - S*P) / np.sqrt(P*S*(1-P)*(1-S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd55abb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:39:55.464068Z",
     "start_time": "2022-05-02T10:39:55.442070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1063</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>684</td>\n",
       "      <td>3</td>\n",
       "      <td>978824268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>2029</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>2879</td>\n",
       "      <td>4</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1390</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>6</td>\n",
       "      <td>1392</td>\n",
       "      <td>4</td>\n",
       "      <td>978238948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>6</td>\n",
       "      <td>1390</td>\n",
       "      <td>4</td>\n",
       "      <td>978237570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>6</td>\n",
       "      <td>3255</td>\n",
       "      <td>5</td>\n",
       "      <td>978237767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>6</td>\n",
       "      <td>2236</td>\n",
       "      <td>3</td>\n",
       "      <td>978236975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>6</td>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>978237909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid  movieid  rating  timestamp\n",
       "0         1     1063       5  978300760\n",
       "29        1      684       3  978824268\n",
       "30        1     2029       4  978824291\n",
       "31        1     2879       4  978300019\n",
       "32        1     1390       4  978824330\n",
       "..      ...      ...     ...        ...\n",
       "480       6     1392       4  978238948\n",
       "479       6     1390       4  978237570\n",
       "485       6     3255       5  978237767\n",
       "477       6     2236       3  978236975\n",
       "476       6      369       4  978237909\n",
       "\n",
       "[512 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b8a5446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-02T10:38:18.522492Z",
     "start_time": "2022-05-02T10:38:18.018485Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m downvote_seen_items(X_out, X_te, data_description)\n\u001b[0;32m     17\u001b[0m recs \u001b[38;5;241m=\u001b[39m topn_recommendations(X_out, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C \u001b[38;5;241m=\u001b[39m \u001b[43mvae_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m hr_list\u001b[38;5;241m.\u001b[39mappend(hr)\n\u001b[0;32m     22\u001b[0m mrr_list\u001b[38;5;241m.\u001b[39mappend(mrr)\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mvae_evaluate\u001b[1;34m(recommended_items, holdout, holdout_description, alpha, topn, dcg)\u001b[0m\n\u001b[0;32m      5\u001b[0m n_test_users \u001b[38;5;241m=\u001b[39m recommended_items\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m holdout_items \u001b[38;5;241m=\u001b[39m holdout[itemid]\u001b[38;5;241m.\u001b[39mvalues \n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m recommended_items\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(holdout_items)\n\u001b[0;32m     11\u001b[0m hits_mask \u001b[38;5;241m=\u001b[39m recommended_items[:, :topn] \u001b[38;5;241m==\u001b[39m holdout_items\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m pos_mask \u001b[38;5;241m=\u001b[39m (holdout[rateid] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m alpha)\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eval_N = testset.shape[0]\n",
    "batch_size = 512\n",
    "data_te = testset\n",
    "eval_idxlist = list(range(data_te.shape[0]))\n",
    "\n",
    "for batch_idx, start_idx in enumerate(range(0, eval_N, batch_size)):\n",
    "    end_idx = min(start_idx + batch_size, eval_N)\n",
    "    X_te = data_te.iloc[eval_idxlist[start_idx:end_idx]]\n",
    "    \n",
    "    svd_params = build_svd_model({'rank':64, 'f':1.9}, training, data_description)\n",
    "    svd_scores = svd_model_scoring(svd_params, X_te, data_description)\n",
    "    downvote_seen_items(svd_scores, X_te, data_description)\n",
    "    \n",
    "    X_out = svd_scores\n",
    "\n",
    "    downvote_seen_items(X_out, X_te, data_description)\n",
    "    recs = topn_recommendations(X_out, topn=10)\n",
    "\n",
    "    hr, hr_pos, hr_neg, mrr, mrr_pos, mrr_neg, cov, C = vae_evaluate(recs, X_te, data_description, alpha=3, topn=10, dcg=False)\n",
    "    \n",
    "\n",
    "    hr_list.append(hr)\n",
    "    mrr_list.append(mrr)\n",
    "    C_list.append(C)\n",
    "\n",
    "    mrr_pos_list.append(mrr_pos)\n",
    "    mrr_neg_list.append(mrr_neg)\n",
    "    cov_set |= set(cov)\n",
    "    hr_pos_list.append(hr_pos)\n",
    "    hr_neg_list.append(hr_neg)\n",
    "\n",
    "C = get_mattew_c(*tuple(np.array(C_list).sum(axis=0)))\n",
    "\n",
    "hr = np.sum(hr_list) / eval_N# / data_te.shape[0]\n",
    "mrr = np.sum(mrr_list) / eval_N# / data_te.shape[0]\n",
    "hr_pos = np.sum(hr_pos_list) / eval_N\n",
    "hr_neg = np.sum(hr_neg_list) / eval_N\n",
    "mrr_pos = np.sum(mrr_pos_list) / eval_N\n",
    "mrr_neg = np.sum(mrr_neg_list) / eval_N\n",
    "cov = len(cov_set) / holdout_description['n_items']\n",
    "\n",
    "print(hr, mrr, hr_pos, hr_neg, mrr_pos, mrr_neg, cov, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8bfac",
   "metadata": {},
   "source": [
    "## EASEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "754eebc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-30T17:25:10.625935Z",
     "start_time": "2022-04-30T17:25:07.905661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for context  evaluation (Test): \n",
      "\n",
      "HR@5 = 0.0339, MRR@5 = 0.0201, Coverage@5 = 0.1974\n",
      "HR_pos@5 = 0.0316, HR_neg@5 = 0.0023\n",
      "MRR_pos@5 = 0.0193, MRR_neg@5 = 0.0009\n",
      "Matthews@5 = 0.0526\n",
      "-------------------------------------\n",
      "HR@10 = 0.0598, MRR@10 = 0.0236, Coverage@10 = 0.2713\n",
      "HR_pos@10 = 0.0558, HR_neg@10 = 0.0040\n",
      "MRR_pos@10 = 0.0225, MRR_neg@10 = 0.0011\n",
      "Matthews@10 = 0.0711\n",
      "-------------------------------------\n",
      "HR@20 = 0.0897, MRR@20 = 0.0257, Coverage@20 = 0.3536\n",
      "HR_pos@20 = 0.0822, HR_neg@20 = 0.0075\n",
      "MRR_pos@20 = 0.0244, MRR_neg@20 = 0.0013\n",
      "Matthews@20 = 0.0752\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.023634500762160338, 0.05980448533640023, 0.07109841695764516)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easer_params = easer(training, data_description, lmbda=30)\n",
    "easer_scores = easer_scoring(easer_params, testset, data_description)\n",
    "downvote_seen_items(easer_scores, testset, data_description)\n",
    "\n",
    "make_prediction(easer_scores, holdout, data_description, mode='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d047e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.319px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
